--- a/Makefile
+++ b/Makefile
@@ -10,14 +10,11 @@ qca-nss-tun6rd-objs := nss_connmgr_tun6r
 ccflags-y += -DNSS_TUN6RD_DEBUG_LEVEL=0
 ccflags-y += -Werror
 
-KERNELVERSION := $(word 1, $(subst ., ,$(KERNELVERSION))).$(word 2, $(subst ., ,$(KERNELVERSION)))
-
 obj-$(bridge-mgr)+= bridge/
 obj-$(capwapmgr)+= capwapmgr/
 obj-$(dtlsmgr)+= dtls/$(DTLSMGR_DIR)/
 obj-$(gre)+= gre/
 obj-$(ipsecmgr)+= ipsecmgr/$(IPSECMGR_DIR)/
-obj-$(ipsecmgr-klips)+= ipsecmgr/$(IPSECMGR_DIR)/plugins/klips/
 obj-$(l2tpv2)+= l2tp/l2tpv2/
 obj-$(lag-mgr)+= lag/
 obj-$(map-t)+= map/map-t/
--- a/eogremgr/nss_eogremgr.c
+++ b/eogremgr/nss_eogremgr.c
@@ -19,6 +19,7 @@
  *	NSS EOGRE manager
  */
 
+#include <linux/of.h>
 #include <nss_api_if.h>
 #include <nss_cmn.h>
 #include "nss_connmgr_gre_public.h"
--- a/gre/nss_connmgr_gre_v4.c
+++ b/gre/nss_connmgr_gre_v4.c
@@ -162,14 +162,6 @@ int nss_connmgr_gre_v4_set_config(struct
 		}
 	}
 
-	/*
-	 * IP address validate
-	 */
-	if ((cfg->src_ip == 0) || (cfg->dest_ip == 0)) {
-		nss_connmgr_gre_warning("Source ip/Destination IP is invalid");
-		return GRE_ERR_INVALID_IP;
-	}
-
 	memset(t, 0, sizeof(struct ip_tunnel));
 
 	priv->pad_len =  (cfg->add_padding) ? GRE_HDR_PAD_LEN : 0;
--- a/gre/nss_connmgr_gre_v6.c
+++ b/gre/nss_connmgr_gre_v6.c
@@ -95,7 +95,8 @@ static int nss_connmgr_gre_v6_get_mac_ad
 	/*
 	 * Find src MAC address
 	 */
-	local_dev = (struct net_device *)ipv6_dev_find(&init_net, &src_addr, 1);
+	local_dev = NULL;
+	local_dev = (struct net_device *)ipv6_dev_find(&init_net, &src_addr, local_dev);
 	if (!local_dev) {
 		nss_connmgr_gre_warning("Unable to find local dev for %pI6", src_ip);
 		return GRE_ERR_NO_LOCAL_NETDEV;
@@ -106,7 +107,6 @@ static int nss_connmgr_gre_v6_get_mac_ad
 	/*
 	 * Find dest MAC address
 	 */
-
 	rt = nss_connmgr_gre_v6_route_lookup(&init_net, &dst_addr);
 	if (!rt) {
 		nss_connmgr_gre_warning("Unable to find route lookup for %pI6", dest_ip);
@@ -140,8 +140,7 @@ static int nss_connmgr_gre_v6_get_mac_ad
 		 * Release hold on existing route entry, and find the route entry again
 		 */
 		ip6_rt_put(rt);
-
-		rt = nss_connmgr_gre_v6_route_lookup(&init_net, &dst_addr);
+		rt = rt6_lookup(&init_net, &dst_addr, NULL, 0, NULL, 0);
 		if (!rt) {
 			nss_connmgr_gre_warning("Unable to find route lookup for %pI6\n", dest_ip);
 			return GRE_ERR_NEIGH_LOOKUP;
--- a/gre/test/nss_connmgr_gre_test.c
+++ b/gre/test/nss_connmgr_gre_test.c
@@ -229,10 +229,12 @@ static int nss_connmgr_gre_test_open_pro
 /*
  * Proc ops
  */
-static const struct file_operations nss_connmgr_gre_test_proc_ops =  {
-	.open =  nss_connmgr_gre_test_open_proc,
-	.write = nss_connmgr_gre_test_write_proc,
-	.read = seq_read,
+static const struct proc_ops nss_connmgr_gre_test_proc_ops =  {
+	.proc_open	= nss_connmgr_gre_test_open_proc,
+	.proc_read	= seq_read,
+	.proc_lseek	= seq_lseek,
+	.proc_release	= single_release,
+	.proc_write	= nss_connmgr_gre_test_write_proc,
 };
 
 /*
--- a/ipsecmgr/v1.0/nss_ipsecmgr.c
+++ b/ipsecmgr/v1.0/nss_ipsecmgr.c
@@ -377,7 +377,7 @@ free:
  * nss_ipsecmgr_tunnel_stats()
  * 	get tunnel statistics
  */
-static struct rtnl_link_stats64 *nss_ipsecmgr_tunnel_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)
+void nss_ipsecmgr_tunnel_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)
 {
 	struct nss_ipsecmgr_priv *priv = netdev_priv(dev);
 
@@ -389,8 +389,6 @@ static struct rtnl_link_stats64 *nss_ips
 	read_lock_bh(&ipsecmgr_ctx->lock);
 	memcpy(stats, &priv->stats, sizeof(struct rtnl_link_stats64));
 	read_unlock_bh(&ipsecmgr_ctx->lock);
-
-	return stats;
 }
 
 /*
@@ -442,7 +440,7 @@ static void nss_ipsecmgr_tunnel_setup(st
 	dev->header_ops = NULL;
 	dev->netdev_ops = &nss_ipsecmgr_tunnel_ops;
 
-	dev->destructor = nss_ipsecmgr_tunnel_free;
+	dev->priv_destructor = nss_ipsecmgr_tunnel_free;
 
 	/*
 	 * get the MAC address from the ethernet device
--- a/l2tp/l2tpv2/nss_connmgr_l2tpv2.c
+++ b/l2tp/l2tpv2/nss_connmgr_l2tpv2.c
@@ -244,7 +244,7 @@ static struct nss_connmgr_l2tpv2_session
 	 */
 	data->l2tpv2.session.session_id = session->session_id;
 	data->l2tpv2.session.peer_session_id = session->peer_session_id;
-	data->l2tpv2.session.offset = session->offset;
+	data->l2tpv2.session.offset = 0;
 	data->l2tpv2.session.hdr_len = session->hdr_len;
 	data->l2tpv2.session.reorder_timeout = session->reorder_timeout;
 	data->l2tpv2.session.recv_seq = session->recv_seq;
@@ -253,7 +253,7 @@ static struct nss_connmgr_l2tpv2_session
 	nss_connmgr_l2tpv2_info("sess %u, peer=%u nr=%u ns=%u off=%u  hdr_len=%u timeout=%x"
 	       " recv_seq=%x send_seq=%x\n",
 	       session->session_id,  session->peer_session_id, session->nr,
-	       session->ns,  session->offset, session->hdr_len,
+	       session->ns, 0, session->hdr_len,
 	       session->reorder_timeout, session->recv_seq,
 	       session->send_seq);
 
--- a/l2tp/l2tpv2/nss_connmgr_l2tpv2.h
+++ b/l2tp/l2tpv2/nss_connmgr_l2tpv2.h
@@ -30,10 +30,10 @@
 
 #define L2TP_V_2 2
 
-#define tunnel_hold(tunnel) atomic_inc(&tunnel->ref_count)
-#define tunnel_put(tunnel)  atomic_dec(&tunnel->ref_count)
-#define session_hold(session) atomic_inc(&session->ref_count)
-#define session_put(session)  atomic_dec(&session->ref_count)
+#define tunnel_hold(tunnel) refcount_inc(&tunnel->ref_count)
+#define tunnel_put(tunnel)  refcount_dec(&tunnel->ref_count)
+#define session_hold(session) refcount_inc(&session->ref_count)
+#define session_put(session)  refcount_dec(&session->ref_count)
 
  /*
   *		----------------------------------------------------------------------------------
--- a/l2tp/l2tpv2/nss_l2tpv2_stats.c
+++ b/l2tp/l2tpv2/nss_l2tpv2_stats.c
@@ -21,6 +21,7 @@
  */
 
 #include <linux/types.h>
+#include <linux/netdevice.h>
 #include <linux/ppp_channel.h>
 #include <nss_api_if.h>
 #include <nss_dynamic_interface.h>
@@ -103,14 +104,14 @@ void nss_l2tpv2_update_dev_stats(struct
 	/*
 	 * Update tunnel & session stats
 	 */
-	tunnel = l2tp_tunnel_find(dev_net(dev), data.l2tpv2.tunnel.tunnel_id);
+	tunnel = l2tp_tunnel_get(dev_net(dev), data.l2tpv2.tunnel.tunnel_id);
 	if (!tunnel) {
 		dev_put(dev);
 		return;
 	}
 	tunnel_hold(tunnel);
 
-	session = l2tp_session_find(dev_net(dev), tunnel, data.l2tpv2.session.session_id);
+	session = l2tp_session_get(dev_net(dev), data.l2tpv2.session.session_id);
 	if (!session) {
 		tunnel_put(tunnel);
 		dev_put(dev);
--- a/match/nss_match.c
+++ b/match/nss_match.c
@@ -28,6 +28,7 @@
 #include <linux/types.h>
 #include <nss_api_if.h>
 #include <linux/debugfs.h>
+#include <linux/of.h>
 
 /*
  * nss_match_verify_config_msg()
--- a/match/nss_match_priv.h
+++ b/match/nss_match_priv.h
@@ -29,19 +29,19 @@
 /*
  * Statically compile messages at different levels
  */
-#if (NSS_match_DEBUG_LEVEL < 2)
+#if (NSS_MATCH_DEBUG_LEVEL < 2)
 #define nss_match_warn(s, ...)
 #else
 #define nss_match_warn(s, ...) pr_warn("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
 #endif
 
-#if (NSS_match_DEBUG_LEVEL < 3)
+#if (NSS_MATCH_DEBUG_LEVEL < 3)
 #define nss_match_info(s, ...)
 #else
 #define nss_match_info(s, ...)   pr_notice("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
 #endif
 
-#if (NSS_match_DEBUG_LEVEL < 4)
+#if (NSS_MATCH_DEBUG_LEVEL < 4)
 #define nss_match_trace(s, ...)
 #else
 #define nss_match_trace(s, ...)  pr_info("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
--- a/portifmgr/nss_portifmgr.c
+++ b/portifmgr/nss_portifmgr.c
@@ -187,16 +187,20 @@ drop:
 }
 
 /*
- * nss_portifmgr_get_stats()
+ * nss_portifmgr_get_stats64()
  *	Netdev get stats function to get port stats
  */
-static struct rtnl_link_stats64 *nss_portifmgr_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+/*
+ * nss_nlgre_redir_cmn_dev_stats64
+ *	Report packet statistics to linux
+ */
+static void nss_portifmgr_get_stats64(struct net_device *dev,
+		struct rtnl_link_stats64 *stats)
 {
 	struct nss_portifmgr_priv *priv = (struct nss_portifmgr_priv *)netdev_priv(dev);
 	BUG_ON(priv == NULL);
 
 	nss_portid_get_stats(priv->if_num, stats);
-	return stats;
 }
 
 /*
@@ -225,7 +229,7 @@ static const struct net_device_ops nss_p
 	.ndo_start_xmit		= nss_portifmgr_start_xmit,
 	.ndo_set_mac_address	= eth_mac_addr,
 	.ndo_change_mtu		= nss_portifmgr_change_mtu,
-	.ndo_get_stats64	= nss_portifmgr_get_stats,
+	.ndo_get_stats64	= nss_portifmgr_get_stats64,
 };
 
 /*
--- a/profiler/profile.c
+++ b/profiler/profile.c
@@ -31,6 +31,7 @@
 #include <linux/fs.h>
 #include <linux/page-flags.h>
 #include <linux/sched.h>
+#include <linux/version.h>
 #include <asm/uaccess.h>
 #include <asm/page.h>
 #include <asm/thread_info.h>
@@ -937,12 +938,26 @@ static ssize_t debug_if(struct file *fil
 	return	count;
 }
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5,6,0)
+#define HAVE_PROC_OPS
+#endif
+
+#ifdef HAVE_PROC_OPS
+static const struct proc_ops profile_fops = {
+  .proc_open = profile_open,
+  .proc_read = profile_read,
+  .proc_lseek = seq_lseek,
+  .proc_release = profile_release,
+  .proc_write = debug_if,
+};
+#else
 static const struct file_operations profile_fops = {
 	.open		= profile_open,
 	.read		= profile_read,
 	.release	= profile_release,
 	.write		= debug_if,
 };
+#endif
 
 /*
  * showing sample status on Linux console
@@ -971,6 +986,15 @@ static ssize_t profile_rate_write(struct
 	return 0;
 }
 
+#ifdef HAVE_PROC_OPS
+static const struct proc_ops profile_rate_fops = {
+  .proc_open = profile_rate_open,
+  .proc_read = seq_read,
+  .proc_lseek = seq_lseek,
+  .proc_release = single_release,
+  .proc_write = profile_rate_write,
+};
+#else
 static const struct file_operations profile_rate_fops = {
 	.open		= profile_rate_open,
 	.read		= seq_read,
@@ -978,6 +1002,7 @@ static const struct file_operations prof
 	.release	= single_release,
 	.write		= profile_rate_write,
 };
+#endif
 
 /*
  * hexdump
--- a/vlan/Makefile
+++ b/vlan/Makefile
@@ -8,7 +8,7 @@ ifeq ($(SoC),$(filter $(SoC),ipq807x ipq
 ccflags-y += -DNSS_VLAN_MGR_PPE_SUPPORT
 endif
 
-ccflags-y += -DNSS_VLAN_MGR_DEBUG_LEVEL=0
+ccflags-y += -DNSS_VLAN_MGR_DEBUG_LEVEL=4
 ccflags-y += -Werror
 
 ifneq (,$(filter $(CONFIG_BONDING),y m))
--- a/vlan/nss_vlan_mgr.c
+++ b/vlan/nss_vlan_mgr.c
@@ -821,8 +821,10 @@ static struct nss_vlan_pvt *nss_vlan_mgr
  */
 static void nss_vlan_mgr_instance_free(struct nss_vlan_pvt *v)
 {
+#ifdef NSS_VLAN_MGR_PPE_SUPPORT
 	int32_t i;
 	int ret = 0;
+#endif
 
 	spin_lock(&vlan_mgr_ctx.lock);
 	BUG_ON(--v->refs);
@@ -980,8 +982,11 @@ static int nss_vlan_mgr_register_event(s
 	int ret;
 #endif
 	uint32_t vlan_tag;
+#ifdef NSS_VLAN_MGR_PPE_SUPPORT
 	struct net_device *slave;
-	int32_t port, port_if;
+	int32_t port;
+#endif
+	int32_t port_if;
 	struct vlan_dev_priv *vlan;
 	struct net_device *real_dev;
 	bool is_bond_master = false;
@@ -1355,8 +1360,10 @@ return_with_error:
 int nss_vlan_mgr_join_bridge(struct net_device *dev, uint32_t bridge_vsi)
 {
 	struct nss_vlan_pvt *v = nss_vlan_mgr_instance_find_and_ref(dev);
+#ifdef NSS_VLAN_MGR_PPE_SUPPORT
 	struct net_device *real_dev;
 	int ret;
+#endif
 
 	if (!v)
 		return 0;
@@ -1416,8 +1423,10 @@ EXPORT_SYMBOL(nss_vlan_mgr_join_bridge);
 int nss_vlan_mgr_leave_bridge(struct net_device *dev, uint32_t bridge_vsi)
 {
 	struct nss_vlan_pvt *v = nss_vlan_mgr_instance_find_and_ref(dev);
+#ifdef NSS_VLAN_MGR_PPE_SUPPORT
 	struct net_device *real_dev;
 	int ret;
+#endif
 
 	if (!v)
 		return 0;
--- a/bridge/nss_bridge_mgr.c
+++ b/bridge/nss_bridge_mgr.c
@@ -1067,8 +1067,10 @@ int nss_bridge_mgr_register_br(struct ne
 	 */
 	b_pvt->ifnum = ifnum;
 	b_pvt->mtu = dev->mtu;
+#if defined(NSS_BRIDGE_MGR_PPE_SUPPORT)
 	b_pvt->wan_if_num = -1;
 	b_pvt->wan_if_enabled = false;
+#endif
 	ether_addr_copy(b_pvt->dev_addr, dev->dev_addr);
 	spin_lock(&br_mgr_ctx.lock);
 	list_add(&b_pvt->list, &br_mgr_ctx.list);
@@ -1130,6 +1132,7 @@ static int nss_bridge_mgr_bond_slave_cha
 		return NOTIFY_DONE;
 	}
 
+#if defined(NSS_BRIDGE_MGR_PPE_SUPPORT)
 	/*
 	 * Add or remove the slave based based on linking event
 	 */
@@ -1144,6 +1147,7 @@ static int nss_bridge_mgr_bond_slave_cha
 					cu_info->upper_dev->name, master->name);
 		}
 	}
+#endif
 
 	return NOTIFY_DONE;
 }
--- a/dtls/v1.0/nss_connmgr_dtls_netdev.c
+++ b/dtls/v1.0/nss_connmgr_dtls_netdev.c
@@ -160,7 +160,7 @@ static void nss_dtlsmgr_dev_setup(struct
 	dev->ethtool_ops = NULL;
 	dev->header_ops = NULL;
 	dev->netdev_ops = &nss_dtlsmgr_session_ops;
-	dev->destructor = NULL;
+	dev->priv_destructor = NULL;
 
 	memcpy(dev->dev_addr, "\xaa\xbb\xcc\xdd\xee\xff", dev->addr_len);
 	memset(dev->broadcast, 0xff, dev->addr_len);
--- a/exports/nss_dtlsmgr.h
+++ b/exports/nss_dtlsmgr.h
@@ -128,7 +128,7 @@ enum nss_dtlsmgr_metadata_result {
  * NSS DTLS manager cryptographic structure to represent key and its length.
  */
 struct nss_dtlsmgr_crypto_data {
-	const uint8_t *data;		/**< Pointer to key or nonce. */
+	uint8_t *data;		/**< Pointer to key or nonce. */
 	uint16_t len;			/**< Length of the key. */
 };
 
--- a/clmapmgr/nss_clmapmgr.c
+++ b/clmapmgr/nss_clmapmgr.c
@@ -87,14 +87,13 @@ fail:
  * nss_clmapmgr_dev_stats64()
  *	Netdev ops function to retrieve stats.
  */
-struct rtnl_link_stats64 *nss_clmapmgr_dev_stats64(struct net_device *dev,
+void nss_clmapmgr_dev_stats64(struct net_device *dev,
 						struct rtnl_link_stats64 *stats)
 {
 	struct nss_clmapmgr_priv_t *priv;
 
 	if (!stats) {
 		nss_clmapmgr_warning("%px: invalid rtnl structure\n", dev);
-		return stats;
 	}
 
 	dev_hold(dev);
@@ -109,7 +108,6 @@ struct rtnl_link_stats64 *nss_clmapmgr_d
 	memcpy(stats, &priv->stats, sizeof(struct rtnl_link_stats64));
 	dev_put(dev);
 
-	return stats;
 }
 
 /*
--- a/tls/nss_tlsmgr_tun.c
+++ b/tls/nss_tlsmgr_tun.c
@@ -102,7 +102,7 @@ static int nss_tlsmgr_tun_open(struct ne
  * nss_tlsmgr_tun_stats64()
  *	TLS manager tunnel device
  */
-static struct rtnl_link_stats64 *nss_tlsmgr_tun_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)
+void nss_tlsmgr_tun_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)
 {
 	struct nss_tlsmgr_tun *tun = netdev_priv(dev);
 
@@ -113,7 +113,6 @@ static struct rtnl_link_stats64 *nss_tls
 	nss_tlsmgr_ctx_stats_copy(&tun->ctx_dec, stats);
 	read_unlock_bh(&tun->lock);
 
-	return stats;
 }
 
 /*
--- a/netlink/include/nss_nldtls_if.h
+++ b/netlink/include/nss_nldtls_if.h
@@ -34,9 +34,9 @@
 #define NSS_NLDTLS_DECAP_SIDE 1
 #define NSS_NLDTLS_TX_PKTS_MODE_END_TO_END 0
 #define NSS_NLDTLS_TX_PKTS_MODE_HOST_TO_HOST 1
-#define NSS_NLDTLS_CKD_MAX 32
-#define NSS_NLDTLS_AKD_MAX 32
-#define NSS_NLDTLS_ND_MAX 20
+#define NSS_NLDTLS_CIPHER_KEY_MAX 32
+#define NSS_NLDTLS_AUTH_KEY_MAX 64
+#define NSS_NLDTLS_NONCE_SIZE_MAX 4
 
 /**
  * @brief Enumeration for all command types.
@@ -51,11 +51,36 @@ enum nss_nldtls_cmd_type {
 };
 
 /**
+ * @brief Parameters for crypto keys
+ */
+struct nss_nldtls_crypto_keys {
+	uint8_t cipher[NSS_NLDTLS_CIPHER_KEY_MAX];	/**< Cipher key data */
+	uint8_t auth[NSS_NLDTLS_CIPHER_KEY_MAX];	/**< Cipher key data */
+	uint8_t nonce[NSS_NLDTLS_CIPHER_KEY_MAX];	/**< Cipher key data */
+};
+
+/**
+ * @brief Parameters for encap configuration
+ */
+struct nss_nldtls_encap_config {
+	struct nss_dtlsmgr_encap_config cfg;
+	struct nss_nldtls_crypto_keys keys;
+};
+
+/**
+ * @brief Parameter for decap configuration
+ */
+struct nss_nldtls_decap_config {
+	struct nss_dtlsmgr_decap_config cfg;
+	struct nss_nldtls_crypto_keys keys;
+};
+
+/**
  * @brief Parameters to create a tunnel.
  */
 struct nss_nldtls_create_tun {
-	struct nss_dtlsmgr_encap_config encap;	/**< Encap data. */
-	struct nss_dtlsmgr_decap_config decap;	/**< Decap data. */
+	struct nss_nldtls_encap_config encap;	/**< Encap data. */
+	struct nss_nldtls_decap_config decap;	/**< Decap data. */
 	uint32_t flags;				/**< DTLS header flags. */
 	uint32_t from_mtu;			/**< Mtu of incoming interface. */
 	uint32_t to_mtu;			/**< Mtu of outgoing interface. */
@@ -77,6 +102,7 @@ struct nss_nldtls_destroy_tun {
  */
 struct nss_nldtls_update_config {
 	struct nss_dtlsmgr_config_update config_update;		/**< Update config params */
+	struct nss_nldtls_crypto_keys keys;			/**< Crypto keys. */
 	uint16_t epoch;						/**< Dtls encap epoch. */
 	uint16_t window_sz;					/**< Dtls window size parameter. */
 	char dev_name[IFNAMSIZ];				/**< Device whose config to be updated. */
@@ -88,10 +114,11 @@ struct nss_nldtls_update_config {
  */
 struct nss_nldtls_tx_pkts {
 	uint32_t num_pkts;		/**< Number of packets to be transmitted */
+	uint32_t seq_num;		/**< starting sequence number */
 	uint16_t pkt_sz;		/**< Size of packet to be transmitted */
 	char dev_name[IFNAMSIZ];	/**< Device used for transmission */
-	uint8_t ip_version;		/**< Ip version [4 or 6] */
 	uint8_t mode;			/**< Can be end_to_end or host_to_host*/
+	uint8_t ctype;			/**< dtls content type */
 	bool log_en;			/**< Enable or disable wireless info */
 };
 
--- a/netlink/nss_nl.h
+++ b/netlink/nss_nl.h
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2015,2018, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2015,2018, 2020, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -25,6 +25,7 @@
 #define NSS_NL_DEBUG_LVL_WARN 2
 #define NSS_NL_DEBUG_LVL_INFO 3
 #define NSS_NL_DEBUG_LVL_TRACE 4
+#define GENL_ID_GENERATE 0
 
 
 #if defined(CONFIG_DYNAMIC_DEBUG)
@@ -35,7 +36,8 @@
 #define nss_nl_warn(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
 #define nss_nl_info(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
 #define nss_nl_trace(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-
+#define nss_nl_hex_dump_bytes(prefix_str, prefix_type, buf, len)	\
+	dynamic_hex_dump(prefix_str, prefix_type, 16, 1, buf, len, true)
 #else
 /*
  * Statically compile messages at different levels
@@ -55,6 +57,11 @@
 		pr_notice("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__);	\
 	}	\
 }
+#define nss_nl_hex_dump_bytes(prefix_str, prefix_type, buf, len) {	\
+	if (NSS_NL_DEBUG_LEVEL > NSS_NL_DEBUG_LVL_INFO) {	\
+		print_hex_dump_bytes(prefix_str, prefix_type, buf, len);	\
+	}	\
+}
 #define nss_nl_trace(s, ...) {	\
 	if (NSS_NL_DEBUG_LEVEL > NSS_NL_DEBUG_LVL_TRACE) {	\
 		pr_info("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__);	\
--- a/netlink/nss_nlc2c_rx.c
+++ b/netlink/nss_nlc2c_rx.c
@@ -46,20 +46,6 @@ static int nss_nlc2c_rx_ops_get_stats(st
 static int nss_nlc2c_rx_process_notify(struct notifier_block *nb,  unsigned long val, void *data);
 
 /*
- * c2c_rx family definition
- */
-static struct genl_family nss_nlc2c_rx_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLC2C_RX_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_c2c_rx_stats_notification),	/* NSS NETLINK c2c_rx stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLC2C_RX version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlc2c_rx_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nlc2c_rx_ops[
 };
 
 /*
+ * c2c_rx family definition
+ */
+static struct genl_family nss_nlc2c_rx_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLC2C_RX_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_c2c_rx_stats_notification),	/* NSS NETLINK c2c_rx stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLC2C_RX version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlc2c_rx_ops,
+	.n_ops = ARRAY_SIZE(nss_nlc2c_rx_ops),
+	.mcgrps = nss_nlc2c_rx_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlc2c_rx_mcgrp)
+};
+
+/*
  * stats call back handler for c2c_rx from NSS
  */
 static struct notifier_block nss_c2c_rx_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nlc2c_rx_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlc2c_rx_family, nss_nlc2c_rx_ops, nss_nlc2c_rx_mcgrp);
+	error = genl_register_family(&nss_nlc2c_rx_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register c2c_rx family\n");
 		return false;
--- a/netlink/nss_nlc2c_tx.c
+++ b/netlink/nss_nlc2c_tx.c
@@ -46,20 +46,6 @@ static int nss_nlc2c_tx_ops_get_stats(st
 static int nss_nlc2c_tx_process_notify(struct notifier_block *nb,  unsigned long val, void *data);
 
 /*
- * c2c_tx family definition
- */
-static struct genl_family nss_nlc2c_tx_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLC2C_TX_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_c2c_tx_stats_notification),	/* NSS NETLINK c2c_tx stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLC2C_TX version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlc2c_tx_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nlc2c_tx_ops[
 };
 
 /*
+ * c2c_tx family definition
+ */
+static struct genl_family nss_nlc2c_tx_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLC2C_TX_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_c2c_tx_stats_notification),	/* NSS NETLINK c2c_tx stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLC2C_TX version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlc2c_tx_ops,
+	.n_ops = ARRAY_SIZE(nss_nlc2c_tx_ops),
+	.mcgrps = nss_nlc2c_tx_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlc2c_tx_mcgrp)
+};
+
+/*
  * stats call back handler for c2c_tx from NSS
  */
 static struct notifier_block nss_c2c_tx_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nlc2c_tx_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlc2c_tx_family, nss_nlc2c_tx_ops, nss_nlc2c_tx_mcgrp);
+	error = genl_register_family(&nss_nlc2c_tx_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register c2c_tx family\n");
 		return false;
--- a/netlink/nss_nldtls.c
+++ b/netlink/nss_nldtls.c
@@ -15,6 +15,7 @@
  */
 
 #include <crypto/internal/skcipher.h>
+#include <linux/debugfs.h>
 #include <linux/etherdevice.h>
 #include <linux/icmp.h>
 #include <linux/inet.h>
@@ -34,6 +35,14 @@
 #include "nss_nldtls_if.h"
 
 /*
+ * prototypes
+ */
+static int nss_nldtls_ops_create_tun(struct sk_buff *skb, struct genl_info *info);
+static int nss_nldtls_ops_destroy_tun(struct sk_buff *skb, struct genl_info *info);
+static int nss_nldtls_ops_update_config(struct sk_buff *skb, struct genl_info *info);
+static int nss_nldtls_ops_tx_pkts(struct sk_buff *skb, struct genl_info *info);
+
+/*
  * Initializing the global variables
  */
 static struct nss_nldtls_gbl_ctx gbl_ctx = {
@@ -52,11 +61,24 @@ static const struct genl_multicast_group
 };
 
 /*
+ * nss_nldtls_ops
+ *	Operation table called by the generic netlink layer based on the command
+ */
+static struct genl_ops nss_nldtls_ops[] = {
+	{.cmd = NSS_NLDTLS_CMD_TYPE_CREATE_TUN, .doit = nss_nldtls_ops_create_tun,},
+	{.cmd = NSS_NLDTLS_CMD_TYPE_DESTROY_TUN, .doit = nss_nldtls_ops_destroy_tun,},
+	{.cmd = NSS_NLDTLS_CMD_TYPE_UPDATE_CONFIG, .doit = nss_nldtls_ops_update_config,},
+	{.cmd = NSS_NLDTLS_CMD_TYPE_TX_PKTS, .doit = nss_nldtls_ops_tx_pkts,},
+};
+
+/*
  * nss_nldtls_family
  *	Dtls family definition
  */
 struct genl_family nss_nldtls_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
 	.id = GENL_ID_GENERATE,				/* Auto generate ID */
+#endif
 	.name = NSS_NLDTLS_FAMILY,			/* family name string */
 	.hdrsize = sizeof(struct nss_nldtls_rule),	/* NSS NETLINK dtls rule */
 	.version = NSS_NL_VER,				/* Set it to NSS_NLDTLS version */
@@ -64,13 +86,17 @@ struct genl_family nss_nldtls_family = {
 	.netnsok = true,
 	.pre_doit = NULL,
 	.post_doit = NULL,
+	.ops = nss_nldtls_ops,
+	.n_ops = ARRAY_SIZE(nss_nldtls_ops),
+	.mcgrps = nss_nldtls_family_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nldtls_family_mcgrp)
 };
 
 /*
- * nss_nldtls_find_dtls_tun_gbl_ctx()
+ * nss_nldtls_find_tun_ctx()
  *	Returns the global context object of a tunnel
  */
-static struct nss_nldtls_tun_ctx *nss_nldtls_find_dtls_tun_gbl_ctx(struct net_device *dev)
+static struct nss_nldtls_tun_ctx *nss_nldtls_find_tun_ctx(struct net_device *dev)
 {
 	struct nss_nldtls_tun_ctx *entry;
 
@@ -87,47 +113,6 @@ static struct nss_nldtls_tun_ctx *nss_nl
 }
 
 /*
- * nss_nldtls_data_cb()
- *	Data callback function for dtls
- */
-static void __maybe_unused nss_nldtls_data_cb(void *app_data __maybe_unused, struct sk_buff *skb __maybe_unused)
-{
-	static bool first_pkt;
-	unsigned long long duration;
-	ktime_t delta;
-
-	if (unlikely(!first_pkt)) {
-		gbl_ctx.first_rx_pkt_time = ktime_get();
-		first_pkt = true;
-	}
-
-	/*
-	 * Remove meta header
-	 */
-	skb_pull(skb, sizeof(struct nss_dtlsmgr_metadata));
-	gbl_ctx.last_rx_pkt_time = ktime_get();
-
-	if (unlikely(gbl_ctx.log_en)) {
-		struct net_device *dev;
-
-		delta = ktime_sub(gbl_ctx.last_rx_pkt_time, gbl_ctx.first_rx_pkt_time);
-		duration = (unsigned long long) ktime_to_ns(delta) >> 10;
-		print_hex_dump_bytes("", DUMP_PREFIX_OFFSET, skb->data, 32);
-		dev = dev_get_by_index(&init_net, skb->skb_iif);
-		if (dev) {
-			nss_nl_error("In dev = %s, out_dev = %s\n", dev->name, skb->dev->name);
-			dev_put(dev);
-		}
-
-		nss_nl_info("%px: DTLS RX (%s) pkt len = %d udp_csum = %s rx_time: %llu\n", skb,
-				skb->dev->name, skb->len, udp_lib_checksum_complete(skb) ?
-				"invalid" : "valid", duration);
-	}
-
-	dev_kfree_skb_any(skb);
-}
-
-/*
  * nss_nldtls_dev_rx_handler()
  *	Common rx handler for all dtls dev
  */
@@ -416,6 +401,48 @@ static int nss_nldtls_create_ipv6_rule(s
 }
 
 /*
+ * nss_nldtls_data_callback()
+ *	Data callback function for dtls
+ */
+static void nss_nldtls_data_callback(void *app_data, struct sk_buff *skb)
+{
+	struct nss_dtlsmgr_metadata *ndm;
+	struct nss_nldtls_tun_ctx *tun;
+	struct nss_nldtls_stats *stats;
+	struct net_device *dev;
+
+	dev = dev_get_by_index(&init_net, skb->skb_iif);
+	if (!dev) {
+		nss_nl_error("Unable to get net dev for skb_iif %d\n", skb->skb_iif);
+		dev_kfree_skb_any(skb);
+		return;
+	}
+
+	ndm = (struct nss_dtlsmgr_metadata *)skb->data;
+	tun = nss_nldtls_find_tun_ctx(dev);
+	if (!tun) {
+		nss_nl_error("Unable find tunnel ctx for %s\n", dev->name);
+		dev_put(dev);
+		dev_kfree_skb_any(skb);
+		return;
+	}
+
+	stats = &tun->stats[NSS_NLDTLS_CTYPE_TO_IDX(ndm->ctype)];
+	spin_lock(&gbl_ctx.lock);
+	stats->rx_pkts++;
+	stats->rx_bytes += skb->len - sizeof(*ndm);
+	spin_unlock(&gbl_ctx.lock);
+
+	if (unlikely(gbl_ctx.log_en)) {
+		nss_nl_hex_dump_bytes("", DUMP_PREFIX_OFFSET, skb->data, (skb->len > 64) ? 64 : skb->len);
+	}
+
+	nss_nl_trace("%px Received DTLS packet\n", skb);
+	dev_put(dev);
+	dev_kfree_skb_any(skb);
+}
+
+/*
  * nss_nldtls_create_session()
  *	Create a DTLS session through dtlsmgr driver API.
  */
@@ -425,6 +452,7 @@ static struct net_device *nss_nldtls_cre
 	struct nss_dtlsmgr_config dcfg;
 	struct nss_dtlsmgr_ctx *ctx;
 	struct net_device *ndev;
+	uint16_t key_len;
 	uint8_t algo;
 	int err;
 
@@ -434,24 +462,66 @@ static struct net_device *nss_nldtls_cre
 	}
 
 	memset(&dcfg, 0, sizeof(struct nss_dtlsmgr_config));
-	algo = nl_rule->msg.create.encap.crypto.algo;
-	dcfg.flags = flags;
+	algo = nl_rule->msg.create.encap.cfg.crypto.algo;
+	dcfg.flags = flags | (NSS_DTLSMGR_ENCAP_METADATA | NSS_DTLSMGR_HDR_CAPWAP);
 	if (algo == NSS_DTLSMGR_ALGO_AES_GCM)
 		dcfg.flags |= NSS_DTLSMGR_CIPHER_MODE_GCM;
 
 	dcfg.app_data = NULL;
 	dcfg.notify = NULL;
-	dcfg.data = NULL;
+	dcfg.data = nss_nldtls_data_callback;
 
 	/*
 	 * Encap configuration
 	 */
-	memcpy((void *)&dcfg.encap, (void *)&nl_rule->msg.create.encap, sizeof(struct nss_dtlsmgr_encap_config));
+	key_len = nl_rule->msg.create.encap.cfg.crypto.cipher_key.len;
+	if (key_len > NSS_NLDTLS_CIPHER_KEY_MAX) {
+		nss_nl_error("Invalid cipher length: %u\n", key_len);
+		return NULL;
+	}
+
+	key_len = nl_rule->msg.create.encap.cfg.crypto.auth_key.len;
+	if (key_len > NSS_NLDTLS_AUTH_KEY_MAX) {
+		nss_nl_error("Invalid authentication length: %u\n", key_len);
+		return NULL;
+	}
+
+	key_len = nl_rule->msg.create.encap.cfg.crypto.nonce.len;
+	if (key_len > NSS_NLDTLS_NONCE_SIZE_MAX) {
+		nss_nl_error("Invalid nonce length: %u\n", key_len);
+		return NULL;
+	}
+
+	nl_rule->msg.create.encap.cfg.crypto.cipher_key.data = nl_rule->msg.create.encap.keys.cipher;
+	nl_rule->msg.create.encap.cfg.crypto.auth_key.data = nl_rule->msg.create.encap.keys.auth;
+	nl_rule->msg.create.encap.cfg.crypto.nonce.data = nl_rule->msg.create.encap.keys.nonce;
+	memcpy((void *)&dcfg.encap, (void *)&nl_rule->msg.create.encap.cfg, sizeof(struct nss_dtlsmgr_encap_config));
 
 	/*
 	 * Decap configuration
 	 */
-	memcpy((void *)&dcfg.decap, (void *)&nl_rule->msg.create.decap, sizeof(struct nss_dtlsmgr_decap_config));
+	key_len = nl_rule->msg.create.decap.cfg.crypto.cipher_key.len;
+	if (key_len > NSS_NLDTLS_CIPHER_KEY_MAX) {
+		nss_nl_error("Invalid cipher length: %u\n", key_len);
+		return NULL;
+	}
+
+	key_len = nl_rule->msg.create.decap.cfg.crypto.auth_key.len;
+	if (key_len > NSS_NLDTLS_AUTH_KEY_MAX) {
+		nss_nl_error("Invalid authentication length: %u\n", key_len);
+		return NULL;
+	}
+
+	key_len = nl_rule->msg.create.decap.cfg.crypto.nonce.len;
+	if (key_len > NSS_NLDTLS_NONCE_SIZE_MAX) {
+		nss_nl_error("Invalid nonce length: %u\n", key_len);
+		return NULL;
+	}
+
+	nl_rule->msg.create.decap.cfg.crypto.cipher_key.data = nl_rule->msg.create.decap.keys.cipher;
+	nl_rule->msg.create.decap.cfg.crypto.auth_key.data = nl_rule->msg.create.decap.keys.auth;
+	nl_rule->msg.create.decap.cfg.crypto.nonce.data = nl_rule->msg.create.decap.keys.nonce;
+	memcpy((void *)&dcfg.decap, (void *)&nl_rule->msg.create.decap.cfg, sizeof(struct nss_dtlsmgr_decap_config));
 	dcfg.decap.nexthop_ifnum = NSS_N2H_INTERFACE;
 
 	/*
@@ -484,6 +554,7 @@ static struct net_device *nss_nldtls_cre
 	dtls_tun_data = (struct nss_nldtls_tun_ctx *)kmalloc(sizeof(*dtls_tun_data), GFP_KERNEL);
 	dtls_tun_data->nl_rule = nl_rule;
 	memcpy(dtls_tun_data->dev_name, ndev->name, IFNAMSIZ);
+	memset(&dtls_tun_data->stats, 0, sizeof(dtls_tun_data->stats));
 
 	/*
 	 * Adding tunnel to global list of tunnels
@@ -524,15 +595,15 @@ static int nss_nldtls_create_ipv4_rule_e
 	ipv4.src_interface_num = if_num;
 	ipv4.dest_interface_num = nss_dtlsmgr_get_interface(dtls_dev, NSS_DTLSMGR_INTERFACE_TYPE_OUTER);
 
-	ipv4.src_port = nl_rule->msg.create.encap.dport;
-	ipv4.src_port_xlate = nl_rule->msg.create.encap.dport;
-	ipv4.src_ip = nl_rule->msg.create.encap.dip[0];
-	ipv4.src_ip_xlate = nl_rule->msg.create.encap.dip[0];
-
-	ipv4.dest_ip = nl_rule->msg.create.encap.sip[0];
-	ipv4.dest_ip_xlate = nl_rule->msg.create.encap.sip[0];
-	ipv4.dest_port = nl_rule->msg.create.encap.sport;
-	ipv4.dest_port_xlate = nl_rule->msg.create.encap.sport;
+	ipv4.src_port = nl_rule->msg.create.encap.cfg.dport;
+	ipv4.src_port_xlate = nl_rule->msg.create.encap.cfg.dport;
+	ipv4.src_ip = nl_rule->msg.create.encap.cfg.dip[0];
+	ipv4.src_ip_xlate = nl_rule->msg.create.encap.cfg.dip[0];
+
+	ipv4.dest_ip = nl_rule->msg.create.encap.cfg.sip[0];
+	ipv4.dest_ip_xlate = nl_rule->msg.create.encap.cfg.sip[0];
+	ipv4.dest_port = nl_rule->msg.create.encap.cfg.sport;
+	ipv4.dest_port_xlate = nl_rule->msg.create.encap.cfg.sport;
 
 	ipv4.protocol = IPPROTO_UDP;
 	ipv4.in_vlan_tag[0] = NSS_NLDTLS_VLAN_INVALID;
@@ -575,14 +646,14 @@ static int nss_nldtls_create_ipv6_rule_e
 	if_num = nss_cmn_get_interface_number_by_dev(ndev);
 	ipv6.src_interface_num = if_num;
 	ipv6.dest_interface_num = nss_dtlsmgr_get_interface(dtls_dev, NSS_DTLSMGR_INTERFACE_TYPE_OUTER);
-	ipv6.src_port = nl_rule->msg.create.encap.dport;
-	ipv6.dest_port = nl_rule->msg.create.encap.sport;
+	ipv6.src_port = nl_rule->msg.create.encap.cfg.dport;
+	ipv6.dest_port = nl_rule->msg.create.encap.cfg.sport;
 
 	/*
 	 * Configure IPv6 rule
 	 */
-	memcpy(ipv6.src_ip, nl_rule->msg.create.encap.dip, sizeof(ipv6.src_ip));
-	memcpy(ipv6.dest_ip, nl_rule->msg.create.encap.sip, sizeof(ipv6.dest_ip));
+	memcpy(ipv6.src_ip, nl_rule->msg.create.encap.cfg.dip, sizeof(ipv6.src_ip));
+	memcpy(ipv6.dest_ip, nl_rule->msg.create.encap.cfg.sip, sizeof(ipv6.dest_ip));
 	ipv6.protocol = IPPROTO_UDP;
 
 	ipv6.in_vlan_tag[0] = NSS_NLDTLS_VLAN_INVALID;
@@ -602,29 +673,27 @@ static int nss_nldtls_create_ipv6_rule_e
  * nss_nldtls_destroy_tun()
  *	Common handler for tunnel destroy
  */
-static int nss_nldtls_destroy_tun(struct net_device *dtls_ndev)
+static int nss_nldtls_destroy_tun(struct net_device *dev)
 {
-	struct nss_nldtls_tun_ctx *dtls_tun_data;
+	struct nss_nldtls_tun_ctx *tun;
 
-	dtls_tun_data = nss_nldtls_find_dtls_tun_gbl_ctx(dtls_ndev);
-	if (!dtls_tun_data) {
-		nss_nl_error("Unable to find context of the tunnel: %s\n", dtls_ndev->name);
-		dev_put(dtls_ndev);
+	tun = nss_nldtls_find_tun_ctx(dev);
+	if (!tun) {
+		nss_nl_error("Unable to find context of the tunnel: %s\n", dev->name);
 		return -EAGAIN;
 	}
 
 	/*
 	 * Delete tunnel node from the list
 	 */
-	list_del_init(&dtls_tun_data->list);
-	kfree(dtls_tun_data);
-	dev_put(dtls_ndev);
+	list_del_init(&tun->list);
+	kfree(tun);
 
 	/*
 	 * Destroy the dtls session
 	 */
-	if (nss_dtlsmgr_session_destroy(dtls_ndev)) {
-		nss_nl_error("Unable to destroy the tunnel: %s\n", dtls_ndev->name);
+	if (nss_dtlsmgr_session_destroy(dev)) {
+		nss_nl_error("Unable to destroy the tunnel: %s\n", dev->name);
 		return -EAGAIN;
 	}
 
@@ -709,8 +778,8 @@ static int nss_nldtls_ops_create_tun(str
 static int nss_nldtls_ops_destroy_tun(struct sk_buff *skb, struct genl_info *info)
 {
 	struct nss_nldtls_rule *nl_rule;
-	struct net_device *dtls_ndev;
 	struct nss_nlcmn *nl_cm;
+	struct net_device *dev;
 	int ret;
 
 	/*
@@ -727,18 +796,20 @@ static int nss_nldtls_ops_destroy_tun(st
 	 */
 	nl_rule = container_of(nl_cm, struct nss_nldtls_rule, cm);
 
-	dtls_ndev = dev_get_by_name(&init_net, nl_rule->msg.destroy.dev_name);
-	if (!dtls_ndev) {
-		nss_nl_error("%px: Unable to find dev: %s\n", skb, nl_rule->msg.destroy.dev_name);
+	dev = dev_get_by_name(&init_net, nl_rule->msg.destroy.dev_name);
+	if (!dev) {
+		nss_nl_error("%px Unable to find dev: %s\n", skb, nl_rule->msg.destroy.dev_name);
 		return -EINVAL;
 	}
 
+	dev_put(dev);
+
 	/*
 	 * Common dtls handler for tunnel destroy
 	 */
-	ret = nss_nldtls_destroy_tun(dtls_ndev);
+	ret = nss_nldtls_destroy_tun(dev);
 	if (ret < 0) {
-		nss_nl_error("%px: Unable to destroy tunnel: %s\n", skb, dtls_ndev->name);
+		nss_nl_error("%px Unable to destroy tunnel: %s\n", skb, dev->name);
 		return -EAGAIN;
 	}
 
@@ -753,13 +824,14 @@ static int nss_nldtls_ops_destroy_tun(st
  */
 static int nss_nldtls_ops_update_config(struct sk_buff *skb, struct genl_info *info)
 {
-	struct nss_nldtls_tun_ctx *dtls_tun_data;
 	struct nss_dtlsmgr_config_update dcfg;
 	struct nss_nldtls_rule *nl_rule;
-	struct net_device *dtls_ndev;
+	struct nss_nldtls_tun_ctx *tun;
 	struct nss_dtlsmgr_ctx *ctx;
 	nss_dtlsmgr_status_t status;
 	struct nss_nlcmn *nl_cm;
+	struct net_device *dev;
+	uint16_t key_len;
 
 	/*
 	 * extract the message payload
@@ -775,17 +847,17 @@ static int nss_nldtls_ops_update_config(
 	 */
 	nl_rule = container_of(nl_cm, struct nss_nldtls_rule, cm);
 
-	dtls_ndev = dev_get_by_name(&init_net, nl_rule->msg.update_config.dev_name);
-	if (!dtls_ndev) {
-		nss_nl_error("%px: Unable to find dev: %s\n", skb, nl_rule->msg.update_config.dev_name);
+	dev = dev_get_by_name(&init_net, nl_rule->msg.update_config.dev_name);
+	if (!dev) {
+		nss_nl_error("%px Unable to find dev: %s\n", skb, nl_rule->msg.update_config.dev_name);
 		return -EINVAL;
 	}
 
-	ctx = netdev_priv(dtls_ndev);
-	dtls_tun_data = nss_nldtls_find_dtls_tun_gbl_ctx(dtls_ndev);
-	if (!dtls_tun_data) {
-		nss_nl_error("%px: Unable to find context of the tunnel: %s\n", ctx, dtls_ndev->name);
-		dev_put(dtls_ndev);
+	ctx = netdev_priv(dev);
+	tun = nss_nldtls_find_tun_ctx(dev);
+	if (!tun) {
+		nss_nl_error("%px Unable to find context of the tunnel: %s\n", ctx, dev->name);
+		dev_put(dev);
 		return -EAGAIN;
 	}
 
@@ -793,28 +865,46 @@ static int nss_nldtls_ops_update_config(
 	 * Configure the dtls configuration
 	 */
 	dcfg.crypto.algo = nl_rule->msg.update_config.config_update.crypto.algo;
-	dcfg.crypto.cipher_key.data = nl_rule->msg.update_config.config_update.crypto.cipher_key.data;
-	dcfg.crypto.cipher_key.len = nl_rule->msg.update_config.config_update.crypto.cipher_key.len;
-	dcfg.crypto.auth_key.data = nl_rule->msg.update_config.config_update.crypto.auth_key.data;
-	dcfg.crypto.auth_key.len = nl_rule->msg.update_config.config_update.crypto.auth_key.len;
-	dcfg.crypto.nonce.data = nl_rule->msg.update_config.config_update.crypto.nonce.data;
-	dcfg.crypto.nonce.len = nl_rule->msg.update_config.config_update.crypto.nonce.len;
+	dcfg.crypto.cipher_key.data = nl_rule->msg.update_config.keys.cipher;
+	dcfg.crypto.auth_key.data = nl_rule->msg.update_config.keys.auth;
+	dcfg.crypto.nonce.data = nl_rule->msg.update_config.keys.nonce;
+	key_len = nl_rule->msg.update_config.config_update.crypto.cipher_key.len;
+	if (key_len > NSS_NLDTLS_CIPHER_KEY_MAX) {
+		nss_nl_error("Invalid cipher length: %u\n", key_len);
+		return -EINVAL;
+	}
+
+	dcfg.crypto.cipher_key.len = key_len;
+	key_len = nl_rule->msg.update_config.config_update.crypto.auth_key.len;
+	if (key_len > NSS_NLDTLS_AUTH_KEY_MAX) {
+		nss_nl_error("Invalid authentication length: %u\n", key_len);
+		return -EINVAL;
+	}
+
+	dcfg.crypto.auth_key.len = key_len;
+	key_len = nl_rule->msg.update_config.config_update.crypto.nonce.len;
+	if (key_len > NSS_NLDTLS_NONCE_SIZE_MAX) {
+		nss_nl_error("Invalid nonce length: %u\n", key_len);
+		return -EINVAL;
+	}
+
+	dcfg.crypto.nonce.len = key_len;
 	dcfg.epoch = nl_rule->msg.update_config.config_update.epoch;
 	dcfg.window_size = nl_rule->msg.update_config.config_update.window_size;
 	if (!nl_rule->msg.update_config.dir) {
-		status = nss_dtlsmgr_session_update_encap(dtls_ndev, &dcfg);
+		status = nss_dtlsmgr_session_update_encap(dev, &dcfg);
 		if (status != NSS_DTLSMGR_OK) {
-			nss_nl_error("%px: Unable to update encap configuration\n", ctx);
-			dev_put(dtls_ndev);
+			nss_nl_error("%px Unable to update encap configuration\n", ctx);
+			dev_put(dev);
 			return -EINVAL;
 		}
 
 		nss_nl_info("%px: Successfully update the encap configuration\n", ctx);
 	} else {
-		status = nss_dtlsmgr_session_update_decap(dtls_ndev, &dcfg);
+		status = nss_dtlsmgr_session_update_decap(dev, &dcfg);
 		if (status != NSS_DTLSMGR_OK) {
-			nss_nl_error("%px: Unable to update decap configuration\n", ctx);
-			dev_put(dtls_ndev);
+			nss_nl_error("%px Unable to update decap configuration\n", ctx);
+			dev_put(dev);
 			return -EINVAL;
 		}
 
@@ -824,213 +914,65 @@ static int nss_nldtls_ops_update_config(
 	/*
 	 * Update the tun data configuration
 	 */
-	dtls_tun_data->nl_rule = nl_rule;
+	tun->nl_rule = nl_rule;
+	dev_put(dev);
 	return 0;
 }
 
 /*
- * nss_nldtls_construct_ipv4_udp_header()
- *	Creates an ipv4 + udp packet
- */
-static struct sk_buff *nss_nldtls_construct_ipv4_udp_header(struct net_device *dev, struct nss_nldtls_rule *nl_rule)
-{
-	struct nss_nldtls_tun_ctx *tun_data;
-	struct nss_nldtls_rule *dtls_rule;
-	uint16_t hroom, troom;
-	struct sk_buff *skb;
-	struct udphdr *uh;
-	struct iphdr *iph;
-
-	/*
-	 * Get the tun data
-	 */
-	tun_data = nss_nldtls_find_dtls_tun_gbl_ctx(dev);
-	dtls_rule = tun_data->nl_rule;
-	hroom = dev->needed_headroom;
-	troom = dev->needed_tailroom;
-	skb = dev_alloc_skb(nl_rule->msg.tx_pkts.pkt_sz + hroom + troom);
-	if (!skb) {
-		nss_nl_info("Failed to allocate skb\n");
-		return NULL;
-	}
-
-	skb_reserve(skb, sizeof(struct udphdr) + sizeof(struct iphdr));
-	skb_put(skb, nl_rule->msg.tx_pkts.pkt_sz);
-
-	/*
-	 * Fill the packet with dummy data
-	 */
-	memset(skb->data, NSS_NLDTLS_DUMMY_DATA, skb->len);
-
-	/*
-	 * Fill udp header fields
-	 */
-	skb_push(skb, sizeof(struct udphdr));
-	uh = (struct udphdr *)skb->data;
-	uh->source = htons(dtls_rule->msg.create.encap.sport);
-	uh->dest = htons(dtls_rule->msg.create.encap.dport);
-	uh->len = htons(skb->len);
-	uh->check = 0;
-
-	/*
-	 * Fill IP header fields
-	 */
-	skb_push(skb, sizeof(struct iphdr));
-	iph = (struct iphdr *)skb->data;
-	iph->ihl = 5;
-	iph->version = 4;
-	iph->tot_len = (nl_rule->msg.tx_pkts.pkt_sz + sizeof(struct udphdr) + sizeof(struct iphdr));
-	iph->ttl = dtls_rule->msg.create.encap.ip_ttl;
-	iph->protocol = IPPROTO_UDP;
-	iph->saddr = dtls_rule->msg.create.encap.sip[0];
-	iph->daddr = dtls_rule->msg.create.encap.dip[0];
-
-	/*
-	 * UDP checksum
-	 */
-	uh->check = udp_csum(skb);
-	uh->check = csum_tcpudp_magic(iph->saddr, iph->daddr, skb->len,
-				      IPPROTO_UDP, uh->check);
-
-	if (nl_rule->msg.tx_pkts.log_en) {
-		nss_nl_info("%px: DTLS TX pkt len:%d udp_csum:0x%x\n", skb, skb->len, uh->check);
-	}
-
-	return skb;
-}
-
-/*
- * nss_nldtls_construct_ipv6_udp_header()
- *	Creates an ipv6 + udp packet
+ * nss_nldtls_alloc_pkt()
+ *	Handler for forming ctype packet
  */
-static struct sk_buff *nss_nldtls_construct_ipv6_udp_header(struct net_device *dev, struct nss_nldtls_rule *nl_rule)
+static struct sk_buff *nss_nldtls_alloc_pkt(struct nss_nldtls_rule *nl_rule,
+			struct net_device *dev, uint32_t pkt_sz, uint8_t ctype)
 {
-	struct nss_nldtls_tun_ctx *tun_data;
-	struct nss_nldtls_rule *dtls_rule;
-	uint16_t hroom, troom;
+	struct nss_dtlsmgr_metadata *ndm;
+	uint16_t hdr_len, payload_len;
 	struct sk_buff *skb;
-	struct udphdr *uh;
-	struct ipv6hdr *ip6h;
 
-	/*
-	 * Get the tun data
-	 */
-	tun_data = nss_nldtls_find_dtls_tun_gbl_ctx(dev);
-	dtls_rule = tun_data->nl_rule;
-	hroom = dev->needed_headroom;
-	troom = dev->needed_tailroom;
-	skb = dev_alloc_skb(nl_rule->msg.tx_pkts.pkt_sz + hroom + troom);
+	hdr_len = dev->needed_headroom + sizeof(*ndm);
+	payload_len = hdr_len + dev->needed_tailroom + pkt_sz;
+	skb = netdev_alloc_skb(dev, payload_len);
 	if (!skb) {
-		nss_nl_info("Failed to allocate skb\n");
 		return NULL;
 	}
 
-	skb_reserve(skb, sizeof(struct udphdr) + sizeof(struct iphdr));
-	skb_put(skb, nl_rule->msg.tx_pkts.pkt_sz);
+	skb_reserve(skb, hdr_len);
 
 	/*
 	 * Fill the packet with dummy data
 	 */
-	memset(skb->data, NSS_NLDTLS_DUMMY_DATA, skb->len);
-
-	/*
-	 * Fill udp header fields
-	 */
-	skb_push(skb, sizeof(struct udphdr));
-	uh = (struct udphdr *)skb->data;
-	uh->source = htons(dtls_rule->msg.create.encap.sport);
-	uh->dest = htons(dtls_rule->msg.create.encap.dport);
-	uh->len = htons(skb->len);
-	uh->check = 0;
+	memset(skb_put(skb, pkt_sz), NSS_NLDTLS_DUMMY_DATA, skb->len);
 
-	/*
-	 * Fill IP header fields
-	 */
-	skb_push(skb, sizeof(struct ipv6hdr));
-	ip6h = (struct ipv6hdr *)skb->data;
-	ip6h->version = 6;
-	ip6h->payload_len = htons(nl_rule->msg.tx_pkts.pkt_sz + sizeof(struct udphdr));
-	ip6h->hop_limit = 64;
-	ip6h->nexthdr = IPPROTO_UDP;
-	ip6h->saddr.in6_u.u6_addr32[0] = htonl(dtls_rule->msg.create.encap.sip[0]);
-	ip6h->saddr.in6_u.u6_addr32[1] = htonl(dtls_rule->msg.create.encap.sip[1]);
-	ip6h->saddr.in6_u.u6_addr32[2] = htonl(dtls_rule->msg.create.encap.sip[2]);
-	ip6h->saddr.in6_u.u6_addr32[3] = htonl(dtls_rule->msg.create.encap.sip[3]);
+	ndm = nss_dtlsmgr_metadata_init(skb);
+	nss_dtlsmgr_metadata_set_seq(ndm, nl_rule->msg.tx_pkts.seq_num);
+	nss_dtlsmgr_metadata_set_ctype(ndm, ctype);
 
-	ip6h->saddr.in6_u.u6_addr32[0] = htonl(dtls_rule->msg.create.encap.dip[0]);
-	ip6h->saddr.in6_u.u6_addr32[1] = htonl(dtls_rule->msg.create.encap.dip[1]);
-	ip6h->saddr.in6_u.u6_addr32[2] = htonl(dtls_rule->msg.create.encap.dip[2]);
-	ip6h->saddr.in6_u.u6_addr32[3] = htonl(dtls_rule->msg.create.encap.dip[3]);
-
-	skb_set_transport_header(skb, sizeof(struct ipv6hdr));
-	/*
-	 * UDP checksum
-	 */
-	udp6_set_csum(false, skb, &ip6h->saddr, &ip6h->daddr, nl_rule->msg.tx_pkts.pkt_sz + sizeof(struct udphdr));
-
-	if (nl_rule->msg.tx_pkts.log_en) {
-		nss_nl_info("%px: DTLS TX pkt len:%d udp_csum:0x%x\n", skb, skb->len, uh->check);
+	if (unlikely(nl_rule->msg.tx_pkts.log_en)) {
+		nss_nl_info("%px DTLS TX pkt len:%u\n", skb, skb->len);
 	}
 
 	return skb;
 }
 
 /*
- * nss_nldtls_tx_ipv4_pkts_host_to_host()
- *	Handler for sending ipv4 traffic from one host to other
- */
-static bool nss_nldtls_tx_ipv4_pkts_host_to_host(struct nss_nldtls_rule *nl_rule, struct net_device *dtls_dev)
-{
-	int i;
-	for (i = 0; i < nl_rule->msg.tx_pkts.num_pkts; i++) {
-		struct sk_buff *skb;
-
-		skb = nss_nldtls_construct_ipv4_udp_header(dtls_dev, nl_rule);
-		if (!skb) {
-			nss_nl_error("%px: Unable to create ipv4 + udp packet\n", dtls_dev);
-			return false;
-		}
-
-		dtls_dev->netdev_ops->ndo_start_xmit(skb, dtls_dev);
-	}
-
-	return true;
-}
-
-/*
- * nss_nldtls_tx_ipv6_pkts_host_to_host()
- *	Handler for sending ipv6 traffic from one host to other
- */
-static bool nss_nldtls_tx_ipv6_pkts_host_to_host(struct nss_nldtls_rule *nl_rule, struct net_device *dtls_dev)
-{
-	int i;
-	for (i = 0; i < nl_rule->msg.tx_pkts.num_pkts; i++) {
-		struct sk_buff *skb;
-
-		skb = nss_nldtls_construct_ipv6_udp_header(dtls_dev, nl_rule);
-		if (!skb) {
-			nss_nl_error("%px: Unable to create ipv4 + udp packet\n", dtls_dev);
-			return false;
-		}
-
-		dtls_dev->netdev_ops->ndo_start_xmit(skb, dtls_dev);
-	}
-
-	return true;
-}
-
-/*
  * nss_nldtls_ops_tx_pkts()
  *	Handler for sending traffic
  */
 static int nss_nldtls_ops_tx_pkts(struct sk_buff *skb, struct genl_info *info)
 {
-	struct nss_nldtls_tun_ctx *dtls_tun_data;
 	struct nss_nldtls_rule *nl_rule;
-	struct net_device *dtls_ndev;
+	struct nss_nldtls_tun_ctx *tun;
+	struct nss_nldtls_stats *stats;
 	unsigned long long duration;
 	struct nss_nlcmn *nl_cm;
+	struct net_device *dev;
+	struct sk_buff *tx_skb;
+	uint32_t num_pkts;
+	uint32_t pkt_sz;
+	uint32_t count;
 	ktime_t delta;
+	uint8_t ctype;
 
 	/*
 	 * extract the message payload
@@ -1046,56 +988,149 @@ static int nss_nldtls_ops_tx_pkts(struct
 	 */
 	nl_rule = container_of(nl_cm, struct nss_nldtls_rule, cm);
 
-	dtls_ndev = dev_get_by_name(&init_net, nl_rule->msg.tx_pkts.dev_name);
-	if (!dtls_ndev) {
-		nss_nl_error("%px: Unable to find dev: %s\n", skb, nl_rule->msg.tx_pkts.dev_name);
+	ctype = nl_rule->msg.tx_pkts.ctype;
+	num_pkts = nl_rule->msg.tx_pkts.num_pkts;
+
+	switch (ctype) {
+	case NSS_DTLSMGR_METADATA_CTYPE_CCS:
+		pkt_sz = NSS_NLDTLS_CCS_PKT_SZ;
+		break;
+
+	case NSS_DTLSMGR_METADATA_CTYPE_ALERT:
+		pkt_sz = NSS_NLDTLS_ALERT_PKT_SZ;
+		break;
+
+	case NSS_DTLSMGR_METADATA_CTYPE_HANDSHAKE:
+		pkt_sz = NSS_NLDTLS_HANDSHAKE_PKT_SZ;
+		break;
+
+	case NSS_DTLSMGR_METADATA_CTYPE_APP:
+		pkt_sz = nl_rule->msg.tx_pkts.pkt_sz;
+		break;
+
+	default:
 		return -EINVAL;
 	}
 
-	dtls_tun_data = nss_nldtls_find_dtls_tun_gbl_ctx(dtls_ndev);
-	if (!dtls_tun_data) {
-		nss_nl_error("%px: Unable to find context of the tunnel: %s\n", skb, dtls_ndev->name);
-		dev_put(dtls_ndev);
-		return -EAGAIN;
+	dev = dev_get_by_name(&init_net, nl_rule->msg.tx_pkts.dev_name);
+	if (!dev) {
+		nss_nl_error("%px Unable to find dev: %s\n", skb, nl_rule->msg.tx_pkts.dev_name);
+		return -EINVAL;
+	}
+
+	tun = nss_nldtls_find_tun_ctx(dev);
+	if (!tun) {
+		nss_nl_error("%px Unable to find context of the tunnel: %s\n", skb, dev->name);
+		dev_put(dev);
+		return -EINVAL;
 	}
 
 	spin_lock(&gbl_ctx.lock);
 	gbl_ctx.log_en = nl_rule->msg.tx_pkts.log_en;
 	spin_unlock(&gbl_ctx.lock);
 
-	/*
-	 * Send traffic from host to host
-	 */
 	gbl_ctx.first_tx_pkt_time = ktime_get();
-	if (nl_rule->msg.tx_pkts.ip_version == NSS_NLDTLS_IP_VERS_4) {
-		if (!nss_nldtls_tx_ipv4_pkts_host_to_host(nl_rule, dtls_ndev)) {
-			nss_nl_error("%px: Error in transmission\n", skb);
-			return -EAGAIN;
-		}
-	} else {
-		if (!nss_nldtls_tx_ipv6_pkts_host_to_host(nl_rule, dtls_ndev)) {
-			nss_nl_error("%px: Error in transmission\n", skb);
-			return -EAGAIN;
+
+	for (count = 0; count < num_pkts; count++) {
+		tx_skb = nss_nldtls_alloc_pkt(nl_rule, dev, pkt_sz, ctype);
+		if (!tx_skb) {
+			nss_nl_error("%px Failed to allocate skb\n", dev);
+			break;
 		}
+
+		dev->netdev_ops->ndo_start_xmit(tx_skb, dev);
+	}
+
+	stats = &tun->stats[NSS_NLDTLS_CTYPE_TO_IDX(ctype)];
+	spin_lock(&gbl_ctx.lock);
+	stats->tx_pkts += count;
+	stats->tx_bytes += (count * pkt_sz);
+	spin_unlock(&gbl_ctx.lock);
+	dev_put(dev);
+
+	if (count != num_pkts) {
+		nss_nl_error("%px Error in transmission\n", skb);
+		return -EAGAIN;
 	}
 
 	gbl_ctx.last_tx_pkt_time = ktime_get();
 	delta = ktime_sub(gbl_ctx.last_tx_pkt_time, gbl_ctx.first_tx_pkt_time);
 	duration = (unsigned long long) ktime_to_ns(delta) >> 10;
-	nss_nl_info("%px: Packets sent in %llu usecs", dtls_ndev, duration);
-	nss_nl_info("%px: Traffic transmission successful\n", skb);
+	nss_nl_info("%px Packets sent in %llu usecs", dev, duration);
+	nss_nl_info("%px Traffic transmission successful\n", skb);
 	return 0;
 }
 
 /*
- * nss_nldtls_cmd_ops
- *	Operation table called by the generic netlink layer based on the command
+ * nss_nldtls_tunnel_stats_read()
+ *	reads the per tunnel tx and rx packets stats for every ctypes
  */
-struct genl_ops nss_nldtls_cmd_ops[] = {
-	{.cmd = NSS_NLDTLS_CMD_TYPE_CREATE_TUN, .doit = nss_nldtls_ops_create_tun,},
-	{.cmd = NSS_NLDTLS_CMD_TYPE_DESTROY_TUN, .doit = nss_nldtls_ops_destroy_tun,},
-	{.cmd = NSS_NLDTLS_CMD_TYPE_UPDATE_CONFIG, .doit = nss_nldtls_ops_update_config,},
-	{.cmd = NSS_NLDTLS_CMD_TYPE_TX_PKTS, .doit = nss_nldtls_ops_tx_pkts,},
+static ssize_t nss_nldtls_tunnel_stats_read(struct file *fp, char __user *ubuf, size_t sz, loff_t *f_ppos)
+{
+	struct nss_nldtls_stats stats[NSS_NLDTLS_CTYPE_MAX];
+	struct nss_nldtls_tun_ctx *entry;
+	uint32_t max_output_lines;
+	char dev_name[IFNAMSIZ];
+	ssize_t bytes_read = 0;
+	ssize_t size_wr = 0;
+	ssize_t size_al;
+	char *lbuf;
+
+	max_output_lines = 2 + (NSS_NLDTLS_MAX_TUNNELS * NSS_NLDTLS_STATS_MAX_ROW);
+	size_al = NSS_NLDTLS_STATS_MAX_STR_LEN * max_output_lines;
+
+	lbuf = vzalloc(size_al);
+
+	if (!lbuf) {
+		nss_nl_error("%px Could not allocate buffer for debug entry\n", f_ppos);
+		return 0;
+	}
+
+	size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\nDTLS netlink ctype stats:\n");
+	list_for_each_entry(entry, &gbl_ctx.dtls_list_head, list) {
+		spin_lock_bh(&gbl_ctx.lock);
+		memcpy(&stats, &entry->stats, sizeof(stats));
+		strlcpy(dev_name, entry->dev_name, IFNAMSIZ);
+		spin_unlock_bh(&gbl_ctx.lock);
+
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n--------------------------------");
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n%s:\t %s", "dev", dev_name);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n change_cipher_spec");
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_pkts", stats[0].tx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_bytes", stats[0].tx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_pkts", stats[0].rx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_bytes", stats[0].rx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n alert");
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_pkts", stats[1].tx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_bytes", stats[1].tx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_pkts", stats[1].rx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_bytes", stats[1].rx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n handshake");
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_pkts", stats[2].tx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_bytes", stats[2].tx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_pkts", stats[2].rx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_bytes", stats[2].rx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n app_data");
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_pkts", stats[3].tx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "tx_bytes", stats[3].tx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_pkts", stats[3].rx_pkts);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n\t%s:\t %llu", "rx_bytes", stats[3].rx_bytes);
+		size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\n--------------------------------\n");
+	}
+
+	size_wr += scnprintf(lbuf + size_wr, size_al - size_wr, "\nDTLS netlink ctype stats end\n\n");
+	bytes_read = simple_read_from_buffer(ubuf, sz, f_ppos, lbuf, size_wr);
+
+	vfree(lbuf);
+	return bytes_read;
+}
+
+/*
+ * nss_nldtls_stats_ops()
+ *	file operation handler for dentry
+ */
+static const struct file_operations nss_nldtls_stats_ops = {
+	.read = nss_nldtls_tunnel_stats_read,
 };
 
 /*
@@ -1111,14 +1146,35 @@ bool nss_nldtls_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	err = genl_register_family_with_ops_groups(&nss_nldtls_family, nss_nldtls_cmd_ops, nss_nldtls_family_mcgrp);
+	err = genl_register_family(&nss_nldtls_family);
 	if (err) {
 		nss_nl_info_always("Error: %d unable to register gre_redir family\n", err);
 		genl_unregister_family(&nss_nldtls_family);
 		return false;
 	}
 
+	/*
+	 * Create a debugfs entry for netlink dtls
+	 */
+	gbl_ctx.dentry = debugfs_create_dir("nldtls", NULL);
+	if (!gbl_ctx.dentry) {
+		nss_nl_info_always("Cannot create nldtls directory\n");
+		goto free_family;
+	}
+
+	if (!debugfs_create_file("stats", 0400, gbl_ctx.dentry, NULL, &nss_nldtls_stats_ops)) {
+		nss_nl_info_always("Cannot create nldtls dentry file\n");
+		goto free_debugfs;
+	}
+
 	return true;
+
+free_debugfs:
+	debugfs_remove_recursive(gbl_ctx.dentry);
+free_family:
+	genl_unregister_family(&nss_nldtls_family);
+
+	return false;
 }
 
 /*
@@ -1128,7 +1184,7 @@ bool nss_nldtls_init(void)
 bool nss_nldtls_exit(void)
 {
 	struct nss_nldtls_tun_ctx *entry, *tmp;
-	struct net_device *dtls_ndev;
+	struct net_device *dev;
 	int err;
 
 	nss_nl_info_always("Exit NSS netlink dtls handler\n");
@@ -1137,9 +1193,10 @@ bool nss_nldtls_exit(void)
 	 * Destroy all active tunnel before exiting
 	 */
 	list_for_each_entry_safe(entry, tmp, &gbl_ctx.dtls_list_head, list) {
-		dtls_ndev = dev_get_by_name(&init_net, entry->dev_name);
-		if (dtls_ndev) {
-			nss_nldtls_destroy_tun(dtls_ndev);
+		dev = dev_get_by_name(&init_net, entry->dev_name);
+		if (dev) {
+			dev_put(dev);
+			nss_nldtls_destroy_tun(dev);
 		}
 	}
 
--- a/netlink/nss_nldtls.h
+++ b/netlink/nss_nldtls.h
@@ -27,6 +27,27 @@
 #define NSS_NLDTLS_VLAN_INVALID 0xFFF
 #define NSS_NLDTLS_IP_VERS_4 4
 #define NSS_NLDTLS_DUMMY_DATA 0xcc
+#define NSS_NLDTLS_STATS_MAX_ROW 23
+#define NSS_NLDTLS_STATS_MAX_STR_LEN 35
+
+#define NSS_NLDTLS_CTYPE_MAX 4
+#define NSS_NLDTLS_CTYPE_BASE	NSS_DTLSMGR_METADATA_CTYPE_CCS
+#define NSS_NLDTLS_CTYPE_TO_IDX(ctype)	((ctype) - NSS_NLDTLS_CTYPE_BASE)
+
+#define NSS_NLDTLS_CCS_PKT_SZ 1
+#define NSS_NLDTLS_ALERT_PKT_SZ 2
+#define NSS_NLDTLS_HANDSHAKE_PKT_SZ 56
+
+/*
+ * nss_dtls_stats
+ *	netlink DTLS TX and RX statistics
+ */
+struct nss_nldtls_stats {
+	uint64_t rx_pkts;
+	uint64_t rx_bytes;
+	uint64_t tx_pkts;
+	uint64_t tx_bytes;
+};
 
 /*
  * nss_nldtls_tun_ctx
@@ -36,6 +57,8 @@ struct nss_nldtls_tun_ctx {
 	struct list_head list;			/**< List for holding different tunnel info */
 	struct nss_nldtls_rule *nl_rule;	/**< Dtls rule structure */
 	char dev_name[IFNAMSIZ];		/**< Dtls session netdev */
+	struct nss_nldtls_stats stats[NSS_NLDTLS_CTYPE_MAX];
+						/**< Dtls stats */
 };
 
 /*
@@ -51,6 +74,7 @@ struct nss_nldtls_gbl_ctx {
 	ktime_t first_tx_pkt_time;
 	ktime_t last_rx_pkt_time;
 	ktime_t last_tx_pkt_time;
+	struct dentry *dentry;
 };
 
 #if (CONFIG_NSS_NLDTLS == 1)
--- a/netlink/nss_nldynamic_interface.c
+++ b/netlink/nss_nldynamic_interface.c
@@ -46,20 +46,6 @@ static int nss_nldynamic_interface_ops_g
 static int nss_nldynamic_interface_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * dynamic interface family definition
- */
-static struct genl_family nss_nldynamic_interface_family = {
-	.id = GENL_ID_GENERATE,					/* Auto generate ID */
-	.name = NSS_NLDYNAMIC_INTERFACE_FAMILY,			/* family name string */
-	.hdrsize = sizeof(struct nss_dynamic_interface_notification),	/* NSS NETLINK dynamic interface information */
-	.version = NSS_NL_VER,					/* Set it to NSS_NLDYNAMIC_INTERFACE version */
-	.maxattr = NSS_STATS_EVENT_MAX,				/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nldynamic_interface_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nldynamic_int
 };
 
 /*
+ * dynamic interface family definition
+ */
+static struct genl_family nss_nldynamic_interface_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,					/* Auto generate ID */
+#endif
+	.name = NSS_NLDYNAMIC_INTERFACE_FAMILY,			/* family name string */
+	.hdrsize = sizeof(struct nss_dynamic_interface_notification),	/* NSS NETLINK dynamic interface information */
+	.version = NSS_NL_VER,					/* Set it to NSS_NLDYNAMIC_INTERFACE version */
+	.maxattr = NSS_STATS_EVENT_MAX,				/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nldynamic_interface_ops,
+	.n_ops = ARRAY_SIZE(nss_nldynamic_interface_ops),
+	.mcgrps = nss_nldynamic_interface_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nldynamic_interface_mcgrp)
+};
+
+/*
  * destroy interface call back handler for dynamic interface from NSS
  */
 static struct notifier_block nss_dynamic_interface_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nldynamic_interface_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nldynamic_interface_family, nss_nldynamic_interface_ops, nss_nldynamic_interface_mcgrp);
+	error = genl_register_family(&nss_nldynamic_interface_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register dynamic_interface family\n");
 		return false;
--- a/netlink/nss_nledma.c
+++ b/netlink/nss_nledma.c
@@ -45,20 +45,6 @@ static int nss_nledma_ops_get_stats(stru
 static int nss_nledma_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * Edma family definition
- */
-static struct genl_family nss_nledma_family = {
-	.id = GENL_ID_GENERATE,				/* Auto generate ID */
-	.name = NSS_NLEDMA_FAMILY,			/* family name string */
-	.hdrsize = sizeof(struct nss_nledma_stats),	/* NSS NETLINK Edma stats */
-	.version = NSS_NL_VER,				/* Set it to NSS_NLEDMA version */
-	.maxattr = NSS_STATS_EVENT_MAX,			/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nledma_mcgrp[] = {
@@ -73,6 +59,26 @@ static struct genl_ops nss_nledma_ops[]
 };
 
 /*
+ * Edma family definition
+ */
+static struct genl_family nss_nledma_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,				/* Auto generate ID */
+#endif
+	.name = NSS_NLEDMA_FAMILY,			/* family name string */
+	.hdrsize = sizeof(struct nss_nledma_stats),	/* NSS NETLINK Edma stats */
+	.version = NSS_NL_VER,				/* Set it to NSS_NLEDMA version */
+	.maxattr = NSS_STATS_EVENT_MAX,			/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nledma_ops,
+	.n_ops = ARRAY_SIZE(nss_nledma_ops),
+	.mcgrps = nss_nledma_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nledma_mcgrp)
+};
+
+/*
  * statistics call back handler for edma from NSS
  */
 static struct notifier_block nss_edma_stats_notifier_nb = {
@@ -130,7 +136,7 @@ bool nss_nledma_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nledma_family, nss_nledma_ops, nss_nledma_mcgrp);
+	error = genl_register_family(&nss_nledma_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register Edma family\n");
 		return false;
--- a/netlink/nss_nlethrx.c
+++ b/netlink/nss_nlethrx.c
@@ -46,20 +46,6 @@ static int nss_nlethrx_ops_get_stats(str
 static int nss_nlethrx_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * eth_rx family definition
- */
-static struct genl_family nss_nlethrx_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLETHRX_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_eth_rx_stats_notification),	/* NSS NETLINK eth_rx rule */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLETHRX version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlethrx_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nlethrx_ops[]
 };
 
 /*
+ * eth_rx family definition
+ */
+static struct genl_family nss_nlethrx_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLETHRX_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_eth_rx_stats_notification),	/* NSS NETLINK eth_rx rule */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLETHRX version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlethrx_ops,
+	.n_ops = ARRAY_SIZE(nss_nlethrx_ops),
+	.mcgrps = nss_nlethrx_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlethrx_mcgrp)
+};
+
+/*
  * statistics call back handler for eth_rx from NSS
  */
 static struct notifier_block nss_eth_rx_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nlethrx_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlethrx_family, nss_nlethrx_ops, nss_nlethrx_mcgrp);
+	error = genl_register_family(&nss_nlethrx_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register eth_rx family\n");
 		return false;
--- a/netlink/nss_nlgre_redir_cmd.c
+++ b/netlink/nss_nlgre_redir_cmd.c
@@ -43,11 +43,46 @@ static DEFINE_SPINLOCK(lock);
 static enum nss_nlgre_redir_cmd_deploy_mode deploy_mode;
 
 /*
+ * prototypes
+ */
+static int nss_nlgre_redir_cmd_ops_tun_create(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlgre_redir_cmd_ops_tun_destroy(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlgre_redir_cmd_ops_map(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlgre_redir_cmd_ops_unmap(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlgre_redir_cmd_ops_set_next(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlgre_redir_cmd_ops_add_hash(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlgre_redir_cmd_ops_del_hash(struct sk_buff *skb, struct genl_info *info);
+
+/*
+ * nss_nlgre_redir_cmd_mcgrp
+ *	Multicast group for sending message status & events
+ */
+static const struct genl_multicast_group nss_nlgre_redir_family_mcgrp[] = {
+         {.name = NSS_NLGRE_REDIR_MCAST_GRP},
+};
+
+/*
+ * nss_nlgre_redir_ops
+ * 	Operation table called by the generic netlink layer based on the command
+ */
+static struct genl_ops nss_nlgre_redir_ops[] = {
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_CREATE_TUN, .doit = nss_nlgre_redir_cmd_ops_tun_create,},
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_DESTROY_TUN, .doit = nss_nlgre_redir_cmd_ops_tun_destroy,},
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_MAP, .doit = nss_nlgre_redir_cmd_ops_map,},
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_UNMAP, .doit = nss_nlgre_redir_cmd_ops_unmap,},
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_SET_NEXT_HOP, .doit = nss_nlgre_redir_cmd_ops_set_next,},
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_ADD_HASH, .doit = nss_nlgre_redir_cmd_ops_add_hash,},
+	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_DEL_HASH, .doit = nss_nlgre_redir_cmd_ops_del_hash,},
+};
+
+/*
  * nss_nlgre_redir_cmd_family
  * 	Gre_redir family definition
  */
 struct genl_family nss_nlgre_redir_cmd_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
 	.id = GENL_ID_GENERATE,				/* Auto generate ID */
+#endif
 	.name = NSS_NLGRE_REDIR_FAMILY,			/* family name string */
 	.hdrsize = sizeof(struct nss_nlgre_redir_rule),	/* NSS NETLINK gre_redir rule */
 	.version = NSS_NL_VER,				/* Set it to NSS_NLGRE_REDIR version */
@@ -55,6 +90,10 @@ struct genl_family nss_nlgre_redir_cmd_f
 	.netnsok = true,
 	.pre_doit = NULL,
 	.post_doit = NULL,
+	.ops = nss_nlgre_redir_ops,
+	.n_ops = ARRAY_SIZE(nss_nlgre_redir_ops),
+	.mcgrps = nss_nlgre_redir_family_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlgre_redir_family_mcgrp)
 };
 
 /*
@@ -134,7 +173,7 @@ done:
 }
 
 /*
- * nss_nlgre_redir_cmd_ops_destroy_tun()
+ * nss_nlgre_redir_cmd_ops_tun_destroy()
  * 	Handler to destroy tunnel
  */
 static int nss_nlgre_redir_cmd_ops_tun_destroy(struct sk_buff *skb, struct genl_info *info)
@@ -287,7 +326,7 @@ static int nss_nlgre_redir_cmd_ops_unmap
 }
 
 /*
- * nss_nlgre_redir_cmd_set_next()
+ * nss_nlgre_redir_cmd_ops_set_next()
  * 	Handler for set_next command
  */
 static int nss_nlgre_redir_cmd_ops_set_next(struct sk_buff *skb, struct genl_info *info)
@@ -340,7 +379,7 @@ done:
 }
 
 /*
- * nss_nlgre_redir_cmd_add_hash()
+ * nss_nlgre_redir_cmd_ops_add_hash()
  * 	Handler for adding hash a value
  */
 static int nss_nlgre_redir_cmd_ops_add_hash(struct sk_buff *skb, struct genl_info *info)
@@ -373,7 +412,7 @@ static int nss_nlgre_redir_cmd_ops_add_h
 }
 
 /*
- * nss_nlgre_redir_cmd_del_hash()
+ * nss_nlgre_redir_cmd_ops_del_hash()
  * 	Handler for deleting a hash value
  */
 static int nss_nlgre_redir_cmd_ops_del_hash(struct sk_buff *skb, struct genl_info *info)
@@ -410,20 +449,6 @@ static int nss_nlgre_redir_cmd_ops_del_h
 }
 
 /*
- * nss_nlgre_redir_cmd_ops
- * 	Operation table called by the generic netlink layer based on the command
- */
-struct genl_ops nss_nlgre_redir_cmd_ops[] = {
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_CREATE_TUN, .doit = nss_nlgre_redir_cmd_ops_tun_create,},
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_DESTROY_TUN, .doit = nss_nlgre_redir_cmd_ops_tun_destroy,},
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_MAP, .doit = nss_nlgre_redir_cmd_ops_map,},
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_UNMAP, .doit = nss_nlgre_redir_cmd_ops_unmap,},
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_SET_NEXT_HOP, .doit = nss_nlgre_redir_cmd_ops_set_next,},
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_ADD_HASH, .doit = nss_nlgre_redir_cmd_ops_add_hash,},
-	{.cmd = NSS_NLGRE_REDIR_CMD_TYPE_DEL_HASH, .doit = nss_nlgre_redir_cmd_ops_del_hash,},
-};
-
-/*
  * nss_nlgre_redir_cmd_get_ifnum()
  * 	Get the interface number corresponding to netdev
  */
--- a/netlink/nss_nlgre_redir_cmd.h
+++ b/netlink/nss_nlgre_redir_cmd.h
@@ -38,11 +38,6 @@ enum nss_nlgre_redir_cmd_deploy_mode {
 extern struct genl_family nss_nlgre_redir_cmd_family;
 
 /*
- * Gre_redir generic netlink operations
- */
-extern struct genl_ops nss_nlgre_redir_cmd_ops[NSS_NLGRE_REDIR_CMD_MAX];
-
-/*
  * nss_nlgre_redir_cmd_get_ifnum()
  * 	Get the interface number corresponding to netdev
  */
--- a/netlink/nss_nlgre_redir_cmn.c
+++ b/netlink/nss_nlgre_redir_cmn.c
@@ -354,6 +354,24 @@ static struct rtnl_link_stats64 *nss_nlg
 }
 
 /*
+ * nss_nlgre_redir_cmn_dev_stats64
+ *	Report packet statistics to linux
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 11, 0))
+static struct rtnl_link_stats64 *nss_nlgre_redir_cmn_dev_stats64(struct net_device *dev,
+		struct rtnl_link_stats64 *stats)
+{
+	return nss_nlgre_redir_cmn_get_stats64(dev, stats);
+}
+#else
+static void nss_nlgre_redir_cmn_dev_stats64(struct net_device *dev,
+		struct rtnl_link_stats64 *stats)
+{
+	nss_nlgre_redir_cmn_get_stats64(dev, stats);
+}
+#endif
+
+/*
  * nss_nlgre_redir_cmn_set_mac_address()
  * 	Sets the mac address of netdev
  */
@@ -389,7 +407,11 @@ static void nss_nlgre_redir_cmn_dev_setu
 	ether_setup(dev);
 	dev->needed_headroom = NSS_NLGRE_REDIR_CMN_NEEDED_HEADROOM;
 	dev->netdev_ops = &gre_redir_netdev_ops;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 11, 0))
 	dev->destructor = nss_nlgre_redir_cmn_netdev_destructor;
+#else
+	dev->priv_destructor = nss_nlgre_redir_cmn_netdev_destructor;
+#endif
 	eth_hw_addr_random(dev);
 }
 
@@ -401,7 +423,7 @@ static const struct net_device_ops gre_r
 	.ndo_open = nss_nlgre_redir_cmn_open_interface,
 	.ndo_stop = nss_nlgre_redir_cmn_close_interface,
 	.ndo_start_xmit = nss_nlgre_redir_cmn_xmit_data,
-	.ndo_get_stats64 = nss_nlgre_redir_cmn_get_stats64,
+	.ndo_get_stats64 = nss_nlgre_redir_cmn_dev_stats64,
 	.ndo_set_mac_address = nss_nlgre_redir_cmn_set_mac_address,
 };
 
--- a/netlink/nss_nlgre_redir_family.c
+++ b/netlink/nss_nlgre_redir_family.c
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2015-2016,2018-2019, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2015-2016,2018-2020, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -28,14 +28,6 @@
 #include "nss_nlgre_redir_cmd.h"
 
 /*
- * nss_nlgre_redir_cmd_mcgrp
- * 	Multicast group for sending message status & events
- */
-static const struct genl_multicast_group nss_nlgre_redir_family_mcgrp[] = {
-	{.name = NSS_NLGRE_REDIR_MCAST_GRP},
-};
-
-/*
  * nss_nlgre_redir_family_init()
  * 	handler init
  */
@@ -47,7 +39,7 @@ bool nss_nlgre_redir_family_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	err = genl_register_family_with_ops_groups(&nss_nlgre_redir_cmd_family, nss_nlgre_redir_cmd_ops, nss_nlgre_redir_family_mcgrp);
+	err = genl_register_family(&nss_nlgre_redir_cmd_family);
 	if (err) {
 		nss_nl_info_always("Error: %d unable to register gre_redir family\n", err);
 		return false;
--- a/netlink/nss_nlipsec.c
+++ b/netlink/nss_nlipsec.c
@@ -43,6 +43,16 @@
 #include "nss_nlipv4_if.h"
 
 /*
+ * Function prototypes
+ */
+static int nss_nlipsec_op_create_tunnel(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlipsec_op_destroy_tunnel(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlipsec_op_add_sa(struct sk_buff *skb, struct genl_info *info);
+static int nss_nlipsec_op_delete_sa(struct sk_buff *skb, struct genl_info *info);
+// static int nss_nlipsec_op_add_flow(struct sk_buff *skb, struct genl_info *info);
+// static int nss_nlipsec_op_delete_flow(struct sk_buff *skb, struct genl_info *info);
+
+/*
  * Hold netdevice references
  */
 struct nss_nlipsec_ref {
@@ -72,10 +82,49 @@ struct nss_nlipsec_ctx {
 static struct nss_nlipsec_ctx gbl_ctx;
 
 /*
+ * Multicast group for sending message status & events
+ */
+static const struct genl_multicast_group nss_nlipsec_mcgrp[] = {
+	{.name = NSS_NLIPSEC_MCAST_GRP},
+};
+
+/*
+ * Operation table called by the generic netlink layer based on the command
+ */
+static struct genl_ops nss_nlipsec_ops[] = {
+	{ /* Create tunnel */
+		.cmd = NSS_NLIPSEC_CMD_ADD_TUNNEL,
+		.doit = nss_nlipsec_op_create_tunnel,
+	},
+	{ /* Destroy tunnel */
+		.cmd = NSS_NLIPSEC_CMD_DEL_TUNNEL,
+		.doit = nss_nlipsec_op_destroy_tunnel,
+	},
+	{ /* Add Security Association */
+		.cmd = NSS_NLIPSEC_CMD_ADD_SA,
+		.doit = nss_nlipsec_op_add_sa,
+	},
+	{ /* Delete Security Association */
+		.cmd = NSS_NLIPSEC_CMD_DEL_SA,
+		.doit = nss_nlipsec_op_delete_sa,
+	},
+	// { /* Add flow */
+	// 	.cmd = NSS_NLIPSEC_CMD_ADD_FLOW,
+	// 	.doit = nss_nlipsec_op_add_flow,
+	// },
+	// { /* Delete flow */
+	// 	.cmd = NSS_NLIPSEC_CMD_DEL_FLOW,
+	// 	.doit = nss_nlipsec_op_delete_flow,
+	// },
+};
+
+/*
  * IPsec family definition
  */
 static struct genl_family nss_nlipsec_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
 	.id = GENL_ID_GENERATE,			/* Auto generate ID */
+#endif
 	.name = NSS_NLIPSEC_FAMILY,		/* Family name string */
 	.hdrsize = sizeof(struct nss_nlipsec_rule),/* NSS NETLINK IPsec rule */
 	.version = NSS_NL_VER,			/* Set it to NSS_NL version */
@@ -83,13 +132,10 @@ static struct genl_family nss_nlipsec_fa
 	.netnsok = true,
 	.pre_doit = NULL,
 	.post_doit = NULL,
-};
-
-/*
- * Multicast group for sending message status & events
- */
-static const struct genl_multicast_group nss_nlipsec_mcgrp[] = {
-	{.name = NSS_NLIPSEC_MCAST_GRP},
+	.ops = nss_nlipsec_ops,
+	.n_ops = ARRAY_SIZE(nss_nlipsec_ops),
+	.mcgrps = nss_nlipsec_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlipsec_mcgrp)
 };
 
 /*
@@ -501,7 +547,7 @@ static int nss_nlipsec_op_add_sa(struct
 	sa_data->cmn.keys.auth_key = sa_rule->auth_key;
 	sa_data->cmn.keys.nonce = sa_rule->nonce;
 
-	error = nss_ipsecmgr_sa_add_sync(dev, &sa_rule->tuple, sa_data, &if_num);
+	error = nss_ipsecmgr_sa_add(dev, &sa_rule->tuple, sa_data, &if_num);
 	if (error) {
 		nss_nl_error("%d: Failed to add SA for net device(%s), error:%d\n", pid, nl_rule->ifname, error);
 		goto free_dev;
@@ -579,102 +625,73 @@ static int nss_nlipsec_op_delete_sa(stru
  * nss_nlipsec_op_add_flow()
  *	Add a flow
  */
-static int nss_nlipsec_op_add_flow(struct sk_buff *skb, struct genl_info *info)
-{
-	struct nss_ipsecmgr_flow_tuple *flow_tuple;
-	struct nss_ipsecmgr_sa_tuple *sa_tuple;
-	struct nss_nlipsec_rule *nl_rule;
-	struct net_device *dev;
-	uint32_t pid;
-	int error = 0;
-
-	nl_rule = nss_nlipsec_get_rule(info, NSS_NLIPSEC_CMD_ADD_FLOW, &dev);
-	if (!nl_rule) {
-		nss_nl_error("Failed to extract SA data\n");
-		return -EINVAL;
-	}
-
-	pid = nl_rule->cm.pid;
-	nss_nl_error("%d: device(%s)", pid, dev->name);
-
-	flow_tuple = &nl_rule->rule.flow.tuple;
-	sa_tuple = &nl_rule->rule.flow.sa;
-
-	error = nss_ipsecmgr_flow_add_sync(dev, flow_tuple, sa_tuple);
-	if (error) {
-		nss_nl_error("%d: Failed to add subnet for net_device(%s)", pid, nl_rule->ifname);
-	}
-
-	/*
-	 *  dev_put for dev_get done on nss_nlipsec_get_rule
-	 */
-	dev_put(dev);
-	return error;
-}
+// static int nss_nlipsec_op_add_flow(struct sk_buff *skb, struct genl_info *info)
+// {
+// 	struct nss_ipsecmgr_flow_tuple *flow_tuple;
+// 	struct nss_ipsecmgr_sa_tuple *sa_tuple;
+// 	struct nss_nlipsec_rule *nl_rule;
+// 	struct net_device *dev;
+// 	uint32_t pid;
+// 	int error = 0;
+//
+// 	nl_rule = nss_nlipsec_get_rule(info, NSS_NLIPSEC_CMD_ADD_FLOW, &dev);
+// 	if (!nl_rule) {
+// 		nss_nl_error("Failed to extract SA data\n");
+// 		return -EINVAL;
+// 	}
+//
+// 	pid = nl_rule->cm.pid;
+// 	nss_nl_error("%d: device(%s)", pid, dev->name);
+//
+// 	flow_tuple = &nl_rule->rule.flow.tuple;
+// 	sa_tuple = &nl_rule->rule.flow.sa;
+//
+// 	//struct nss_ipsecmgr_ref *nss_ipsecmgr_flow_alloc(struct nss_ipsecmgr_priv *priv, struct nss_ipsecmgr_key *key)
+// 	error = nss_ipsecmgr_flow_add_sync(dev, flow_tuple, sa_tuple);
+// 	if (error) {
+// 		nss_nl_error("%d: Failed to add subnet for net_device(%s)", pid, nl_rule->ifname);
+// 	}
+//
+// 	/*
+// 	 *  dev_put for dev_get done on nss_nlipsec_get_rule
+// 	 */
+// 	dev_put(dev);
+// 	return error;
+// }
 
 /*
  * nss_nlipsec_op_delete_flow()
  *	Delete a flow
  */
-static int nss_nlipsec_op_delete_flow(struct sk_buff *skb, struct genl_info *info)
-{
-	struct nss_ipsecmgr_flow_tuple *flow_tuple;
-	struct nss_ipsecmgr_sa_tuple *sa_tuple;
-	struct nss_nlipsec_rule *nl_rule;
-	struct net_device *dev;
-	uint32_t pid;
-	int error = 0;
-
-	nl_rule = nss_nlipsec_get_rule(info, NSS_NLIPSEC_CMD_DEL_FLOW, &dev);
-	if (!nl_rule) {
-		nss_nl_error("Failed to extract SA data\n");
-		return -EINVAL;
-	}
-
-	pid = nl_rule->cm.pid;
-	nss_nl_error("%d: device(%s)", pid, dev->name);
-
-	flow_tuple = &nl_rule->rule.flow.tuple;
-	sa_tuple = &nl_rule->rule.flow.sa;
-
-	nss_ipsecmgr_flow_del(dev, flow_tuple, sa_tuple);
-
-	/*
-	 *  dev_put for dev_get done on nss_nlipsec_get_rule
-	 */
-	dev_put(dev);
-	return error;
-}
-
-/*
- * Operation table called by the generic netlink layer based on the command
- */
-static struct genl_ops nss_nlipsec_ops[] = {
-	{ /* Create tunnel */
-		.cmd = NSS_NLIPSEC_CMD_ADD_TUNNEL,
-		.doit = nss_nlipsec_op_create_tunnel,
-	},
-	{ /* Destroy tunnel */
-		.cmd = NSS_NLIPSEC_CMD_DEL_TUNNEL,
-		.doit = nss_nlipsec_op_destroy_tunnel,
-	},
-	{ /* Add Security Association */
-		.cmd = NSS_NLIPSEC_CMD_ADD_SA,
-		.doit = nss_nlipsec_op_add_sa,
-	},
-	{ /* Delete Security Association */
-		.cmd = NSS_NLIPSEC_CMD_DEL_SA,
-		.doit = nss_nlipsec_op_delete_sa,
-	},
-	{ /* Add flow */
-		.cmd = NSS_NLIPSEC_CMD_ADD_FLOW,
-		.doit = nss_nlipsec_op_add_flow,
-	},
-	{ /* Delete flow */
-		.cmd = NSS_NLIPSEC_CMD_DEL_FLOW,
-		.doit = nss_nlipsec_op_delete_flow,
-	},
-};
+// static int nss_nlipsec_op_delete_flow(struct sk_buff *skb, struct genl_info *info)
+// {
+// 	struct nss_ipsecmgr_flow_tuple *flow_tuple;
+// 	struct nss_ipsecmgr_sa_tuple *sa_tuple;
+// 	struct nss_nlipsec_rule *nl_rule;
+// 	struct net_device *dev;
+// 	uint32_t pid;
+// 	int error = 0;
+//
+// 	nl_rule = nss_nlipsec_get_rule(info, NSS_NLIPSEC_CMD_DEL_FLOW, &dev);
+// 	if (!nl_rule) {
+// 		nss_nl_error("Failed to extract SA data\n");
+// 		return -EINVAL;
+// 	}
+//
+// 	pid = nl_rule->cm.pid;
+// 	nss_nl_error("%d: device(%s)", pid, dev->name);
+//
+// 	flow_tuple = &nl_rule->rule.flow.tuple;
+// 	sa_tuple = &nl_rule->rule.flow.sa;
+//
+// 	nss_ipsecmgr_flow_del(dev, flow_tuple, sa_tuple);
+//
+// 	/*
+// 	 *  dev_put for dev_get done on nss_nlipsec_get_rule
+// 	 */
+// 	dev_put(dev);
+// 	return error;
+// }
 
 /*
  * nss_nlipsec_init()
@@ -700,7 +717,7 @@ bool nss_nlipsec_init(void)
 	/*
 	 * Register with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlipsec_family, nss_nlipsec_ops, nss_nlipsec_mcgrp);
+	error = genl_register_family(&nss_nlipsec_family);
 	if (error != 0) {
 		nss_nl_info_always("Error: unable to register IPsec family\n");
 		return false;
--- a/netlink/nss_nlipv4.c
+++ b/netlink/nss_nlipv4.c
@@ -71,20 +71,6 @@ static int nss_nlipv4_ops_destroy_rule(s
 static int nss_nlipv4_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * IPv4 family definition
- */
-static struct genl_family nss_nlipv4_family = {
-	.id = GENL_ID_GENERATE,				/* Auto generate ID */
-	.name = NSS_NLIPV4_FAMILY,			/* family name string */
-	.hdrsize = sizeof(struct nss_nlipv4_rule),	/* NSS NETLINK IPv4 rule */
-	.version = NSS_NL_VER,				/* Set it to NSS_NLIPv4 version */
-	.maxattr = NSS_IPV4_MAX_MSG_TYPES,		/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlipv4_mcgrp[] = {
@@ -100,6 +86,26 @@ static struct genl_ops nss_nlipv4_ops[]
 };
 
 /*
+ * IPv4 family definition
+ */
+static struct genl_family nss_nlipv4_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,				/* Auto generate ID */
+#endif
+	.name = NSS_NLIPV4_FAMILY,			/* family name string */
+	.hdrsize = sizeof(struct nss_nlipv4_rule),	/* NSS NETLINK IPv4 rule */
+	.version = NSS_NL_VER,				/* Set it to NSS_NLIPv4 version */
+	.maxattr = NSS_IPV4_MAX_MSG_TYPES,		/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlipv4_ops,
+	.n_ops = ARRAY_SIZE(nss_nlipv4_ops),
+	.mcgrps = nss_nlipv4_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlipv4_mcgrp)
+};
+
+/*
  * statistics call back handler for ipv4 from NSS
  */
 static struct notifier_block nss_ipv4_stats_notifier_nb = {
@@ -330,20 +336,6 @@ static int nss_nlipv4_verify_conn_rule(s
 							tuple->return_ident, tuple->flow_ident);
 		break;
 
-	case NSS_NL_IFTYPE_TUNNEL_GRE:
-		/*
-		 * Currently this implementation is only for gre_redir
-		 */
-		conn->flow_interface_num = nss_nlgre_redir_cmd_get_ifnum(flow_dev, tuple->protocol);
-		if (conn->flow_interface_num < 0 ) {
-			nss_nl_error("%px: Failed to get flow interface number (dev:%s, type:%d)\n",
-								flow_dev, flow_dev->name, flow_iftype);
-			return -EINVAL;
-		}
-
-		conn->flow_mtu = nss_nlgre_redir_cmd_get_mtu(flow_dev, NSS_GRE_REDIR_IP_HDR_TYPE_IPV4, conn->flow_interface_num);
-		break;
-
 	case NSS_NL_IFTYPE_VLAN:
 		conn->flow_interface_num = nss_cmn_get_interface_number_by_dev(vlan_dev_real_dev(flow_dev));
 		if (conn->flow_interface_num < 0 ) {
@@ -390,17 +382,6 @@ static int nss_nlipv4_verify_conn_rule(s
 							tuple->return_ident, tuple->flow_ident);
 		break;
 
-	case NSS_NL_IFTYPE_TUNNEL_GRE:
-		conn->return_interface_num = nss_nlgre_redir_cmd_get_ifnum(return_dev, tuple->protocol);
-		if (conn->return_interface_num < 0 ) {
-			nss_nl_error("%px: Failed to get return interface number (dev:%s, type:%d)\n",
-							return_dev, return_dev->name, return_iftype);
-			return -EINVAL;
-		}
-
-		conn->return_mtu = nss_nlgre_redir_cmd_get_mtu(return_dev, NSS_GRE_REDIR_IP_HDR_TYPE_IPV4, conn->return_interface_num);
-		break;
-
 	case NSS_NL_IFTYPE_VLAN:
 		conn->return_interface_num = nss_cmn_get_interface_number_by_dev(vlan_dev_real_dev(return_dev));
 		if (conn->return_interface_num < 0 ) {
@@ -915,7 +896,7 @@ bool nss_nlipv4_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlipv4_family, nss_nlipv4_ops, nss_nlipv4_mcgrp);
+	error = genl_register_family(&nss_nlipv4_family);
 	if (error != 0) {
 		nss_nl_info_always("Error: unable to register IPv4 family\n");
 		return false;
--- a/netlink/nss_nlipv4_reasm.c
+++ b/netlink/nss_nlipv4_reasm.c
@@ -46,20 +46,6 @@ static int nss_nlipv4_reasm_ops_get_stat
 static int nss_nlipv4_reasm_process_notify(struct notifier_block *nb,  unsigned long val, void *data);
 
 /*
- * ipv4_reasm family definition
- */
-static struct genl_family nss_nlipv4_reasm_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLIPV4_REASM_FAMILY,				/* family name string */
-	.hdrsize = sizeof(struct nss_ipv4_reasm_stats_notification),	/* NSS NETLINK ipv4_reasm stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLIPV4_REASM version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlipv4_reasm_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nlipv4_reasm_
 };
 
 /*
+ * ipv4_reasm family definition
+ */
+static struct genl_family nss_nlipv4_reasm_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLIPV4_REASM_FAMILY,				/* family name string */
+	.hdrsize = sizeof(struct nss_ipv4_reasm_stats_notification),	/* NSS NETLINK ipv4_reasm stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLIPV4_REASM version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlipv4_reasm_ops,
+	.n_ops = ARRAY_SIZE(nss_nlipv4_reasm_ops),
+	.mcgrps = nss_nlipv4_reasm_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlipv4_reasm_mcgrp)
+};
+
+/*
  * stats call back handler for ipv4_reasm from NSS
  */
 static struct notifier_block nss_ipv4_reasm_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nlipv4_reasm_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlipv4_reasm_family, nss_nlipv4_reasm_ops, nss_nlipv4_reasm_mcgrp);
+	error = genl_register_family(&nss_nlipv4_reasm_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register ipv4_reasm family\n");
 		return false;
--- a/netlink/nss_nlipv6.c
+++ b/netlink/nss_nlipv6.c
@@ -79,20 +79,6 @@ static int nss_nlipv6_ops_destroy_rule(s
 static int nss_nlipv6_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * IPV6 family definition
- */
-static struct genl_family nss_nlipv6_family = {
-	.id = GENL_ID_GENERATE,				/* Auto generate ID */
-	.name = NSS_NLIPV6_FAMILY,			/* family name string */
-	.hdrsize = sizeof(struct nss_nlipv6_rule),	/* NSS NETLINK IPV6 rule */
-	.version = NSS_NL_VER,				/* Set it to NSS_NLIPV6 version */
-	.maxattr = NSS_IPV6_MAX_MSG_TYPES,		/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static struct genl_multicast_group nss_nlipv6_mcgrp[] = {
@@ -108,6 +94,26 @@ static struct genl_ops nss_nlipv6_ops[]
 };
 
 /*
+ * IPV6 family definition
+ */
+static struct genl_family nss_nlipv6_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,				/* Auto generate ID */
+#endif
+	.name = NSS_NLIPV6_FAMILY,			/* family name string */
+	.hdrsize = sizeof(struct nss_nlipv6_rule),	/* NSS NETLINK IPV6 rule */
+	.version = NSS_NL_VER,				/* Set it to NSS_NLIPV6 version */
+	.maxattr = NSS_IPV6_MAX_MSG_TYPES,		/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlipv6_ops,
+	.n_ops = ARRAY_SIZE(nss_nlipv6_ops),
+	.mcgrps = nss_nlipv6_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlipv6_mcgrp)
+};
+
+/*
  * statistics call back handler for ipv6 from NSS
  */
 static struct notifier_block nss_ipv6_stats_notifier_nb = {
@@ -131,7 +137,11 @@ static struct neighbour *nss_nlipv6_get_
 
 	IPV6_ADDR_TO_IN6_ADDR(daddr, dst_addr);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 17, 0))
 	rt = rt6_lookup(&init_net, &daddr, NULL, 0, 0);
+#else
+	rt = rt6_lookup(&init_net, &daddr, NULL, 0, NULL, 0);
+#endif
 	if (!rt) {
 		return NULL;
 	}
@@ -343,17 +353,6 @@ static int nss_nlipv6_verify_conn_rule(s
 							tuple->return_ident, tuple->flow_ident);
 		break;
 
-	case NSS_NL_IFTYPE_TUNNEL_GRE:
-		conn->flow_interface_num = nss_nlgre_redir_cmd_get_ifnum(flow_dev, tuple->protocol);
-		if (conn->flow_interface_num < 0 ) {
-			nss_nl_error("%px: Failed to get flow interface number (dev:%s, type:%d)\n",
-			flow_dev, flow_dev->name, flow_iftype);
-			return -EINVAL;
-		}
-
-		conn->flow_mtu = nss_nlgre_redir_cmd_get_mtu(flow_dev, NSS_GRE_REDIR_IP_HDR_TYPE_IPV6, conn->flow_interface_num);
-		break;
-
 	case NSS_NL_IFTYPE_VLAN:
 		conn->flow_interface_num = nss_cmn_get_interface_number_by_dev(vlan_dev_real_dev(flow_dev));
 		if (conn->flow_interface_num < 0 ) {
@@ -401,17 +400,6 @@ static int nss_nlipv6_verify_conn_rule(s
 							tuple->return_ident, tuple->flow_ident);
 		break;
 
-	case NSS_NL_IFTYPE_TUNNEL_GRE:
-		conn->return_interface_num = nss_nlgre_redir_cmd_get_ifnum(return_dev, tuple->protocol);
-		if (conn->return_interface_num < 0 ) {
-			nss_nl_error("%px: Failed to get return interface number (dev:%s, type:%d)\n",
-			return_dev, return_dev->name, return_iftype);
-			return -EINVAL;
-		}
-
-		conn->return_mtu = nss_nlgre_redir_cmd_get_mtu(return_dev, NSS_GRE_REDIR_IP_HDR_TYPE_IPV6, conn->return_interface_num);
-		break;
-
 	case NSS_NL_IFTYPE_VLAN:
 		conn->return_interface_num = nss_cmn_get_interface_number_by_dev(vlan_dev_real_dev(return_dev));
 		if (conn->return_interface_num < 0 ) {
@@ -916,7 +904,7 @@ bool nss_nlipv6_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlipv6_family, nss_nlipv6_ops, nss_nlipv6_mcgrp);
+	error = genl_register_family(&nss_nlipv6_family);
 	if (error != 0) {
 		nss_nl_info_always("Error: unable to register IPV6 family\n");
 		return false;
--- a/netlink/nss_nlipv6_reasm.c
+++ b/netlink/nss_nlipv6_reasm.c
@@ -46,20 +46,6 @@ static int nss_nlipv6_reasm_ops_get_stat
 static int nss_nlipv6_reasm_process_notify(struct notifier_block *nb,  unsigned long val, void *data);
 
 /*
- * ipv6_reasm family definition
- */
-static struct genl_family nss_nlipv6_reasm_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLIPV6_REASM_FAMILY,				/* family name string */
-	.hdrsize = sizeof(struct nss_ipv6_reasm_stats_notification),	/* NSS NETLINK ipv6_reasm stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLIPV6_REASM version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlipv6_reasm_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nlipv6_reasm_
 };
 
 /*
+ * ipv6_reasm family definition
+ */
+static struct genl_family nss_nlipv6_reasm_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLIPV6_REASM_FAMILY,				/* family name string */
+	.hdrsize = sizeof(struct nss_ipv6_reasm_stats_notification),	/* NSS NETLINK ipv6_reasm stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLIPV6_REASM version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlipv6_reasm_ops,
+	.n_ops = ARRAY_SIZE(nss_nlipv6_reasm_ops),
+	.mcgrps = nss_nlipv6_reasm_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlipv6_reasm_mcgrp)
+};
+
+/*
  * stats call back handler for ipv6_reasm from NSS
  */
 static struct notifier_block nss_ipv6_reasm_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nlipv6_reasm_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlipv6_reasm_family, nss_nlipv6_reasm_ops, nss_nlipv6_reasm_mcgrp);
+	error = genl_register_family(&nss_nlipv6_reasm_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register ipv6_reasm family\n");
 		return false;
--- a/netlink/nss_nll2tpv2.c
+++ b/netlink/nss_nll2tpv2.c
@@ -47,20 +47,6 @@ static int nss_nll2tpv2_ops_get_stats(st
 static int nss_nll2tpv2_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * l2tpv2 family definition
- */
-static struct genl_family nss_nll2tpv2_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLL2TPV2_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_l2tpv2_stats_notification),	/* NSS NETLINK l2tpv2 stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLL2TPV2 version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nll2tpv2_mcgrp[] = {
@@ -75,6 +61,26 @@ static struct genl_ops nss_nll2tpv2_ops[
 };
 
 /*
+ * l2tpv2 family definition
+ */
+static struct genl_family nss_nll2tpv2_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLL2TPV2_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_l2tpv2_stats_notification),	/* NSS NETLINK l2tpv2 stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLL2TPV2 version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nll2tpv2_ops,
+	.n_ops = ARRAY_SIZE(nss_nll2tpv2_ops),
+	.mcgrps = nss_nll2tpv2_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nll2tpv2_mcgrp)
+};
+
+/*
  * device call back handler for l2tpv2 from NSS
  */
 static struct notifier_block nss_l2tpv2_stats_notifier_nb = {
@@ -126,7 +132,7 @@ bool nss_nll2tpv2_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nll2tpv2_family, nss_nll2tpv2_ops, nss_nll2tpv2_mcgrp);
+	error = genl_register_family(&nss_nll2tpv2_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register l2tpv2 family\n");
 		return false;
--- a/netlink/nss_nllso_rx.c
+++ b/netlink/nss_nllso_rx.c
@@ -47,20 +47,6 @@ static int nss_nllso_rx_ops_get_stats(st
 static int nss_nllso_rx_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * lso_rx family definition
- */
-static struct genl_family nss_nllso_rx_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLLSO_RX_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_lso_rx_stats_notification),	/* NSS NETLINK lso_rx stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLLSO_RX version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nllso_rx_mcgrp[] = {
@@ -75,6 +61,26 @@ static struct genl_ops nss_nllso_rx_ops[
 };
 
 /*
+ * lso_rx family definition
+ */
+static struct genl_family nss_nllso_rx_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLLSO_RX_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_lso_rx_stats_notification),	/* NSS NETLINK lso_rx stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLLSO_RX version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nllso_rx_ops,
+	.n_ops = ARRAY_SIZE(nss_nllso_rx_ops),
+	.mcgrps = nss_nllso_rx_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nllso_rx_mcgrp)
+};
+
+/*
  * device call back handler for lso_rx from NSS
  */
 static struct notifier_block nss_lso_rx_stats_notifier_nb = {
@@ -126,7 +132,7 @@ bool nss_nllso_rx_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nllso_rx_family, nss_nllso_rx_ops, nss_nllso_rx_mcgrp);
+	error = genl_register_family(&nss_nllso_rx_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register lso_rx family\n");
 		return false;
--- a/netlink/nss_nlmap_t.c
+++ b/netlink/nss_nlmap_t.c
@@ -47,20 +47,6 @@ static int nss_nlmap_t_ops_get_stats(str
 static int nss_nlmap_t_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * map_t family definition
- */
-static struct genl_family nss_nlmap_t_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLMAP_T_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_map_t_stats_notification),		/* NSS NETLINK map_t stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLMAP_T version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlmap_t_mcgrp[] = {
@@ -75,6 +61,26 @@ static struct genl_ops nss_nlmap_t_ops[]
 };
 
 /*
+ * map_t family definition
+ */
+static struct genl_family nss_nlmap_t_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLMAP_T_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_map_t_stats_notification),		/* NSS NETLINK map_t stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLMAP_T version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlmap_t_ops,
+	.n_ops = ARRAY_SIZE(nss_nlmap_t_ops),
+	.mcgrps = nss_nlmap_t_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlmap_t_mcgrp)
+};
+
+/*
  * device call back handler for map_t from NSS
  */
 static struct notifier_block nss_map_t_stats_notifier_nb = {
@@ -126,7 +132,7 @@ bool nss_nlmap_t_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlmap_t_family, nss_nlmap_t_ops, nss_nlmap_t_mcgrp);
+	error = genl_register_family(&nss_nlmap_t_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register map_t family\n");
 		return false;
--- a/netlink/nss_nln2h.c
+++ b/netlink/nss_nln2h.c
@@ -46,20 +46,6 @@ static int nss_nln2h_ops_get_stats(struc
 static int nss_nln2h_process_notify(struct notifier_block *nb,  unsigned long val, void *data);
 
 /*
- * n2h family definition
- */
-static struct genl_family nss_nln2h_family = {
-	.id = GENL_ID_GENERATE,					/* Auto generate ID */
-	.name = NSS_NLN2H_FAMILY,				/* family name string */
-	.hdrsize = sizeof(struct nss_n2h_stats_notification),	/* NSS NETLINK n2h stats */
-	.version = NSS_NL_VER,					/* Set it to NSS_NLN2H version */
-	.maxattr = NSS_STATS_EVENT_MAX,				/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nln2h_mcgrp[] = {
@@ -74,6 +60,26 @@ static struct genl_ops nss_nln2h_ops[] =
 };
 
 /*
+ * n2h family definition
+ */
+static struct genl_family nss_nln2h_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,					/* Auto generate ID */
+#endif
+	.name = NSS_NLN2H_FAMILY,				/* family name string */
+	.hdrsize = sizeof(struct nss_n2h_stats_notification),	/* NSS NETLINK n2h stats */
+	.version = NSS_NL_VER,					/* Set it to NSS_NLN2H version */
+	.maxattr = NSS_STATS_EVENT_MAX,				/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nln2h_ops,
+	.n_ops = ARRAY_SIZE(nss_nln2h_ops),
+	.mcgrps = nss_nln2h_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nln2h_mcgrp)
+};
+
+/*
  * stats call back handler for n2h from NSS
  */
 static struct notifier_block nss_n2h_stats_notifier_nb = {
@@ -125,7 +131,7 @@ bool nss_nln2h_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nln2h_family, nss_nln2h_ops, nss_nln2h_mcgrp);
+	error = genl_register_family(&nss_nln2h_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register n2h family\n");
 		return false;
--- a/netlink/nss_nloam.c
+++ b/netlink/nss_nloam.c
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2016,2018, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2016,2018, 2020, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -82,11 +82,25 @@ struct nss_nloam_msg_map global_nloam_ms
 	},
 };
 
+static struct genl_multicast_group nss_nloam_mcgrp[] = {
+	{.name = NSS_NLOAM_MCAST_GRP},
+};
+
+/*
+ * operation table called by the generic netlink layer based on the command
+ */
+static struct genl_ops nss_nloam_ops[] = {
+	{.cmd = NSS_NLOAM_CMD_NONE, .doit = nss_nloam_op_none,},
+	{.cmd = NSS_NLOAM_CMD_GET_REQ, .doit = nss_nloam_op_get_req,},
+};
+
 /*
  * OAM family definition
  */
 static struct genl_family nss_nloam_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
 	.id = GENL_ID_GENERATE,				/* Auto generate ID */
+#endif
 	.name = NSS_NLOAM_FAMILY,			/* family name string */
 	.hdrsize = sizeof(struct nss_nloam_rule),	/* NLOAM msg size */
 	.version = NSS_NL_VER,				/* nss netlink version */
@@ -94,18 +108,10 @@ static struct genl_family nss_nloam_fami
 	.netnsok = false,
 	.pre_doit = NULL,
 	.post_doit = NULL,
-};
-
-static struct genl_multicast_group nss_nloam_mcgrp[] = {
-	{.name = NSS_NLOAM_MCAST_GRP},
-};
-
-/*
- * operation table called by the generic netlink layer based on the command
- */
-static struct genl_ops nss_nloam_ops[] = {
-	{.cmd = NSS_NLOAM_CMD_NONE, .doit = nss_nloam_op_none,},
-	{.cmd = NSS_NLOAM_CMD_GET_REQ, .doit = nss_nloam_op_get_req,},
+	.ops = nss_nloam_ops,
+	.n_ops = ARRAY_SIZE(nss_nloam_ops),
+	.mcgrps = nss_nloam_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nloam_mcgrp)
 };
 
 #define NSS_NLOAM_OPS_SZ ARRAY_SIZE(nss_nloam_ops)
@@ -340,7 +346,7 @@ bool nss_nloam_init(void)
 	/*
 	 * register with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nloam_family, nss_nloam_ops, nss_nloam_mcgrp);
+	error = genl_register_family(&nss_nloam_family);
 	if (error != 0) {
 		nss_nl_info_always("unable to register OAM family\n");
 		return false;
--- a/netlink/nss_nlpppoe.c
+++ b/netlink/nss_nlpppoe.c
@@ -47,20 +47,6 @@ static int nss_nlpppoe_ops_get_stats(str
 static int nss_nlpppoe_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * pppoe family definition
- */
-static struct genl_family nss_nlpppoe_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLPPPOE_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_pppoe_stats_notification),		/* NSS NETLINK pppoe stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLPPPOE version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlpppoe_mcgrp[] = {
@@ -75,6 +61,26 @@ static struct genl_ops nss_nlpppoe_ops[]
 };
 
 /*
+ * pppoe family definition
+ */
+static struct genl_family nss_nlpppoe_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLPPPOE_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_pppoe_stats_notification),		/* NSS NETLINK pppoe stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLPPPOE version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlpppoe_ops,
+	.n_ops = ARRAY_SIZE(nss_nlpppoe_ops),
+	.mcgrps = nss_nlpppoe_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlpppoe_mcgrp)
+};
+
+/*
  * device call back handler for pppoe from NSS
  */
 static struct notifier_block nss_pppoe_stats_notifier_nb = {
@@ -126,7 +132,7 @@ bool nss_nlpppoe_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlpppoe_family, nss_nlpppoe_ops, nss_nlpppoe_mcgrp);
+	error = genl_register_family(&nss_nlpppoe_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register pppoe family\n");
 		return false;
--- a/netlink/nss_nlpptp.c
+++ b/netlink/nss_nlpptp.c
@@ -47,20 +47,6 @@ static int nss_nlpptp_ops_get_stats(stru
 static int nss_nlpptp_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * pptp family definition
- */
-static struct genl_family nss_nlpptp_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLPPTP_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_pptp_stats_notification),		/* NSS NETLINK pptp stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLPPTP version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlpptp_mcgrp[] = {
@@ -75,6 +61,26 @@ static struct genl_ops nss_nlpptp_ops[]
 };
 
 /*
+ * pptp family definition
+ */
+static struct genl_family nss_nlpptp_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLPPTP_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_pptp_stats_notification),		/* NSS NETLINK pptp stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLPPTP version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlpptp_ops,
+	.n_ops = ARRAY_SIZE(nss_nlpptp_ops),
+	.mcgrps = nss_nlpptp_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlpptp_mcgrp)
+};
+
+/*
  * device call back handler for pptp from NSS
  */
 static struct notifier_block nss_pptp_stats_notifier_nb = {
@@ -126,7 +132,7 @@ bool nss_nlpptp_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlpptp_family, nss_nlpptp_ops, nss_nlpptp_mcgrp);
+	error = genl_register_family(&nss_nlpptp_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register pptp family\n");
 		return false;
--- a/netlink/nss_nlwifili.c
+++ b/netlink/nss_nlwifili.c
@@ -47,20 +47,6 @@ static int nss_nlwifili_ops_get_stats(st
 static int nss_nlwifili_process_notify(struct notifier_block *nb, unsigned long val, void *data);
 
 /*
- * wifili family definition
- */
-static struct genl_family nss_nlwifili_family = {
-	.id = GENL_ID_GENERATE,						/* Auto generate ID */
-	.name = NSS_NLWIFILI_FAMILY,					/* family name string */
-	.hdrsize = sizeof(struct nss_wifili_stats_notification),	/* NSS NETLINK wifili stats */
-	.version = NSS_NL_VER,						/* Set it to NSS_NLWIFILI version */
-	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
-	.netnsok = true,
-	.pre_doit = NULL,
-	.post_doit = NULL,
-};
-
-/*
  * multicast group for sending message status & events
  */
 static const struct genl_multicast_group nss_nlwifili_mcgrp[] = {
@@ -75,6 +61,26 @@ static struct genl_ops nss_nlwifili_ops[
 };
 
 /*
+ * wifili family definition
+ */
+static struct genl_family nss_nlwifili_family = {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 9, 0))
+	.id = GENL_ID_GENERATE,						/* Auto generate ID */
+#endif
+	.name = NSS_NLWIFILI_FAMILY,					/* family name string */
+	.hdrsize = sizeof(struct nss_wifili_stats_notification),	/* NSS NETLINK wifili stats */
+	.version = NSS_NL_VER,						/* Set it to NSS_NLWIFILI version */
+	.maxattr = NSS_STATS_EVENT_MAX,					/* maximum commands supported */
+	.netnsok = true,
+	.pre_doit = NULL,
+	.post_doit = NULL,
+	.ops = nss_nlwifili_ops,
+	.n_ops = ARRAY_SIZE(nss_nlwifili_ops),
+	.mcgrps = nss_nlwifili_mcgrp,
+	.n_mcgrps = ARRAY_SIZE(nss_nlwifili_mcgrp)
+};
+
+/*
  * device call back handler for wifili from NSS
  */
 static struct notifier_block nss_wifili_stats_notifier_nb = {
@@ -126,7 +132,7 @@ bool nss_nlwifili_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	error = genl_register_family_with_ops_groups(&nss_nlwifili_family, nss_nlwifili_ops, nss_nlwifili_mcgrp);
+	error = genl_register_family(&nss_nlwifili_family);
 	if (error) {
 		nss_nl_info_always("Error: unable to register wifili family\n");
 		return false;
--- a/netlink/nss_nlcapwap.c
+++ b/netlink/nss_nlcapwap.c
@@ -36,7 +36,6 @@
 #include <nss_dtls_cmn.h>
 #include <nss_nlcmn_if.h>
 #include <nss_nl_if.h>
-#include "nss_crypto_defines.h"
 #include "nss_nl.h"
 #include "nss_nlcapwap_if.h"
 #include "nss_nlcapwap.h"
@@ -1510,7 +1509,7 @@ bool nss_nlcapwap_init(void)
 	/*
 	 * register NETLINK ops with the family
 	 */
-	err = genl_register_family_with_ops_groups(&nss_nlcapwap_family, nss_nlcapwap_cmd_ops, nss_nlcapwap_family_mcgrp);
+	err = genl_register_family(&nss_nlcapwap_family);
 	if (err) {
 		nss_nl_info_always("Error: %d unable to register capwap family\n", err);
 		goto free;
--- a/netlink/Makefile
+++ b/netlink/Makefile
@@ -1,5 +1,6 @@
+GRE_ENABLED := $(strip $(if $(filter $(gre), y), 1 , 0))
 CAPWAP_ENABLED := $(strip $(if $(filter $(capwapmgr), y), 1 , 0))
-IPSEC_ENABLED := $(strip $(if $(filter $(ipsecmgr), y), 1 , 0))
+IPSEC_ENABLED := 0
 DTLS_ENABLED := $(strip $(if $(filter $(dtlsmgr), y), 1 , 0))
 
 ccflags-y := -Werror
@@ -10,44 +11,39 @@ ccflags-y += -DNSS_CLIENT_BUILD_ID="$(BU
 
 ccflags-y += -DCONFIG_NSS_NLIPV4=1
 ccflags-y += -DCONFIG_NSS_NLIPV6=1
-ccflags-y += -DCONFIG_NSS_NLOAM=1
-ccflags-y += -DCONFIG_NSS_NLGRE_REDIR_FAMILY=1
+ccflags-y += -DCONFIG_NSS_NLOAM=0
+ccflags-y += -DCONFIG_NSS_NLGRE_REDIR_FAMILY=${GRE_ENABLED}
 ccflags-y += -DCONFIG_NSS_NLETHRX=1
 ccflags-y += -DCONFIG_NSS_NLDYNAMIC_INTERFACE=1
 ccflags-y += -DCONFIG_NSS_NLN2H=1
-ccflags-y += -DCONFIG_NSS_NLIPV4_REASM=1
-ccflags-y += -DCONFIG_NSS_NLIPV6_REASM=1
+ccflags-y += -DCONFIG_NSS_NLIPV4_REASM=0
+ccflags-y += -DCONFIG_NSS_NLIPV6_REASM=0
 ccflags-y += -DCONFIG_NSS_NLWIFILI=1
 ccflags-y += -DCONFIG_NSS_NLLSO_RX=1
-ccflags-y += -DCONFIG_NSS_NLMAP_T=1
-ccflags-y += -DCONFIG_NSS_NLPPPOE=1
-ccflags-y += -DCONFIG_NSS_NLL2TPV2=1
-ccflags-y += -DCONFIG_NSS_NLPPTP=1
+ccflags-y += -DCONFIG_NSS_NLMAP_T=0
+ccflags-y += -DCONFIG_NSS_NLPPPOE=0
+ccflags-y += -DCONFIG_NSS_NLL2TPV2=0
+ccflags-y += -DCONFIG_NSS_NLPPTP=0
 ccflags-y += -DCONFIG_NSS_NLCAPWAP=${CAPWAP_ENABLED}
 ccflags-y += -DCONFIG_NSS_NLIPSEC=${IPSEC_ENABLED}
 ccflags-y += -DCONFIG_NSS_NLDTLS=${DTLS_ENABLED}
 
 qca-nss-netlink-objs := nss_nl.o
-qca-nss-netlink-objs += nss_nlgre_redir_family.o
-qca-nss-netlink-objs += nss_nlgre_redir_cmd.o
-qca-nss-netlink-objs += nss_nlgre_redir_cmn.o
-qca-nss-netlink-objs += nss_nlgre_redir.o
-qca-nss-netlink-objs += nss_nlgre_redir_lag.o
 qca-nss-netlink-objs += nss_nlipv4.o
 qca-nss-netlink-objs += nss_nlipv6.o
-qca-nss-netlink-objs += nss_nloam.o
+# qca-nss-netlink-objs += nss_nloam.o
 qca-nss-netlink-objs += nss_nlethrx.o
 qca-nss-netlink-objs += nss_nldynamic_interface.o
 qca-nss-netlink-objs += nss_nln2h.o
-qca-nss-netlink-objs += nss_nlipv4_reasm.o
-qca-nss-netlink-objs += nss_nlipv6_reasm.o
+# qca-nss-netlink-objs += nss_nlipv4_reasm.o
+# qca-nss-netlink-objs += nss_nlipv6_reasm.o
 qca-nss-netlink-objs += nss_nlwifili.o
 qca-nss-netlink-objs += nss_nllso_rx.o
-qca-nss-netlink-objs += nss_nlmap_t.o
-qca-nss-netlink-objs += nss_nlpppoe.o
-qca-nss-netlink-objs += nss_nll2tpv2.o
-qca-nss-netlink-objs += nss_nlpptp.o
-
+# qca-nss-netlink-objs += nss_nlmap_t.o
+# qca-nss-netlink-objs += nss_nlpppoe.o
+# qca-nss-netlink-objs += nss_nll2tpv2.o
+# qca-nss-netlink-objs += nss_nlpptp.o
+#
 ifneq (,$(filter $(capwapmgr), y))
 qca-nss-netlink-objs += nss_nlcapwap.o
 endif
@@ -56,8 +52,12 @@ ifneq (,$(filter $(dtlsmgr), y))
 qca-nss-netlink-objs += nss_nldtls.o
 endif
 
-ifneq (,$(filter $(ipsecmgr), y))
-qca-nss-netlink-objs += nss_nlipsec.o
+ifneq (,$(filter $(gre), y))
+qca-nss-netlink-objs += nss_nlgre_redir_family.o
+qca-nss-netlink-objs += nss_nlgre_redir_cmd.o
+qca-nss-netlink-objs += nss_nlgre_redir_cmn.o
+qca-nss-netlink-objs += nss_nlgre_redir.o
+qca-nss-netlink-objs += nss_nlgre_redir_lag.o
 endif
 
 ifeq ($(SoC),$(filter $(SoC),ipq807x ipq807x_64))
--- a/netlink/nss_nl.c
+++ b/netlink/nss_nl.c
@@ -35,8 +35,6 @@
 #include "nss_nlcmn_if.h"
 #include "nss_nldtls.h"
 #include "nss_nldtls_if.h"
-#include "nss_nlgre_redir_if.h"
-#include "nss_nlgre_redir_family.h"
 #include "nss_nlipsec.h"
 #include "nss_nlipsec_if.h"
 #include "nss_nlipv4.h"
@@ -59,10 +57,6 @@
 #include "nss_nlc2c_tx_if.h"
 #include "nss_nlc2c_rx.h"
 #include "nss_nlc2c_rx_if.h"
-#include "nss_nlipv4_reasm.h"
-#include "nss_nlipv4_reasm_if.h"
-#include "nss_nlipv6_reasm.h"
-#include "nss_nlipv6_reasm_if.h"
 #include "nss_nlwifili.h"
 #include "nss_nlwifili_if.h"
 #include "nss_nllso_rx.h"
@@ -106,24 +100,6 @@ static struct nss_nl_family family_handl
 	},
 	{
 		/*
-		 * NSS_NLIPSEC
-		 */
-		.name = NSS_NLIPSEC_FAMILY,		/* ipsec */
-		.entry = NSS_NLIPSEC_INIT,		/* init */
-		.exit = NSS_NLIPSEC_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLIPSEC		/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLOAM
-		 */
-		.name = NSS_NLOAM_FAMILY,		/* oam */
-		.entry = NSS_NLOAM_INIT,		/* init */
-		.exit = NSS_NLOAM_EXIT,			/* exit */
-		.valid = CONFIG_NSS_NLOAM		/* 1 or 0 */
-	},
-	{
-		/*
 		 * NSS_NLIPV6
 		 */
 		.name = NSS_NLIPV6_FAMILY,		/* ipv6 */
@@ -133,24 +109,6 @@ static struct nss_nl_family family_handl
 	},
 	{
 		/*
-		 * NSS_NLGRE_REDIR
-		 */
-		.name = NSS_NLGRE_REDIR_FAMILY,		/* gre_redir */
-		.entry = NSS_NLGRE_REDIR_FAMILY_INIT,	/* init */
-		.exit = NSS_NLGRE_REDIR_FAMILY_EXIT,	/* exit */
-		.valid = CONFIG_NSS_NLGRE_REDIR_FAMILY	/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLCAPWAP
-		 */
-		.name = NSS_NLCAPWAP_FAMILY,		/* capwap */
-		.entry = NSS_NLCAPWAP_INIT,		/* init */
-		.exit = NSS_NLCAPWAP_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLCAPWAP		/* 1 or 0 */
-	},
-	{
-		/*
 		 * NSS_NLDTLS
 		 */
 		.name = NSS_NLDTLS_FAMILY,		/* dtls */
@@ -169,15 +127,6 @@ static struct nss_nl_family family_handl
 	},
 	{
 		/*
-		 * NSS_NLEDMA
-		 */
-		.name = NSS_NLEDMA_FAMILY,		/* edma */
-		.entry = NSS_NLEDMA_INIT,		/* init */
-		.exit = NSS_NLEDMA_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLEDMA		/* 1 or 0 */
-	},
-	{
-		/*
 		 * NSS_NLDYNAMIC_INTERFACE
 		 */
 		.name = NSS_NLDYNAMIC_INTERFACE_FAMILY,	/* dynamic interface */
@@ -196,42 +145,6 @@ static struct nss_nl_family family_handl
 	},
 	{
 		/*
-		 * NSS_NLC2C_TX
-		 */
-		.name = NSS_NLC2C_TX_FAMILY,		/* c2c_tx */
-		.entry = NSS_NLC2C_TX_INIT,		/* init */
-		.exit = NSS_NLC2C_TX_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLC2C_TX		/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLC2C_RX
-		 */
-		.name = NSS_NLC2C_RX_FAMILY,		/* c2c_rx */
-		.entry = NSS_NLC2C_RX_INIT,		/* init */
-		.exit = NSS_NLC2C_RX_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLC2C_RX		/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLIPV4_REASM
-		 */
-		.name = NSS_NLIPV4_REASM_FAMILY,	/* ipv4_reasm */
-		.entry = NSS_NLIPV4_REASM_INIT,		/* init */
-		.exit = NSS_NLIPV4_REASM_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLIPV4_REASM	/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLIPV6_REASM
-		 */
-		.name = NSS_NLIPV6_REASM_FAMILY,	/* ipv6_reasm */
-		.entry = NSS_NLIPV6_REASM_INIT,		/* init */
-		.exit = NSS_NLIPV6_REASM_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLIPV6_REASM	/* 1 or 0 */
-	},
-	{
-		/*
 		 * NSS_NLWIFILI
 		 */
 		.name = NSS_NLWIFILI_FAMILY,		/* wifili */
@@ -248,42 +161,6 @@ static struct nss_nl_family family_handl
 		.exit = NSS_NLLSO_RX_EXIT,		/* exit */
 		.valid = CONFIG_NSS_NLLSO_RX		/* 1 or 0 */
 	},
-	{
-		/*
-		 * NSS_NLMAP_T
-		 */
-		.name = NSS_NLMAP_T_FAMILY,		/* map_t */
-		.entry = NSS_NLMAP_T_INIT,		/* init */
-		.exit = NSS_NLMAP_T_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLMAP_T		/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLPPPOE
-		 */
-		.name = NSS_NLPPPOE_FAMILY,		/* pppoe */
-		.entry = NSS_NLPPPOE_INIT,		/* init */
-		.exit = NSS_NLPPPOE_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLPPPOE		/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLL2TPV2
-		 */
-		.name = NSS_NLL2TPV2_FAMILY,		/* l2tpv2 */
-		.entry = NSS_NLL2TPV2_INIT,		/* init */
-		.exit = NSS_NLL2TPV2_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLL2TPV2		/* 1 or 0 */
-	},
-	{
-		/*
-		 * NSS_NLPPTP
-		 */
-		.name = NSS_NLPPTP_FAMILY,		/* pptp */
-		.entry = NSS_NLPPTP_INIT,		/* init */
-		.exit = NSS_NLPPTP_EXIT,		/* exit */
-		.valid = CONFIG_NSS_NLPPTP		/* 1 or 0 */
-	},
 };
 
 #define NSS_NL_FAMILY_HANDLER_SZ ARRAY_SIZE(family_handlers)
--- a/nss_qdisc/Makefile
+++ b/nss_qdisc/Makefile
@@ -6,7 +6,7 @@ ifeq ($(SoC),$(filter $(SoC),ipq807x ipq
 ccflags-y += -DNSS_QDISC_PPE_SUPPORT -DNSS_QDISC_BRIDGE_SUPPORT
 endif
 
-ccflags-y += -Werror
+ccflags-y += -Wall -Werror
 
 obj-m += qca-nss-qdisc.o
 qca-nss-qdisc-objs := 	nss_qdisc.o \
--- a/nss_qdisc/igs/Makefile
+++ b/nss_qdisc/igs/Makefile
@@ -1,8 +1,7 @@
 # Makefile for IGS (Ingress Shaping)
 
 ccflags-y += $(NSS_CCFLAGS) -I$(obj)/../../exports
-ccflags-y += -DNSS_IGS_DEBUG_LEVEL=2
-ccflags-y += -Werror
+ccflags-y += -Wall -Werror
 
 obj-m += act_nssmirred.o
 act_nssmirred-objs := \
--- a/nss_qdisc/igs/nss_mirred.c
+++ b/nss_qdisc/igs/nss_mirred.c
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2019 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2019-2020 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -24,12 +24,20 @@
 
 static LIST_HEAD(nss_mirred_list);		/* List for all nss mirred actions */
 static DEFINE_SPINLOCK(nss_mirred_list_lock);	/* Lock for the nss mirred list */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+static unsigned int nss_mirred_net_id;		/* NSS mirror net ID */
+static struct tc_action_ops nss_mirred_act_ops;	/* NSS action mirror ops */
+#endif
 
 /*
  * nss_mirred_release()
  *	Cleanup the resources for nss mirred action.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 static void nss_mirred_release(struct tc_action *tc_act, int bind)
+#else
+static void nss_mirred_release(struct tc_action *tc_act)
+#endif
 {
 	struct nss_mirred_tcf *act = nss_mirred_get(tc_act);
 	struct net_device *dev = rcu_dereference_protected(act->tcfm_dev, 1);
@@ -75,9 +83,23 @@ static const struct nla_policy nss_mirre
  *	Initialize the nss mirred action.
  */
 static int nss_mirred_init(struct net *net, struct nlattr *nla,
-			   struct nlattr *est, struct tc_action *tc_act, int ovr,
-			   int bind)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+						struct nlattr *est, struct tc_action *tc_act, int ovr,
+						int bind)
 {
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(5, 15, 0))
+						struct nlattr *est, struct tc_action **tc_act, int ovr,
+						int bind, bool rtnl_held, struct tcf_proto *tp,
+						u32 flags, struct netlink_ext_ack *extack)
+{
+#else
+						struct nlattr *est, struct tc_action **tc_act,
+						struct tcf_proto *tp, u32 flags, struct netlink_ext_ack *extack)
+{
+	bool bind = flags & TCA_ACT_FLAGS_BIND;
+#endif
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+	u32 index;
 	struct nlattr *arr[TC_NSS_MIRRED_MAX + 1];
 	struct tc_nss_mirred *parm;
 	struct nss_mirred_tcf *act;
@@ -92,7 +114,11 @@ static int nss_mirred_init(struct net *n
 	/*
 	 * Parse and validate the user configurations.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 2, 0))
 	ret = nla_parse_nested(arr, TC_NSS_MIRRED_MAX, nla, nss_mirred_policy);
+#else
+	ret = nla_parse_nested_deprecated(arr, TC_NSS_MIRRED_MAX, nla, nss_mirred_policy, extack);
+#endif
 	if (ret < 0) {
 		return ret;
 	}
@@ -193,6 +219,7 @@ static int nss_mirred_init(struct net *n
 	/*
 	 * Return error if nss mirred action index is present in the hash.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	if (tcf_hash_check(parm->index, tc_act, bind)) {
 		return -EEXIST;
 	}
@@ -204,7 +231,33 @@ static int nss_mirred_init(struct net *n
 	}
 
 	act = nss_mirred_get(tc_act);
+#else
+	index = parm->index;
+	ret = tcf_idr_check_alloc(tn, &index, tc_act, bind);
+	if (ret < 0) {
+		return ret;
+	}
+
+	if (ret && bind) {
+		return 0;
+	}
+
+	if (!ret) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 5, 0))
+		ret = tcf_idr_create(tn, index, est, tc_act, &nss_mirred_act_ops,
+				bind, true);
+#else
+		ret = tcf_idr_create(tn, index, est, tc_act, &nss_mirred_act_ops,
+				bind, true, 0);
+#endif
+		if (ret) {
+			tcf_idr_cleanup(tn, index);
+			return ret;
+		}
+	}
 
+	act = nss_mirred_get(*tc_act);
+#endif
 	/*
 	 * Fill up the nss mirred tc parameters to
 	 * its local action structure.
@@ -222,7 +275,9 @@ static int nss_mirred_init(struct net *n
 	spin_lock_bh(&nss_mirred_list_lock);
 	list_add(&act->tcfm_list, &nss_mirred_list);
 	spin_unlock_bh(&nss_mirred_list_lock);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	tcf_hash_insert(tc_act);
+#endif
 
 	return ACT_P_CREATED;
 }
@@ -234,10 +289,15 @@ static int nss_mirred_init(struct net *n
 static int nss_mirred_act(struct sk_buff *skb, const struct tc_action *tc_act,
 		      struct tcf_result *res)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	struct nss_mirred_tcf *act = tc_act->priv;
+#else
+	struct nss_mirred_tcf *act = nss_mirred_get(tc_act);
+#endif
 	struct net_device *dev;
 	struct sk_buff *skb_new;
 	int retval, err;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	u32 skb_tc_at = G_TC_AT(skb->tc_verd);
 
 	/*
@@ -247,6 +307,12 @@ static int nss_mirred_act(struct sk_buff
 		return TC_ACT_UNSPEC;
 	}
 
+#else
+	if (!skb_at_tc_ingress(skb)) {
+		return TC_ACT_UNSPEC;
+	}
+#endif
+
 	/*
 	 * Update the last use of action.
 	 */
@@ -276,9 +342,14 @@ static int nss_mirred_act(struct sk_buff
 
 	skb_new->skb_iif = skb->dev->ifindex;
 	skb_new->dev = dev;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	skb_new->tc_verd = SET_TC_FROM(skb_new->tc_verd, skb_tc_at);
 	skb_push_rcsum(skb_new, skb->mac_len);
 	skb_sender_cpu_clear(skb_new);
+#else
+	skb_set_redirected(skb_new, skb_new->tc_at_ingress);
+	skb_push_rcsum(skb_new, skb->mac_len);
+#endif
 
 	err = dev_queue_xmit(skb_new);
 	if (!err) {
@@ -300,12 +371,21 @@ static int nss_mirred_dump(struct sk_buf
 {
 	struct tcf_t filter;
 	unsigned char *tail = skb_tail_pointer(skb);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	struct nss_mirred_tcf *act = tc_act->priv;
+#else
+	struct nss_mirred_tcf *act = nss_mirred_get(tc_act);
+#endif
 	struct tc_nss_mirred opt = {
 		.index   = act->tcf_index,
 		.action  = act->tcf_action,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 		.refcnt  = act->tcf_refcnt - ref,
 		.bindcnt = act->tcf_bindcnt - bind,
+#else
+		.refcnt  = refcount_read(&act->tcf_refcnt) - ref,
+		.bindcnt = atomic_read(&act->tcf_bindcnt) - bind,
+#endif
 		.from_ifindex = act->tcfm_from_ifindex,
 		.to_ifindex = act->tcfm_to_ifindex,
 	};
@@ -470,6 +550,64 @@ static int nss_mirred_device_event(struc
 	return NOTIFY_DONE;
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+/*
+ * nss_mirred_walker
+ *	nssmirred tcf_action walker
+ */
+static int nss_mirred_walker(struct net *net, struct sk_buff *skb,
+		struct netlink_callback *cb, int type,
+		const struct tc_action_ops *ops,
+		struct netlink_ext_ack *extack)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+
+	return tcf_generic_walker(tn, skb, cb, type, ops, extack);
+}
+
+/*
+ * nss_mirred_search
+ *	nssmirred search idr function.
+ */
+static int nss_mirred_search(struct net *net, struct tc_action **a, u32 index)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+
+	return tcf_idr_search(tn, a, index);
+}
+
+/*
+ * nss_mirred_dev_put
+ *	Release igs dev
+ */
+static void nss_mirred_dev_put(void *priv)
+{
+	struct net_device *dev = priv;
+
+	dev_put(dev);
+}
+
+/*
+ * nss_mirred_device
+ *	Get the igs dev.
+ */
+static struct net_device *nss_mirred_device(const struct tc_action *a, tc_action_priv_destructor *destructor)
+{
+	struct nss_mirred_tcf *m = nss_mirred_get(a);
+	struct net_device *dev;
+
+	rcu_read_lock();
+	dev = rcu_dereference(m->tcfm_dev);
+	if (dev) {
+		dev_hold(dev);
+		*destructor = nss_mirred_dev_put;
+	}
+	rcu_read_unlock();
+
+	return dev;
+}
+#endif
+
 /*
  * nss_mirred_device_notifier
  *	nss mirred device notifier structure.
@@ -482,14 +620,22 @@ static struct notifier_block nss_mirred_
  * nss_mirred_act_ops
  *	Registration structure for nss mirred action.
  */
-struct tc_action_ops nss_mirred_act_ops = {
+static struct tc_action_ops nss_mirred_act_ops = {
 	.kind		=	"nssmirred",
-	.type		=	TCA_ACT_MIRRED_NSS,
 	.owner		=	THIS_MODULE,
 	.act		=	nss_mirred_act,
 	.dump		=	nss_mirred_dump,
 	.cleanup	=	nss_mirred_release,
 	.init		=	nss_mirred_init,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.type		=	TCA_ACT_MIRRED_NSS,
+#else
+	.id		=	TCA_ID_MIRRED_NSS,
+	.walk		=	nss_mirred_walker,
+	.lookup		=	nss_mirred_search,
+	.size           =       sizeof(struct nss_mirred_tcf),
+	.get_dev	=	nss_mirred_device
+#endif
 };
 
 /*
@@ -514,6 +660,52 @@ struct nf_hook_ops nss_mirred_igs_nf_ops
 	},
 };
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+/*
+ * nss_mirred_init_net
+ *	nssmirred net init function.
+ */
+static __net_init int nss_mirred_init_net(struct net *net)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+	nf_register_net_hooks(net, nss_mirred_igs_nf_ops,
+			ARRAY_SIZE(nss_mirred_igs_nf_ops));
+
+	return tc_action_net_init(net, tn, &nss_mirred_act_ops);
+}
+
+/*
+ * nss_mirred_exit_net
+ *	nssmirred net exit function.
+ */
+static void __net_exit nss_mirred_exit_net(struct net *net)
+{
+	nf_unregister_net_hooks(net, nss_mirred_igs_nf_ops,
+			ARRAY_SIZE(nss_mirred_igs_nf_ops));
+}
+
+/*
+ * nss_mirred_exit_batch_net
+ *	nssmirred exit_batch_net function.
+ */
+static void __net_exit nss_mirred_exit_batch_net(struct list_head *net_list)
+{
+	tc_action_net_exit(net_list, nss_mirred_net_id);
+}
+
+/*
+ * nss_mirred_net_ops
+ *	Per netdevice ops.
+ */
+static struct pernet_operations nss_mirred_net_ops = {
+	.init = nss_mirred_init_net,
+	.exit = nss_mirred_exit_net,
+	.exit_batch = nss_mirred_exit_batch_net,
+	.id   = &nss_mirred_net_id,
+	.size = sizeof(struct tc_action_net),
+};
+#endif
+
 /*
  * nss_mirred_init_module()
  *	nssmirred init function.
@@ -525,6 +717,7 @@ static int __init nss_mirred_init_module
 		return err;
 	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	err = tcf_register_action(&nss_mirred_act_ops, NSS_MIRRED_TAB_MASK);
 	if (err) {
 		unregister_netdevice_notifier(&nss_mirred_device_notifier);
@@ -538,6 +731,13 @@ static int __init nss_mirred_init_module
 		unregister_netdevice_notifier(&nss_mirred_device_notifier);
 		return err;
 	}
+#else
+	err = tcf_register_action(&nss_mirred_act_ops, &nss_mirred_net_ops);
+	if (err) {
+		unregister_netdevice_notifier(&nss_mirred_device_notifier);
+		return err;
+	}
+#endif
 
 	/*
 	 * Set the IGS module reference variable.
@@ -559,12 +759,16 @@ static void __exit nss_mirred_cleanup_mo
 	 */
 	nss_igs_module_save(&nss_mirred_act_ops, NULL);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	nf_unregister_hooks(nss_mirred_igs_nf_ops, ARRAY_SIZE(nss_mirred_igs_nf_ops));
 
 	/*
 	 * Un-register nss mirred action.
 	 */
 	tcf_unregister_action(&nss_mirred_act_ops);
+#else
+	tcf_unregister_action(&nss_mirred_act_ops, &nss_mirred_net_ops);
+#endif
 	unregister_netdevice_notifier(&nss_mirred_device_notifier);
 }
 
--- a/nss_qdisc/igs/nss_mirred.h
+++ b/nss_qdisc/igs/nss_mirred.h
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2019 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2019-2020 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -14,6 +14,7 @@
  **************************************************************************
  */
 
+#include <linux/version.h>
 #include <net/act_api.h>
 
 #define NSS_MIRRED_TAB_MASK 7
@@ -23,7 +24,11 @@
  *	nss mirred internal structure.
  */
 struct nss_mirred_tcf {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	struct tcf_common common;		/* Common filter structure */
+#else
+	struct tc_action common;		/* Common filter structure */
+#endif
 	__u32 tcfm_to_ifindex;			/* Index number of device to which
 						 * traffic will be redirected.
 						 */
@@ -40,5 +45,10 @@ struct nss_mirred_tcf {
  * To get the pointer of nss mirred action structure from the common
  * tc_action structure pointer.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 #define nss_mirred_get(a) \
 	container_of(a->priv, struct nss_mirred_tcf, common)
+#else
+#define nss_mirred_get(a) ((struct nss_mirred_tcf *)a)
+#endif
+
--- a/nss_qdisc/nss_bf.c
+++ b/nss_qdisc/nss_bf.c
@@ -68,12 +68,20 @@ static inline struct nss_bf_class_data *
  * nss_bf_change_class()
  *	Configures a new class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
 		  struct nlattr **tca, unsigned long *arg)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_bf_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
+		  struct nlattr **tca, unsigned long *arg, struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)*arg;
 	struct nlattr *opt = tca[TCA_OPTIONS];
+	struct nlattr *tb[TCA_NSSBF_MAX + 1];
 	struct tc_nssbf_class_qopt *qopt;
 	struct nss_if_msg nim_config;
 	struct net_device *dev = qdisc_dev(sch);
@@ -84,7 +92,12 @@ static int nss_bf_change_class(struct Qd
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, TCA_NSSBF_MAX, TCA_NSSBF_CLASS_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_CLASS_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_CLASS_PARMS, extack);
+#endif
+
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -111,7 +124,7 @@ static int nss_bf_change_class(struct Qd
 		 * reference count should not be 0.
 		 */
 		cl->qdisc = &noop_qdisc;
-		atomic_set(&cl->nq.refcnt, 1);
+		nss_qdisc_atomic_set(&cl->nq);
 		*arg = (unsigned long)cl;
 
 		nss_qdisc_info("Adding classid %u to qdisc %px hash queue %px\n", classid, sch, &q->clhash);
@@ -121,7 +134,8 @@ static int nss_bf_change_class(struct Qd
 		 * that is registered to Linux. Therefore we initialize the NSSBF_GROUP shaper
 		 * here.
 		 */
-		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_BF_GROUP, classid, accel_mode) < 0) {
+		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_BF_GROUP, classid, accel_mode, extack) < 0)
+		{
 			nss_qdisc_error("Nss init for class %u failed\n", classid);
 			kfree(cl);
 			return -EINVAL;
@@ -260,7 +274,7 @@ static void nss_bf_destroy_class(struct
 	/*
 	 * And now we destroy the child.
 	 */
-	qdisc_destroy(cl->qdisc);
+	 nss_qdisc_put(cl->qdisc);
 
 	/*
 	 * Stop the stats polling timer and free class
@@ -282,7 +296,11 @@ static void nss_bf_destroy_class(struct
  * nss_bf_delete_class()
  *	Detaches a class from operation, but does not destroy it.
  */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 12, 0))
+static int nss_bf_delete_class(struct Qdisc *sch, unsigned long arg, struct netlink_ext_ack *extack)
+#else
 static int nss_bf_delete_class(struct Qdisc *sch, unsigned long arg)
+#endif
 {
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)arg;
@@ -311,7 +329,7 @@ static int nss_bf_delete_class(struct Qd
 	sch_tree_lock(sch);
 	qdisc_reset(cl->qdisc);
 	qdisc_class_hash_remove(&q->clhash, &cl->cl_common);
-	refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+	refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
 	sch_tree_unlock(sch);
 	if (!refcnt) {
 		nss_qdisc_error("Reference count should not be zero for class %px\n", cl);
@@ -324,8 +342,13 @@ static int nss_bf_delete_class(struct Qd
  * nss_bf_graft_class()
  *	Replaces the qdisc attached to the provided class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
 								 struct Qdisc **old)
+#else
+static int nss_bf_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
+								 struct Qdisc **old, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)arg;
@@ -415,6 +438,7 @@ static void nss_bf_qlen_notify(struct Qd
 	 */
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 /*
  * nss_bf_get_class()
  *	Fetches the class pointer if provided the classid.
@@ -444,10 +468,24 @@ static void nss_bf_put_class(struct Qdis
 	 * We are safe to destroy the qdisc if the reference count
 	 * goes down to 0.
 	 */
-	if (atomic_sub_return(1, &cl->nq.refcnt) == 0) {
+	if (nss_qdisc_atomic_sub_return(&cl->nq) == 0) {
 		nss_bf_destroy_class(sch, cl);
 	}
 }
+#else
+/*
+ * nss_bf_search_class()
+ *	Fetches the class pointer if provided the classid.
+ */
+static unsigned long nss_bf_search_class(struct Qdisc *sch, u32 classid)
+{
+	struct nss_bf_class_data *cl = nss_bf_find_class(classid, sch);
+
+	nss_qdisc_info("Get bf class %px - class match = %px\n", sch, cl);
+
+	return (unsigned long)cl;
+}
+#endif
 
 /*
  * nss_bf_dump_class()
@@ -475,7 +513,7 @@ static int nss_bf_dump_class(struct Qdis
 	tcm->tcm_handle = cl->cl_common.classid;
 	tcm->tcm_info = cl->qdisc->handle;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSBF_CLASS_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -495,7 +533,7 @@ static int nss_bf_dump_class_stats(struc
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)arg;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &nq->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &nq->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &nq->qstats) < 0) {
 		return -1;
 	}
@@ -538,9 +576,15 @@ static void nss_bf_walk(struct Qdisc *sc
  * nss_bf_change_qdisc()
  *	Can be used to configure a nssbf qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_change_qdisc(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_bf_change_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSBF_MAX + 1];
 	struct tc_nssbf_qopt *qopt;
 
 	/*
@@ -563,7 +607,11 @@ static int nss_bf_change_qdisc(struct Qd
 	/*
 	 * If it is not NULL, parse to get qopt.
 	 */
-	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -643,7 +691,7 @@ static void nss_bf_destroy_qdisc(struct
 			 * Reduce refcnt by 1 before destroying. This is to
 			 * ensure that polling of stat stops properly.
 			 */
-			atomic_sub(1, &cl->nq.refcnt);
+			 nss_qdisc_atomic_sub(&cl->nq);
 
 			/*
 			 * Detach class before destroying it. We dont check for noop qdisc here
@@ -684,9 +732,17 @@ static void nss_bf_destroy_qdisc(struct
  * nss_bf_init_qdisc()
  *	Initializes the nssbf qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_init_qdisc(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_bf_init_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSBF_MAX + 1];
 	struct tc_nssbf_qopt *qopt;
 	int err;
 	unsigned int accel_mode;
@@ -710,7 +766,11 @@ static int nss_bf_init_qdisc(struct Qdis
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_NSS_FW;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
@@ -720,7 +780,7 @@ static int nss_bf_init_qdisc(struct Qdis
 	/*
 	 * Initialize the NSSBF shaper in NSS
 	 */
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_BF, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_BF, 0, accel_mode, extack) < 0) {
 		return -EINVAL;
 	}
 
@@ -729,7 +789,11 @@ static int nss_bf_init_qdisc(struct Qdis
 	/*
 	 * Tune nss_bf parameters.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_bf_change_qdisc(sch, opt) < 0) {
+#else
+	if (nss_bf_change_qdisc(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
@@ -756,7 +820,7 @@ static int nss_bf_dump_qdisc(struct Qdis
 	qopt.defcls = q->defcls;
 	qopt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (!opts || nla_put(skb, TCA_NSSBF_QDISC_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -772,9 +836,18 @@ nla_put_failure:
  * nss_bf_enqueue()
  *	Enqueues a skb to nssbf qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_bf_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_bf_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -786,6 +859,7 @@ static struct sk_buff *nss_bf_dequeue(st
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_bf_drop()
  *	Drops a single skb from linux queue, if not empty.
@@ -797,6 +871,7 @@ static unsigned int nss_bf_drop(struct Q
 	printk("In bf drop\n");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * Registration structure for nssbf class
@@ -807,9 +882,17 @@ const struct Qdisc_class_ops nss_bf_clas
 	.graft		= nss_bf_graft_class,
 	.leaf		= nss_bf_leaf_class,
 	.qlen_notify	= nss_bf_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_bf_get_class,
 	.put		= nss_bf_put_class,
+#else
+	.find		= nss_bf_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block      = nss_qdisc_tcf_block,
+#endif
 	.bind_tcf	= nss_qdisc_tcf_bind,
 	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_bf_dump_class,
@@ -830,7 +913,9 @@ struct Qdisc_ops nss_bf_qdisc_ops __read
 	.enqueue	= nss_bf_enqueue,
 	.dequeue	= nss_bf_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_bf_drop,
+#endif
 	.cl_ops		= &nss_bf_class_ops,
 	.priv_size	= sizeof(struct nss_bf_sched_data),
 	.owner		= THIS_MODULE
--- a/nss_qdisc/nss_blackhole.c
+++ b/nss_qdisc/nss_blackhole.c
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014, 2016-2017, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014, 2016-2017, 2020,  The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -35,9 +35,18 @@ static struct nla_policy nss_blackhole_p
  * nss_blackhole_enqueue()
  *	Enqueue API for nss blackhole qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_blackhole_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_blackhole_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -49,6 +58,7 @@ static struct sk_buff *nss_blackhole_deq
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_blackhole_drop()
  *	The following function drops a packet from HLOS queue.
@@ -60,6 +70,7 @@ static unsigned int nss_blackhole_drop(s
 	nss_qdisc_info("qdisc %x dropping\n", sch->handle);
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_blackhole_reset()
@@ -92,9 +103,15 @@ static void nss_blackhole_destroy(struct
  * nss_blackhole_change()
  *	Function call used to configure the parameters of the nss blackhole qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_blackhole_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_blackhole_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_blackhole_sched_data *q;
+	struct nlattr *tb[TCA_NSSBLACKHOLE_MAX + 1];
 	struct tc_nssblackhole_qopt *qopt;
 	struct nss_if_msg nim;
 
@@ -102,7 +119,11 @@ static int nss_blackhole_change(struct Q
 		return 0;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -154,9 +175,17 @@ static int nss_blackhole_change(struct Q
  * nss_blackhole_init()
  *	Initializes a nss blackhole qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_blackhole_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_blackhole_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSBLACKHOLE_MAX + 1];
 	struct tc_nssblackhole_qopt *qopt;
 	unsigned int accel_mode;
 
@@ -166,7 +195,11 @@ static int nss_blackhole_init(struct Qdi
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_PPE;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
@@ -176,12 +209,17 @@ static int nss_blackhole_init(struct Qdi
 	nss_qdisc_info("qdisc %x initializing\n", sch->handle);
 	nss_blackhole_reset(sch);
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, accel_mode, extack) < 0)
+	{
 		return -EINVAL;
 	}
 
 	nss_qdisc_info("qdisc %x initialized with parent %x\n", sch->handle, sch->parent);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_blackhole_change(sch, opt) < 0) {
+#else
+	if (nss_blackhole_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
@@ -214,7 +252,7 @@ static int nss_blackhole_dump(struct Qdi
 	opt.set_default = q->set_default;
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -251,7 +289,9 @@ struct Qdisc_ops nss_blackhole_qdisc_ops
 	.enqueue	=	nss_blackhole_enqueue,
 	.dequeue	=	nss_blackhole_dequeue,
 	.peek		=	nss_blackhole_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_blackhole_drop,
+#endif
 	.init		=	nss_blackhole_init,
 	.reset		=	nss_blackhole_reset,
 	.destroy	=	nss_blackhole_destroy,
--- a/nss_qdisc/nss_codel.c
+++ b/nss_qdisc/nss_codel.c
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014, 2016-2018, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014, 2016-2018, 2020,  The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -76,9 +76,18 @@ static struct nla_policy nss_codel_polic
  * nss_codel_enqueue()
  *	Enqueue a packet into nss_codel queue in NSS firmware (bounce).
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_codel_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_codel_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -90,6 +99,7 @@ static struct sk_buff *nss_codel_dequeue
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_codel_drop()
  *	Drops a packet from the bounce complete queue.
@@ -100,6 +110,7 @@ static unsigned int nss_codel_drop(struc
 {
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_codel_reset()
@@ -234,9 +245,15 @@ static int nss_codel_mem_sz_get(struct Q
  * nss_codel_change()
  *	Used to configure the nss_codel queue in NSS firmware.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_codel_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_codel_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_codel_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSCODEL_MAX + 1];
 	struct tc_nsscodel_qopt *qopt;
 	struct nss_if_msg nim;
 	struct net_device *dev = qdisc_dev(sch);
@@ -245,7 +262,11 @@ static int nss_codel_change(struct Qdisc
 	struct nss_shaper_node_config *config;
 	bool free_flow_queue = true;
 
-	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -381,16 +402,28 @@ fail:
  * nss_codel_init()
  *	Initializes the nss_codel qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_codel_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_codel_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSCODEL_MAX + 1];
 	struct tc_nsscodel_qopt *qopt;
 
 	if (!opt) {
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -404,7 +437,8 @@ static int nss_codel_init(struct Qdisc *
 	nss_qdisc_register_configure_callback(nq, nss_codel_configure_callback);
 	nss_qdisc_register_stats_callback(nq, nss_codel_stats_callback);
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_CODEL, 0, qopt->accel_mode) < 0) {
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_CODEL, 0, qopt->accel_mode, extack) < 0)
+	{
 		return -EINVAL;
 	}
 
@@ -412,7 +446,11 @@ static int nss_codel_init(struct Qdisc *
 		return -EINVAL;
 	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_codel_change(sch, opt) < 0) {
+#else
+	if (nss_codel_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
@@ -451,7 +489,7 @@ static int nss_codel_dump(struct Qdisc *
 	opt.flows = q->flows;
 	opt.ecn = q->ecn;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -511,7 +549,9 @@ struct Qdisc_ops nss_codel_qdisc_ops __r
 	.enqueue	=	nss_codel_enqueue,
 	.dequeue	=	nss_codel_dequeue,
 	.peek		=	nss_codel_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_codel_drop,
+#endif
 	.init		=	nss_codel_init,
 	.reset		=	nss_codel_reset,
 	.destroy	=	nss_codel_destroy,
@@ -530,7 +570,9 @@ struct Qdisc_ops nss_fq_codel_qdisc_ops
 	.enqueue	=	nss_codel_enqueue,
 	.dequeue	=	nss_codel_dequeue,
 	.peek		=	nss_codel_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_codel_drop,
+#endif
 	.init		=	nss_codel_init,
 	.reset		=	nss_codel_reset,
 	.destroy	=	nss_codel_destroy,
--- a/nss_qdisc/nss_fifo.c
+++ b/nss_qdisc/nss_fifo.c
@@ -29,9 +29,18 @@ static struct nla_policy nss_fifo_policy
 	[TCA_NSSFIFO_PARMS] = { .len = sizeof(struct tc_nssfifo_qopt) },
 };
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_fifo_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_fifo_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 static struct sk_buff *nss_fifo_dequeue(struct Qdisc *sch)
@@ -39,11 +48,13 @@ static struct sk_buff *nss_fifo_dequeue(
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static unsigned int nss_fifo_drop(struct Qdisc *sch)
 {
 	nss_qdisc_info("nss_fifo dropping");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 static void nss_fifo_reset(struct Qdisc *sch)
 {
@@ -64,8 +75,14 @@ static void nss_fifo_destroy(struct Qdis
 	nss_qdisc_info("nss_fifo destroyed");
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_params_validate_and_save(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_fifo_params_validate_and_save(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSFIFO_MAX + 1];
 	struct tc_nssfifo_qopt *qopt;
 	struct nss_fifo_sched_data *q = qdisc_priv(sch);
 	bool is_bfifo = (sch->ops == &nss_bfifo_qdisc_ops);
@@ -74,7 +91,11 @@ static int nss_fifo_params_validate_and_
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS, extack);
+#endif
 	if (!qopt) {
 		nss_qdisc_warning("Invalid input to fifo %x", sch->handle);
 		return -EINVAL;
@@ -101,7 +122,11 @@ static int nss_fifo_params_validate_and_
 }
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_ppe_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_fifo_ppe_change(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_fifo_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
@@ -150,28 +175,45 @@ fail:
 	/*
 	 * Fallback to nss qdisc if PPE Qdisc configuration failed at init time.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_ppe_fallback_to_nss(&q->nq, opt) < 0) {
-		nss_qdisc_warning("nss_fifo %x fallback to nss failed\n", sch->handle);
+#else
+	if (nss_ppe_fallback_to_nss(&q->nq, opt, extack) < 0) {
+#endif
+	nss_qdisc_warning("nss_fifo %x fallback to nss failed\n", sch->handle);
 		return -EINVAL;
 	}
 	return 0;
 }
 #endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_fifo_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_fifo_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
 	struct nss_if_msg nim;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_fifo_params_validate_and_save(sch, opt) < 0) {
+#else
+	if (nss_fifo_params_validate_and_save(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_warning("nss_fifo %px params validate and save failed\n", sch);
 		return -EINVAL;
 	}
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 		if (nss_fifo_ppe_change(sch, opt) < 0) {
+#else
+		if (nss_fifo_ppe_change(sch, opt, extack) < 0) {
+#endif
 			nss_qdisc_warning("nss_fifo %px params validate and save failed\n", sch);
 			return -EINVAL;
 		}
@@ -208,9 +250,17 @@ static int nss_fifo_change(struct Qdisc
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_fifo_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSFIFO_MAX + 1];
 	struct tc_nssfifo_qopt *qopt;
 
 	if (!opt) {
@@ -220,19 +270,28 @@ static int nss_fifo_init(struct Qdisc *s
 	nss_qdisc_info("Initializing Fifo - type %d\n", NSS_SHAPER_NODE_TYPE_FIFO);
 	nss_fifo_reset(sch);
 
-	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS, extack);
+#endif
 	if (!qopt) {
 		nss_qdisc_warning("Invalid input to fifo %x", sch->handle);
 		return -EINVAL;
 	}
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, qopt->accel_mode) < 0) {
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, qopt->accel_mode, extack) < 0)
+	{
 		nss_qdisc_warning("Fifo %x init failed", sch->handle);
 		return -EINVAL;
 	}
 
 	nss_qdisc_info("NSS fifo initialized - handle %x parent %x\n", sch->handle, sch->parent);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_fifo_change(sch, opt) < 0) {
+#else
+	if (nss_fifo_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
@@ -262,7 +321,8 @@ static int nss_fifo_dump(struct Qdisc *s
 	opt.set_default = q->set_default;
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
+
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -290,7 +350,9 @@ struct Qdisc_ops nss_pfifo_qdisc_ops __r
 	.enqueue	=	nss_fifo_enqueue,
 	.dequeue	=	nss_fifo_dequeue,
 	.peek		=	nss_fifo_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_fifo_drop,
+#endif
 	.init		=	nss_fifo_init,
 	.reset		=	nss_fifo_reset,
 	.destroy	=	nss_fifo_destroy,
@@ -305,7 +367,9 @@ struct Qdisc_ops nss_bfifo_qdisc_ops __r
 	.enqueue	=	nss_fifo_enqueue,
 	.dequeue	=	nss_fifo_dequeue,
 	.peek		=	nss_fifo_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_fifo_drop,
+#endif
 	.init		=	nss_fifo_init,
 	.reset		=	nss_fifo_reset,
 	.destroy	=	nss_fifo_destroy,
--- a/nss_qdisc/nss_htb.c
+++ b/nss_qdisc/nss_htb.c
@@ -83,10 +83,16 @@ static inline struct nss_htb_class_data
  * nss_htb_class_params_validate_and_save()
  *	Validates and saves the qdisc configuration parameters.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
 					struct nss_htb_param *param)
+#else
+static int nss_htb_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
+					struct nss_htb_param *param, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nlattr *opt = tca[TCA_OPTIONS];
+	struct nlattr *tb[TCA_NSSHTB_MAX + 1];
 	struct tc_nsshtb_class_qopt *qopt;
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
 	struct net_device *dev = qdisc_dev(sch);
@@ -99,7 +105,11 @@ static int nss_htb_class_params_validate
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, TCA_NSSHTB_MAX, TCA_NSSHTB_CLASS_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_CLASS_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_CLASS_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -219,7 +229,7 @@ static struct nss_htb_class_data *nss_ht
 	 * reference count should not be 0.
 	 */
 	cl->qdisc = &noop_qdisc;
-	atomic_set(&cl->nq.refcnt, 1);
+	nss_qdisc_atomic_set(&cl->nq);
 
 	return cl;
 }
@@ -266,9 +276,16 @@ static int nss_htb_ppe_change_class(stru
  * nss_htb_change_class()
  *	Configures a new class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
 		  struct nlattr **tca, unsigned long *arg)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_htb_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
+		  struct nlattr **tca, unsigned long *arg, struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
 	struct nss_htb_class_data *cl = (struct nss_htb_class_data *)*arg;
 	struct nss_htb_class_data *parent;
@@ -282,7 +299,11 @@ static int nss_htb_change_class(struct Q
 
 	nss_qdisc_trace("configuring htb class %x of qdisc %x\n", classid, sch->handle);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_htb_class_params_validate_and_save(sch, tca, &param) < 0) {
+#else
+	if (nss_htb_class_params_validate_and_save(sch, tca, &param, extack) < 0) {
+#endif
 		nss_qdisc_warning("validation of configuration parameters for htb class %x failed\n",
 					sch->handle);
 		return -EINVAL;
@@ -332,7 +353,8 @@ static int nss_htb_change_class(struct Q
 		 * here.
 		 */
 		cl->nq.parent = nq_parent;
-		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_HTB_GROUP, classid, accel_mode) < 0) {
+		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_HTB_GROUP, classid, accel_mode, extack) < 0)
+		{
 			nss_qdisc_error("nss_init for htb class %x failed\n", classid);
 			goto failure;
 		}
@@ -478,7 +500,7 @@ static void nss_htb_destroy_class(struct
 	/*
 	 * And now we destroy the child.
 	 */
-	qdisc_destroy(cl->qdisc);
+	 nss_qdisc_put(cl->qdisc);
 
 	/*
 	 * Stop the stats polling timer and free class
@@ -500,7 +522,11 @@ static void nss_htb_destroy_class(struct
  * nss_htb_delete_class()
  *	Detaches a class from operation, but does not destroy it.
  */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 12, 0))
+static int nss_htb_delete_class(struct Qdisc *sch, unsigned long arg, struct netlink_ext_ack *extack)
+#else
 static int nss_htb_delete_class(struct Qdisc *sch, unsigned long arg)
+#endif
 {
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
 	struct nss_htb_class_data *cl = (struct nss_htb_class_data *)arg;
@@ -550,7 +576,7 @@ static int nss_htb_delete_class(struct Q
 	 * We simply deduct refcnt and return.
 	 */
 	if (!cl->parent) {
-		refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+		refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
 		sch_tree_unlock(sch);
 		return 0;
 	}
@@ -567,7 +593,7 @@ static int nss_htb_delete_class(struct Q
 	/*
 	 * Decrement refcnt and return
 	 */
-	refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+	refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
 	sch_tree_unlock(sch);
 
 	return 0;
@@ -577,7 +603,12 @@ static int nss_htb_delete_class(struct Q
  * nss_htb_graft_class()
  *	Replaces the qdisc attached to the provided class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new, struct Qdisc **old)
+#else
+static int nss_htb_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new, struct Qdisc **old,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_htb_class_data *cl = (struct nss_htb_class_data *)arg;
 	struct nss_if_msg nim_detach;
@@ -664,6 +695,7 @@ static void nss_htb_qlen_notify(struct Q
 	 */
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 /*
  * nss_htb_get_class()
  *	Fetches the class pointer if provided the classid.
@@ -695,10 +727,22 @@ static void nss_htb_put_class(struct Qdi
 	 * We are safe to destroy the qdisc if the reference count
 	 * goes down to 0.
 	 */
-	if (atomic_sub_return(1, &cl->nq.refcnt) == 0) {
+	if (nss_qdisc_atomic_sub_return(&cl->nq) == 0) {
 		nss_htb_destroy_class(sch, cl);
 	}
 }
+#else
+/*
+ * nss_htb_search_class()
+ *	Fetches the class pointer if provided the classid.
+ */
+static unsigned long nss_htb_search_class(struct Qdisc *sch, u32 classid)
+{
+	struct nss_htb_class_data *cl = nss_htb_find_class(classid, sch);
+
+	return (unsigned long)cl;
+}
+#endif
 
 /*
  * nss_htb_dump_class()
@@ -728,8 +772,7 @@ static int nss_htb_dump_class(struct Qdi
 	tcm->tcm_handle = cl->sch_common.classid;
 	tcm->tcm_info = cl->qdisc->handle;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
-
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSHTB_CLASS_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -750,7 +793,7 @@ static int nss_htb_dump_class_stats(stru
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)arg;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &nq->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &nq->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &nq->qstats) < 0) {
 		nss_qdisc_error("htb class %x stats dump failed\n", nq->qos_tag);
 		return -1;
@@ -795,9 +838,15 @@ static void nss_htb_walk(struct Qdisc *s
  * nss_htb_change_qdisc()
  *	Can be used to configure a htb qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_change_qdisc(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_htb_change_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSHTB_MAX + 1];
 	struct tc_nsshtb_qopt *qopt;
 
 	/*
@@ -820,7 +869,11 @@ static int nss_htb_change_qdisc(struct Q
 	/*
 	 * If it is not NULL, parse to get qopt.
 	 */
-	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -895,7 +948,7 @@ static void nss_htb_destroy_qdisc(struct
 			 * Reduce refcnt by 1 before destroying. This is to
 			 * ensure that polling of stat stops properly.
 			 */
-			atomic_sub(1, &cl->nq.refcnt);
+			 nss_qdisc_atomic_sub(&cl->nq);
 
 			/*
 			 * We are not root class. Therefore we reduce the children count
@@ -945,9 +998,17 @@ static void nss_htb_destroy_qdisc(struct
  * nss_htb_init_qdisc()
  *	Initializes the htb qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_init_qdisc(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_htb_init_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSHTB_MAX + 1];
 	struct tc_nsshtb_qopt *qopt;
 	int err;
 	unsigned int accel_mode;
@@ -964,7 +1025,11 @@ static int nss_htb_init_qdisc(struct Qdi
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_PPE;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
@@ -977,7 +1042,7 @@ static int nss_htb_init_qdisc(struct Qdi
 	/*
 	 * Initialize the NSSHTB shaper in NSS
 	 */
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_HTB, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_HTB, 0, accel_mode, extack) < 0) {
 		nss_qdisc_error("failed to initialize htb qdisc %x in nss", sch->handle);
 		return -EINVAL;
 	}
@@ -987,7 +1052,11 @@ static int nss_htb_init_qdisc(struct Qdi
 	/*
 	 * Tune HTB parameters
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_htb_change_qdisc(sch, opt) < 0) {
+#else
+	if (nss_htb_change_qdisc(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
@@ -1016,7 +1085,8 @@ static int nss_htb_dump_qdisc(struct Qdi
 	qopt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
 	nss_qdisc_info("r2q = %u accel_mode = %u", qopt.r2q, qopt.accel_mode);
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (!opts || nla_put(skb, TCA_NSSHTB_QDISC_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -1032,9 +1102,18 @@ static int nss_htb_dump_qdisc(struct Qdi
  * nss_htb_enqueue()
  *	Enqueues a skb to htb qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_htb_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_htb_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -1046,6 +1125,7 @@ static struct sk_buff *nss_htb_dequeue(s
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_htb_drop()
  *	Drops a single skb from linux queue, if not empty.
@@ -1057,6 +1137,7 @@ static unsigned int nss_htb_drop(struct
 	nss_qdisc_trace("drop called on htb qdisc %x\n", sch->handle);
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * Registration structure for htb class
@@ -1067,9 +1148,17 @@ const struct Qdisc_class_ops nss_htb_cla
 	.graft		= nss_htb_graft_class,
 	.leaf		= nss_htb_leaf_class,
 	.qlen_notify	= nss_htb_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_htb_get_class,
 	.put		= nss_htb_put_class,
+#else
+	.find		=	nss_htb_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block	= nss_qdisc_tcf_block,
+#endif
 	.bind_tcf	= nss_qdisc_tcf_bind,
 	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_htb_dump_class,
@@ -1090,7 +1179,9 @@ struct Qdisc_ops nss_htb_qdisc_ops __rea
 	.enqueue	= nss_htb_enqueue,
 	.dequeue	= nss_htb_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_htb_drop,
+#endif
 	.cl_ops		= &nss_htb_class_ops,
 	.priv_size	= sizeof(struct nss_htb_sched_data),
 	.owner		= THIS_MODULE
--- a/nss_qdisc/nss_ppe.c
+++ b/nss_qdisc/nss_ppe.c
@@ -1773,7 +1773,7 @@ int nss_ppe_set_parent(struct Qdisc *sch
 	struct net_device *dev = qdisc_dev(sch);
 	struct nss_qdisc *parent_nq = NULL;
 	struct Qdisc *parent_qdisc = NULL;
-	unsigned long parent_class;
+	unsigned long parent_class = 0;
 
 	/*
 	 * PPE Qdisc cannot be attached to NSS Qdisc.
@@ -1812,8 +1812,11 @@ int nss_ppe_set_parent(struct Qdisc *sch
 				return NSS_PPE_QDISC_PARENT_NOT_EXISTING;
 			}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 			parent_class = parent_qdisc->ops->cl_ops->get(parent_qdisc, parent);
-
+#else
+			parent_class = parent_qdisc->ops->cl_ops->find(parent_qdisc, parent);
+#endif
 			if (!parent_class) {
 				nq->parent = NULL;
 				nss_qdisc_info("HW qdisc/class %px cannot be attached to non-existing class %x\n", nq->qdisc, parent);
@@ -1822,7 +1825,9 @@ int nss_ppe_set_parent(struct Qdisc *sch
 			}
 
 			nq->parent = (struct nss_qdisc *)parent_class;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 			parent_qdisc->ops->cl_ops->put(parent_qdisc, parent_class);
+#endif
 		}
 	}
 
@@ -2200,14 +2205,22 @@ fail:
  * nss_ppe_fallback_to_nss()
  *	Calls the initialization of NSS Qdisc when PPE initialization fails.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt)
+#else
+int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	nss_qdisc_destroy(nq);
 
 	memset(&nq->npq, 0, sizeof(struct nss_ppe_qdisc));
 	nq->ppe_init_failed = true;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nq->qdisc->ops->init(nq->qdisc, opt) < 0) {
+#else
+	if (nq->qdisc->ops->init(nq->qdisc, opt, extack) < 0) {
+#endif
 			nss_qdisc_warning("Fallback to NSS Qdisc failed.\n");
 			return -EINVAL;
 	}
--- a/nss_qdisc/nss_ppe.h
+++ b/nss_qdisc/nss_ppe.h
@@ -269,7 +269,11 @@ extern int nss_ppe_configure(struct nss_
  * nss_ppe_fallback_to_nss()
  *	Calls the initialization of NSS Qdisc when PPE initialization fails.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 extern int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt);
+#else
+extern int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt, struct netlink_ext_ack *extack);
+#endif
 
 /*
  * nss_ppe_destroy()
--- a/nss_qdisc/nss_prio.c
+++ b/nss_qdisc/nss_prio.c
@@ -37,9 +37,18 @@ static struct nla_policy nss_prio_policy
  * nss_prio_enqueue()
  *	Enqueues a skb to nssprio qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_prio_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_prio_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -51,6 +60,7 @@ static struct sk_buff *nss_prio_dequeue(
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_prio_drop()
  *	Drops a single skb from linux queue, if not empty.
@@ -61,6 +71,7 @@ static unsigned int nss_prio_drop(struct
 {
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_prio_peek()
@@ -117,7 +128,11 @@ static void nss_prio_destroy(struct Qdis
 		/*
 		 * We can now destroy it
 		 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0))
 		qdisc_destroy(q->queues[i]);
+#else
+		qdisc_put(q->queues[i]);
+#endif
 	}
 
 	/*
@@ -157,8 +172,14 @@ static int nss_prio_get_max_bands(struct
  * nss_prio_change()
  *	Function call to configure the nssprio parameters
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_prio_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_prio_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSPRIO_MAX + 1];
 	struct nss_prio_sched_data *q;
 	struct tc_nssprio_qopt *qopt;
 
@@ -180,7 +201,11 @@ static int nss_prio_change(struct Qdisc
 		return 0;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -209,9 +234,17 @@ static int nss_prio_change(struct Qdisc
  * nss_prio_init()
  *	Initializes the nssprio qdisc
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_prio_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_prio_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_prio_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSPRIO_MAX + 1];
 	struct tc_nssprio_qopt *qopt;
 	int i;
 	unsigned int accel_mode;
@@ -223,21 +256,30 @@ static int nss_prio_init(struct Qdisc *s
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_PPE;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
 		accel_mode = qopt->accel_mode;
 	}
 
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_PRIO, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_PRIO, 0, accel_mode, extack) < 0)
+	{
 		return -EINVAL;
 	}
 
 	nss_qdisc_info("Nssprio initialized - handle %x parent %x\n",
 			sch->handle, sch->parent);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_prio_change(sch, opt) < 0) {
+#else
+	if (nss_prio_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
@@ -263,7 +305,7 @@ static int nss_prio_dump(struct Qdisc *s
 	qopt.bands = q->bands;
 	qopt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSPRIO_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -279,8 +321,14 @@ nla_put_failure:
  * nss_prio_graft()
  *	Replaces existing child qdisc with the new qdisc that is passed.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_prio_graft(struct Qdisc *sch, unsigned long arg,
 				struct Qdisc *new, struct Qdisc **old)
+#else
+static int nss_prio_graft(struct Qdisc *sch, unsigned long arg,
+				struct Qdisc *new, struct Qdisc **old,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_prio_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq_new = qdisc_priv(new);
@@ -365,6 +413,7 @@ static struct Qdisc *nss_prio_leaf(struc
 	return q->queues[band];
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 /*
  * nss_prio_get()
  *	Returns the band if provided the classid.
@@ -390,6 +439,24 @@ static void nss_prio_put(struct Qdisc *s
 {
 	nss_qdisc_info("Inside prio put\n");
 }
+#else
+/*
+ * nss_prio_search()
+ *	Returns the band if provided the classid.
+ */
+static unsigned long nss_prio_search(struct Qdisc *sch, u32 classid)
+{
+	struct nss_prio_sched_data *q = qdisc_priv(sch);
+	unsigned long band = TC_H_MIN(classid);
+
+	nss_qdisc_info("Inside get. Handle - %x Classid - %x Band %lu Available band %u\n", sch->handle, classid, band, q->bands);
+
+	if (band > q->bands)
+		return 0;
+
+	return band;
+}
+#endif
 
 /*
  * nss_prio_walk()
@@ -446,7 +513,7 @@ static int nss_prio_dump_class_stats(str
 	cl_q = q->queues[cl - 1];
 	cl_q->qstats.qlen = cl_q->q.qlen;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &cl_q->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &cl_q->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &cl_q->qstats) < 0)
 		return -1;
 
@@ -460,9 +527,17 @@ static int nss_prio_dump_class_stats(str
 const struct Qdisc_class_ops nss_prio_class_ops = {
 	.graft		=	nss_prio_graft,
 	.leaf		=	nss_prio_leaf,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		=	nss_prio_get,
 	.put		=	nss_prio_put,
+#else
+	.find       =   nss_prio_search,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	.tcf_chain	=	nss_qdisc_tcf_chain,
+#else
+	.tcf_block	=	nss_qdisc_tcf_block,
+#endif
 	.bind_tcf	=	nss_qdisc_tcf_bind,
 	.unbind_tcf	=	nss_qdisc_tcf_unbind,
 	.walk		=	nss_prio_walk,
@@ -481,7 +556,9 @@ struct Qdisc_ops nss_prio_qdisc_ops __re
 	.enqueue	=	nss_prio_enqueue,
 	.dequeue	=	nss_prio_dequeue,
 	.peek		=	nss_prio_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_prio_drop,
+#endif
 	.init		=	nss_prio_init,
 	.reset		=	nss_prio_reset,
 	.destroy	=	nss_prio_destroy,
--- a/nss_qdisc/nss_qdisc.c
+++ b/nss_qdisc/nss_qdisc.c
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2020 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2021 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -927,7 +927,11 @@ static inline void nss_qdisc_add_to_tail
 	 * We do not use the qdisc_enqueue_tail() API here in order
 	 * to prevent stats from getting updated by the API.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	__skb_queue_tail(&sch->q, skb);
+#else
+	__qdisc_enqueue_tail(skb, &sch->q);
+#endif
 
 	spin_unlock_bh(&nq->bounce_protection_lock);
 };
@@ -942,7 +946,11 @@ static inline void nss_qdisc_add_to_tail
 	 * We do not use the qdisc_enqueue_tail() API here in order
 	 * to prevent stats from getting updated by the API.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	__skb_queue_tail(&sch->q, skb);
+#else
+	__qdisc_enqueue_tail(skb, &sch->q);
+#endif
 };
 
 /*
@@ -964,10 +972,12 @@ static inline struct sk_buff *nss_qdisc_
 	 * We use __skb_dequeue() to ensure that
 	 * stats don't get updated twice.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0))
 	skb = __skb_dequeue(&sch->q);
-
+#else
+	skb = __qdisc_dequeue_head(&sch->q);
+#endif
 	spin_unlock_bh(&nq->bounce_protection_lock);
-
 	return skb;
 };
 
@@ -981,7 +991,11 @@ static inline struct sk_buff *nss_qdisc_
 	 * We use __skb_dequeue() to ensure that
 	 * stats don't get updated twice.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0))
 	return __skb_dequeue(&sch->q);
+#else
+	return __qdisc_dequeue_head(&sch->q);
+#endif
 };
 
 /*
@@ -1059,24 +1073,33 @@ struct Qdisc *nss_qdisc_replace(struct Q
  * nss_qdisc_qopt_get()
  *	Extracts qopt from opt.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params)
+#else
 void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
-				uint32_t tca_max, uint32_t tca_params)
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params, struct netlink_ext_ack *extack)
+#endif
 {
-	struct nlattr *na[tca_max + 1];
 	int err;
 
 	if (!opt) {
 		return NULL;
 	}
 
-	err = nla_parse_nested(na, tca_max, opt, policy);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	err = nla_parse_nested(tb, tca_max, opt, policy);
+#else
+	err = nla_parse_nested_deprecated(tb, tca_max, opt, policy, extack);
+#endif
+
 	if (err < 0)
 		return NULL;
 
-	if (na[tca_params] == NULL)
+	if (tb[tca_params] == NULL)
 		return NULL;
 
-	return nla_data(na[tca_params]);
+	return nla_data(tb[tca_params]);
 }
 
 /*
@@ -1102,16 +1125,17 @@ struct sk_buff *nss_qdisc_peek(struct Qd
 	struct sk_buff *skb;
 
 	if (!nq->is_virtual) {
-		skb = skb_peek(&sch->q);
+		skb = qdisc_peek_head(sch);
 	} else {
 		spin_lock_bh(&nq->bounce_protection_lock);
-		skb = skb_peek(&sch->q);
+		skb = qdisc_peek_head(sch);
 		spin_unlock_bh(&nq->bounce_protection_lock);
 	}
 
 	return skb;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_qdisc_drop()
  *	Called to drop the packet at the head of queue
@@ -1134,6 +1158,7 @@ unsigned int nss_qdisc_drop(struct Qdisc
 
 	return ret;
 }
+#endif
 
 /*
  * nss_qdisc_reset()
@@ -1181,7 +1206,11 @@ static bool nss_qdisc_iterate_fl(struct
 		return 0;
 	}
 
-	status = tc_classify(skb, tcf, &res, false);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 15, 0))
+	status = tcf_classify(skb, tcf, &res, false);
+#else
+	status = tcf_classify(skb, NULL, tcf, &res, false);
+#endif
 	if ((status == TC_ACT_STOLEN) || (status == TC_ACT_QUEUED)) {
 		return 1;
 	}
@@ -1203,7 +1232,11 @@ static bool nss_qdisc_iterate_fl(struct
  * nss_qdisc_enqueue()
  *	Generic enqueue call for enqueuing packets into NSS for shaping
  */
-int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
+extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free)
+#endif
 {
 	struct nss_qdisc *nq = qdisc_priv(sch);
 	nss_tx_status_t status;
@@ -1263,11 +1296,18 @@ int nss_qdisc_enqueue(struct sk_buff *sk
 	/*
 	 * Skip the shaping of already shaped packets.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	if (skb->tc_verd & TC_NCLS_NSS) {
 		skb->tc_verd = CLR_TC_NCLS_NSS(skb->tc_verd);
 		nss_qdisc_mark_and_schedule(nq->qdisc, skb);
 		return NET_XMIT_SUCCESS;
 	}
+#else
+	if (skb_skip_tc_classify_offload(skb)) {
+		nss_qdisc_mark_and_schedule(nq->qdisc, skb);
+		return NET_XMIT_SUCCESS;
+	}
+#endif
 
 	if (!nq->is_virtual) {
 		/*
@@ -1316,12 +1356,15 @@ enqueue_drop:
 	 * We were unable to transmit the packet for bridge shaping.
 	 * We therefore drop it.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	kfree_skb(skb);
 
 	spin_lock_bh(&nq->lock);
 	sch->qstats.drops++;
 	spin_unlock_bh(&nq->lock);
-
+#else
+	qdisc_drop(skb, sch, to_free);
+#endif
 	return NET_XMIT_DROP;
 }
 
@@ -1882,7 +1925,12 @@ void nss_qdisc_destroy(struct nss_qdisc
 	/*
 	 * Destroy any attached filter over qdisc.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	tcf_destroy_chain(&nq->filter_list);
+#else
+	tcf_block_put(nq->block);
+#endif
+
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
 		nss_ppe_destroy(nq);
@@ -1960,12 +2008,19 @@ void nss_qdisc_destroy(struct nss_qdisc
 }
 
 /*
- * nss_qdisc_init()
+ * __nss_qdisc_init()
  *	Initializes a shaper in NSS, based on the position of this qdisc (child or root)
  *	and if its a normal interface or a bridge interface.
  */
-int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+int __nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode)
+{
+#else
+int __nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode,
+		struct netlink_ext_ack *extack)
 {
+	int err;
+#endif
 	struct Qdisc *root;
 	u32 parent;
 	nss_tx_status_t rc;
@@ -1978,7 +2033,6 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	bool mode_ppe = false;
 #endif
 	bool igs_put = false;
-
 	if (accel_mode >= TCA_NSS_ACCEL_MODE_MAX) {
 		nss_qdisc_warning("Qdisc %px (type %d) accel_mode:%u should be < %u\n",
 					sch, nq->type, accel_mode, TCA_NSS_ACCEL_MODE_MAX);
@@ -2037,8 +2091,9 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	/*
 	 * Initialize filter list.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	RCU_INIT_POINTER(nq->filter_list, NULL);
-
+#endif
 	/*
 	 * If we are a class, then classid is used as the qos tag.
 	 * Else the qdisc handle will be used as the qos tag.
@@ -2073,6 +2128,25 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * or on a net device that is represented by a virtual NSS interface (e.g. WIFI)
 	 */
 	dev = qdisc_dev(sch);
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+	/*
+	 * Currently filter addition is only supported over IFB interfaces.
+	 * Therefore, perform tcf block allocation (which is used for storing
+	 * filter list) only if the input net device is an IFB device.
+	 */
+	if (netif_is_ifb_dev(dev)) {
+		err = tcf_block_get(&nq->block, &nq->filter_list, sch, extack);
+		if (err) {
+			nss_qdisc_error("%px: Unable to initialize tcf_block\n", &nq->block);
+			return -1;
+		}
+	} else {
+		RCU_INIT_POINTER(nq->filter_list, NULL);
+		nq->block = NULL;
+	}
+#endif
+
 	nss_qdisc_info("Qdisc %px (type %d) init dev: %px\n", nq->qdisc, nq->type, dev);
 
 	/*
@@ -2098,6 +2172,8 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * This is to prevent mixing NSS and PPE qdisc with linux qdisc.
 	 */
 	if ((parent != TC_H_ROOT) && (root->ops->owner != THIS_MODULE)) {
+		nss_qdisc_warning("parent (%d) and TC_H_ROOT (%d))", parent, TC_H_ROOT);
+		nss_qdisc_warning("root->ops->owner (%px) and THIS_MODULE (%px))", root->ops->owner , THIS_MODULE);
 		nss_qdisc_warning("NSS qdisc %px (type %d) used along with non-nss qdiscs,"
 			" or the interface is currently down", nq->qdisc, nq->type);
 	}
@@ -2394,7 +2470,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		if (igs_put) {
 			nss_igs_module_put();
 		}
-		nss_qdisc_error("init for qdisc %x timedout!\n", nq->qos_tag);
+	nss_qdisc_error("init for qdisc %x timedout!\n", nq->qos_tag);
 		return -1;
 	}
 
@@ -2465,6 +2541,20 @@ init_fail:
 }
 
 /*
+ * nss_qdisc_init()
+ *	Initialize nss qdisc based on position of the qdisc
+ */
+int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid,
+		uint32_t accel_mode, void *extack)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	return __nss_qdisc_init(sch, nq, type, classid, accel_mode);
+#else
+	return __nss_qdisc_init(sch, nq, type, classid, accel_mode, extack);
+#endif
+}
+
+/*
  * nss_qdisc_basic_stats_callback()
  *	Invoked after getting basic stats
  */
@@ -2476,7 +2566,11 @@ static void nss_qdisc_basic_stats_callba
 	struct gnet_stats_basic_packed *bstats;
 	struct gnet_stats_queue *qstats;
 	struct nss_shaper_node_stats_response *response;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
 	atomic_t *refcnt;
+#else
+	refcount_t *refcnt;
+#endif
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
 		nss_qdisc_warning("Qdisc %px (type %d): Receive stats FAILED - "
@@ -2539,7 +2633,11 @@ static void nss_qdisc_basic_stats_callba
 	 * All access to nq fields below do not need lock protection. They
 	 * do not get manipulated on different thread contexts.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
 	if (atomic_read(refcnt) == 0) {
+#else
+	if (refcount_read(refcnt) == 0) {
+#endif
 		atomic_sub(1, &nq->pending_stat_requests);
 		wake_up(&nq->wait_queue);
 		return;
@@ -2561,9 +2659,18 @@ static void nss_qdisc_basic_stats_callba
  * nss_qdisc_get_stats_timer_callback()
  *	Invoked periodically to get updated stats
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0))
 static void nss_qdisc_get_stats_timer_callback(unsigned long int data)
+#else
+static void nss_qdisc_get_stats_timer_callback(struct timer_list *tm)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0))
 	struct nss_qdisc *nq = (struct nss_qdisc *)data;
+#else
+	struct nss_qdisc *nq = from_timer(nq, tm, stats_get_timer);
+#endif
+
 	nss_tx_status_t rc;
 	struct nss_if_msg nim;
 	int msg_type;
@@ -2610,9 +2717,14 @@ void nss_qdisc_start_basic_stats_polling
 		return;
 	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0))
 	init_timer(&nq->stats_get_timer);
 	nq->stats_get_timer.function = nss_qdisc_get_stats_timer_callback;
 	nq->stats_get_timer.data = (unsigned long)nq;
+#else
+	timer_setup(&nq->stats_get_timer, nss_qdisc_get_stats_timer_callback, 0);
+#endif
+
 	nq->stats_get_timer.expires = jiffies + HZ;
 	atomic_set(&nq->pending_stat_requests, 1);
 	add_timer(&nq->stats_get_timer);
@@ -2650,13 +2762,15 @@ void nss_qdisc_stop_basic_stats_polling(
  * nss_qdisc_gnet_stats_copy_basic()
  *  Wrapper around gnet_stats_copy_basic()
  */
-int nss_qdisc_gnet_stats_copy_basic(struct gnet_dump *d,
+int nss_qdisc_gnet_stats_copy_basic(struct Qdisc *sch, struct gnet_dump *d,
 				struct gnet_stats_basic_packed *b)
 {
 #if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 18, 0))
 	return gnet_stats_copy_basic(d, b);
-#else
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return gnet_stats_copy_basic(d, NULL, b);
+#else
+	return gnet_stats_copy_basic(qdisc_root_sleeping_running(sch), d, NULL, b);
 #endif
 }
 
@@ -2695,10 +2809,8 @@ static int nss_qdisc_if_event_cb(struct
 
 	switch (event) {
 	case NETDEV_BR_JOIN:
-		nss_qdisc_info("Reveived NETDEV_BR_JOIN on interface %s\n",
-				dev->name);
 	case NETDEV_BR_LEAVE:
-		nss_qdisc_info("Reveived NETDEV_BR_LEAVE on interface %s\n",
+		nss_qdisc_info("Received NETDEV_BR_JOIN/NETDEV_BR_LEAVE on interface %s\n",
 				dev->name);
 		br = nss_qdisc_get_dev_master(dev);
 		if_num = nss_cmn_get_interface_number(nss_qdisc_ctx, dev);
@@ -2754,6 +2866,7 @@ static int nss_qdisc_if_event_cb(struct
 	return NOTIFY_DONE;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 /*
  * nss_qdisc_tcf_chain()
  *	Return the filter list of qdisc.
@@ -2778,8 +2891,29 @@ struct tcf_proto __rcu **nss_qdisc_tcf_c
 	if (nq->is_root) {
 		return &(nq->filter_list);
 	}
+
+	return NULL;
+}
+#else
+/*
+ * nss_qdisc_tcf_block()
+ *	Return the block containing chain of qdisc.
+ */
+struct tcf_block *nss_qdisc_tcf_block(struct Qdisc *sch, unsigned long cl, struct netlink_ext_ack *extack)
+{
+	struct nss_qdisc *nq = qdisc_priv(sch);
+
+	/*
+	 * Currently, support is available only for tc filter iterations
+	 * at root qdisc.
+	 */
+	if (nq->is_root) {
+		return nq->block;
+	}
+
 	return NULL;
 }
+#endif
 
 /*
  * nss_qdisc_tcf_bind()
--- a/nss_qdisc/nss_qdisc.h
+++ b/nss_qdisc/nss_qdisc.h
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2018 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2018, 2020 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -20,6 +20,7 @@
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
 #include <net/pkt_sched.h>
+#include <net/pkt_cls.h>
 #include <net/inet_ecn.h>
 #include <net/netfilter/nf_conntrack.h>
 #include <linux/if_bridge.h>
@@ -27,6 +28,9 @@
 #include <linux/version.h>
 #include <br_private.h>
 #include <nss_api_if.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+#include <linux/netlink.h>
+#endif
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 #include "nss_ppe.h"
@@ -186,7 +190,11 @@ struct nss_qdisc {
 						 */
 	struct gnet_stats_basic_packed bstats;	/* Basic class statistics */
 	struct gnet_stats_queue qstats;		/* Qstats for use by classes */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
 	atomic_t refcnt;			/* Reference count for class use */
+#else
+	refcount_t refcnt;			/* Reference count for class use */
+#endif
 	struct timer_list stats_get_timer;	/* Timer used to poll for stats */
 	atomic_t pending_stat_requests;		/* Number of pending stats responses */
 	wait_queue_head_t wait_queue;		/* Wait queue used to wait on responses from the NSS */
@@ -201,6 +209,9 @@ struct nss_qdisc {
 						 */
 #endif
 	struct tcf_proto __rcu *filter_list;	/* Filter list */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+	struct tcf_block *block;
+#endif
 };
 
 /*
@@ -238,11 +249,81 @@ enum nss_qdisc_hybrid_mode {
 };
 
 /*
+ * nss_qdisc_nla_nest_start()
+ *	Returns the container attribute
+ */
+static inline struct nlattr * nss_qdisc_nla_nest_start(struct sk_buff *skb, int attrtype)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	return nla_nest_start(skb, TCA_OPTIONS);
+#else
+	return nla_nest_start_noflag(skb, TCA_OPTIONS);
+#endif
+}
+
+/*
+ * nss_qdisc_atomic_sub()
+ *	Atomically decrements the ref count by 1
+ */
+static inline void nss_qdisc_atomic_sub(struct nss_qdisc *nq)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	atomic_sub(1, &nq->refcnt);
+#else
+	atomic_sub(1, &nq->refcnt.refs);
+#endif
+}
+
+/*
+ * nss_qdisc_atomic_sub_return()
+ *	Atomically decrements the ref count by 1 and return ref count
+ */
+static inline int nss_qdisc_atomic_sub_return(struct nss_qdisc *nq)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	return atomic_sub_return(1, &nq->refcnt);
+#else
+	return atomic_sub_return(1, &nq->refcnt.refs);
+#endif
+}
+
+/*
+ * nss_qdisc_atomic_set()
+ *	Atomically sets the ref count by 1
+ */
+static inline void nss_qdisc_atomic_set(struct nss_qdisc *nq)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	atomic_set(&nq->refcnt, 1);
+#else
+	refcount_set(&nq->refcnt, 1);
+#endif
+}
+
+/*
+ * nss_qdisc_put()
+ *	Destroy the qdisc
+ */
+static inline void nss_qdisc_put(struct Qdisc *sch)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0))
+	qdisc_destroy(sch);
+#else
+	qdisc_put(sch);
+#endif
+}
+
+/*
  * nss_qdisc_qopt_get()
  *	Extracts qopt from opt.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 extern void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
-				uint32_t tca_max, uint32_t tca_params);
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params);
+#else
+extern void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params, struct netlink_ext_ack *extack);
+#endif
 
 /*
  * nss_qdisc_mode_get()
@@ -256,11 +337,13 @@ extern uint8_t nss_qdisc_accel_mode_get(
  */
 extern struct sk_buff *nss_qdisc_peek(struct Qdisc *sch);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_qdisc_drop()
  *	Called to drop the packet at the head of queue
  */
 extern unsigned int nss_qdisc_drop(struct Qdisc *sch);
+#endif
 
 /*
  * nss_qdisc_reset()
@@ -272,7 +355,11 @@ extern void nss_qdisc_reset(struct Qdisc
  * nss_qdisc_enqueue()
  *	Generic enqueue call for enqueuing packets into NSS for shaping
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch);
+#else
+extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free);
+#endif
 
 /*
  * nss_qdisc_dequeue()
@@ -338,7 +425,8 @@ extern void nss_qdisc_destroy(struct nss
  *	Initializes a shaper in NSS, based on the position of this qdisc (child or root)
  *	and if its a normal interface or a bridge interface.
  */
-extern int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode);
+extern int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode,
+		void *extack);
 
 /*
  * nss_qdisc_start_basic_stats_polling()
@@ -356,8 +444,8 @@ extern void nss_qdisc_stop_basic_stats_p
  * nss_qdisc_gnet_stats_copy_basic()
  *  Wrapper around gnet_stats_copy_basic()
  */
-extern int nss_qdisc_gnet_stats_copy_basic(struct gnet_dump *d,
-				struct gnet_stats_basic_packed *b);
+extern int nss_qdisc_gnet_stats_copy_basic(struct Qdisc *sch,
+				struct gnet_dump *d, struct gnet_stats_basic_packed *b);
 
 /*
  * nss_qdisc_gnet_stats_copy_queue()
@@ -373,11 +461,19 @@ extern int nss_qdisc_gnet_stats_copy_que
 extern struct Qdisc *nss_qdisc_replace(struct Qdisc *sch, struct Qdisc *new,
 					struct Qdisc **pold);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 /*
  * nss_qdisc_tcf_chain()
  *	Return the filter list of qdisc.
  */
 extern struct tcf_proto __rcu **nss_qdisc_tcf_chain(struct Qdisc *sch, unsigned long arg);
+#else
+/*
+ * nss_qdisc_tcf_block()
+ *	Return the block containing chain of qdisc.
+ */
+extern struct tcf_block *nss_qdisc_tcf_block(struct Qdisc *sch, unsigned long cl, struct netlink_ext_ack *extack);
+#endif
 
 /*
  * nss_qdisc_tcf_bind()
--- a/nss_qdisc/nss_tbl.c
+++ b/nss_qdisc/nss_tbl.c
@@ -29,9 +29,18 @@ static struct nla_policy nss_tbl_policy[
 	[TCA_NSSTBL_PARMS] = { .len = sizeof(struct tc_nsstbl_qopt) },
 };
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_tbl_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_tbl_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 static struct sk_buff *nss_tbl_dequeue(struct Qdisc *sch)
@@ -39,10 +48,12 @@ static struct sk_buff *nss_tbl_dequeue(s
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static unsigned int nss_tbl_drop(struct Qdisc *sch)
 {
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 static struct sk_buff *nss_tbl_peek(struct Qdisc *sch)
 {
@@ -77,7 +88,7 @@ static void nss_tbl_destroy(struct Qdisc
 	/*
 	 * Now we can destroy our child qdisc
 	 */
-	qdisc_destroy(q->qdisc);
+	 nss_qdisc_put(q->qdisc);
 
 	/*
 	 * Stop the polling of basic stats and destroy qdisc.
@@ -87,7 +98,11 @@ static void nss_tbl_destroy(struct Qdisc
 }
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_ppe_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_tbl_ppe_change(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
@@ -123,8 +138,12 @@ fail:
 	/*
 	 * PPE qdisc config failed, try to initialize in NSS.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_ppe_fallback_to_nss(nq, opt)) {
-		nss_qdisc_warning("nss_tbl %x fallback to nss failed\n", sch->handle);
+#else
+	if (nss_ppe_fallback_to_nss(nq, opt, extack)) {
+#endif
+	nss_qdisc_warning("nss_tbl %x fallback to nss failed\n", sch->handle);
 		return -EINVAL;
 	}
 
@@ -132,9 +151,15 @@ fail:
 }
 #endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_tbl_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSTBL_MAX + 1];
 	struct tc_nsstbl_qopt *qopt;
 	struct nss_if_msg nim;
 	struct net_device *dev = qdisc_dev(sch);
@@ -143,7 +168,11 @@ static int nss_tbl_change(struct Qdisc *
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -178,7 +207,11 @@ static int nss_tbl_change(struct Qdisc *
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (q->nq.mode == NSS_QDISC_MODE_PPE) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 		if (nss_tbl_ppe_change(sch, opt) < 0) {
+#else
+		if (nss_tbl_ppe_change(sch, opt, extack) < 0) {
+#endif
 			nss_qdisc_warning("nss_tbl %x SSDK scheduler config failed\n", sch->handle);
 			return -EINVAL;
 		}
@@ -216,9 +249,17 @@ static int nss_tbl_change(struct Qdisc *
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_tbl_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSTBL_MAX + 1];
 	struct tc_nsstbl_qopt *qopt;
 
 	if (!opt) {
@@ -227,15 +268,25 @@ static int nss_tbl_init(struct Qdisc *sc
 
 	q->qdisc = &noop_qdisc;
 
-	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
 
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_TBL, 0, qopt->accel_mode) < 0)
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_TBL, 0, qopt->accel_mode, extack) < 0)
+	{
 		return -EINVAL;
+	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_tbl_change(sch, opt) < 0) {
+#else
+	if (nss_tbl_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_info("Failed to configure tbl\n");
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
@@ -262,7 +313,8 @@ static int nss_tbl_dump(struct Qdisc *sc
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
 	nss_qdisc_info("Nsstbl dumping");
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSTBL_PARMS, sizeof(opt), &opt)) {
 		goto nla_put_failure;
 	}
@@ -286,8 +338,13 @@ static int nss_tbl_dump_class(struct Qdi
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_graft(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
 			struct Qdisc **old)
+#else
+static int nss_tbl_graft(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
+			struct Qdisc **old, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq_new = (struct nss_qdisc *)qdisc_priv(new);
@@ -339,6 +396,7 @@ static struct Qdisc *nss_tbl_leaf(struct
 	return q->qdisc;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 static unsigned long nss_tbl_get(struct Qdisc *sch, u32 classid)
 {
 	return 1;
@@ -347,6 +405,12 @@ static unsigned long nss_tbl_get(struct
 static void nss_tbl_put(struct Qdisc *sch, unsigned long arg)
 {
 }
+#else
+static unsigned long nss_tbl_search(struct Qdisc *sch, u32 classid)
+{
+	return 1;
+}
+#endif
 
 static void nss_tbl_walk(struct Qdisc *sch, struct qdisc_walker *walker)
 {
@@ -364,9 +428,17 @@ static void nss_tbl_walk(struct Qdisc *s
 const struct Qdisc_class_ops nss_tbl_class_ops = {
 	.graft		=	nss_tbl_graft,
 	.leaf		=	nss_tbl_leaf,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		=	nss_tbl_get,
 	.put		=	nss_tbl_put,
+#else
+	.find       =   nss_tbl_search,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	.tcf_chain	=	nss_qdisc_tcf_chain,
+#else
+	.tcf_block	=	nss_qdisc_tcf_block,
+#endif
 	.bind_tcf	=	nss_qdisc_tcf_bind,
 	.unbind_tcf	=	nss_qdisc_tcf_unbind,
 	.walk		=	nss_tbl_walk,
@@ -381,7 +453,9 @@ struct Qdisc_ops nss_tbl_qdisc_ops __rea
 	.enqueue	=	nss_tbl_enqueue,
 	.dequeue	=	nss_tbl_dequeue,
 	.peek		=	nss_tbl_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_tbl_drop,
+#endif
 	.init		=	nss_tbl_init,
 	.reset		=	nss_tbl_reset,
 	.destroy	=	nss_tbl_destroy,
--- a/nss_qdisc/nss_wred.c
+++ b/nss_qdisc/nss_wred.c
@@ -55,9 +55,18 @@ static struct nla_policy nss_wred_policy
  * nss_wred_enqueue()
  *	Enqueue API for nsswred qdisc
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_wred_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_wred_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -69,6 +78,7 @@ static struct sk_buff *nss_wred_dequeue(
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_wred_drop()
  *	Drops a packet from HLOS queue.
@@ -78,6 +88,7 @@ static unsigned int nss_wred_drop(struct
 	nss_qdisc_info("nsswred dropping");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_wred_reset()
@@ -111,7 +122,11 @@ static void nss_wred_destroy(struct Qdis
  * nss_wred_ppe_change()
  *	Function call to configure the nssred parameters for ppe qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wred_ppe_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_wred_ppe_change(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_wred_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
@@ -159,8 +174,12 @@ fail:
 	/*
 	 * Fallback to nss qdisc if PPE Qdisc configuration failed at init time.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_ppe_fallback_to_nss(&q->nq, opt) < 0) {
-		nss_qdisc_warning("nss_wred %x fallback to nss failed\n", sch->handle);
+#else
+	if (nss_ppe_fallback_to_nss(&q->nq, opt, extack) < 0) {
+#endif
+	nss_qdisc_warning("nss_wred %x fallback to nss failed\n", sch->handle);
 		return -EINVAL;
 	}
 	return 0;
@@ -171,9 +190,15 @@ fail:
  * nss_wred_change()
  *	Function call to configure the nsswred parameters
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wred_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_wred_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_wred_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSWRED_MAX + 1];
 	struct tc_nsswred_qopt *qopt;
 	struct nss_if_msg nim;
 
@@ -181,7 +206,11 @@ static int nss_wred_change(struct Qdisc
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -253,7 +282,11 @@ static int nss_wred_change(struct Qdisc
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (q->nq.mode == NSS_QDISC_MODE_PPE) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 		if (nss_wred_ppe_change(sch, opt) < 0) {
+#else
+		if (nss_wred_ppe_change(sch, opt, extack) < 0) {
+#endif
 			nss_qdisc_warning("nss_wred %px params validate and save failed\n", sch);
 			return -EINVAL;
 		}
@@ -298,16 +331,28 @@ static int nss_wred_change(struct Qdisc
  * nss_wred_init()
  *	Init the nsswred qdisc
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wred_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_wred_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSWRED_MAX + 1];
 	struct tc_nsswred_qopt *qopt;
 
 	if (opt == NULL) {
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -315,11 +360,17 @@ static int nss_wred_init(struct Qdisc *s
 	nss_qdisc_info("Initializing Wred - type %d\n", NSS_SHAPER_NODE_TYPE_WRED);
 	nss_wred_reset(sch);
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_WRED, 0, qopt->accel_mode) < 0)
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_WRED, 0, qopt->accel_mode, extack) < 0)
+	{
 		return -EINVAL;
+	}
 
 	nss_qdisc_info("NSS wred initialized - handle %x parent %x\n", sch->handle, sch->parent);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_wred_change(sch, opt) < 0) {
+#else
+	if (nss_wred_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
@@ -374,7 +425,7 @@ static int nss_wred_dump(struct Qdisc *s
 	opt.set_default = q->set_default;
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSWRED_PARMS, sizeof(opt), &opt)) {
 		goto nla_put_failure;
 	}
@@ -405,7 +456,9 @@ struct Qdisc_ops nss_red_qdisc_ops __rea
 	.enqueue	=	nss_wred_enqueue,
 	.dequeue	=	nss_wred_dequeue,
 	.peek		=	nss_wred_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_wred_drop,
+#endif
 	.init		=	nss_wred_init,
 	.reset		=	nss_wred_reset,
 	.destroy	=	nss_wred_destroy,
@@ -423,7 +476,9 @@ struct Qdisc_ops nss_wred_qdisc_ops __re
 	.enqueue	=	nss_wred_enqueue,
 	.dequeue	=	nss_wred_dequeue,
 	.peek		=	nss_wred_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_wred_drop,
+#endif
 	.init		=	nss_wred_init,
 	.reset		=	nss_wred_reset,
 	.destroy	=	nss_wred_destroy,
--- a/nss_qdisc/nss_wrr.c
+++ b/nss_qdisc/nss_wrr.c
@@ -84,7 +84,7 @@ static void nss_wrr_destroy_class(struct
 	/*
 	 * And now we destroy the child.
 	 */
-	qdisc_destroy(cl->qdisc);
+	 nss_qdisc_put(cl->qdisc);
 
 	/*
 	 * Stop the stats polling timer and free class
@@ -106,9 +106,15 @@ static void nss_wrr_destroy_class(struct
  * nss_wrr_class_params_validate_and_save()
  *	Validates and saves the class configuration parameters.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
 					uint32_t *quantum)
+#else
+static int nss_wrr_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
+					uint32_t *quantum, struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSWRR_MAX + 1];
 	struct nlattr *opt = tca[TCA_OPTIONS];
 	struct tc_nsswrr_class_qopt *qopt;
 	struct net_device *dev = qdisc_dev(sch);
@@ -123,7 +129,11 @@ static int nss_wrr_class_params_validate
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, TCA_NSSWRR_MAX, TCA_NSSWRR_CLASS_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_CLASS_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_CLASS_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -218,9 +228,16 @@ static int nss_wrr_ppe_change_class(stru
 }
 #endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
 		  struct nlattr **tca, unsigned long *arg)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_wrr_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
+		  struct nlattr **tca, unsigned long *arg, struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)*arg;
 	struct nss_if_msg nim_config;
@@ -230,7 +247,11 @@ static int nss_wrr_change_class(struct Q
 
 	nss_qdisc_info("Changing nss_wrr class %u\n", classid);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_wrr_class_params_validate_and_save(sch, tca, &quantum) < 0) {
+#else
+	if (nss_wrr_class_params_validate_and_save(sch, tca, &quantum, extack) < 0) {
+#endif
 		nss_qdisc_warning("validation of configuration parameters for wrr class %x failed\n",
 					sch->handle);
 		return -EINVAL;
@@ -275,7 +296,7 @@ static int nss_wrr_change_class(struct Q
 		 * reference count should not be 0.
 		 */
 		cl->qdisc = &noop_qdisc;
-		atomic_set(&cl->nq.refcnt, 1);
+		nss_qdisc_atomic_set(&cl->nq);
 		*arg = (unsigned long)cl;
 
 		nss_qdisc_info("Adding classid %u to qdisc %px hash queue %px\n", classid, sch, &q->clhash);
@@ -286,7 +307,8 @@ static int nss_wrr_change_class(struct Q
 		 * here.
 		 */
 		cl->nq.parent = &q->nq;
-		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_WRR_GROUP, classid, accel_mode) < 0) {
+		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_WRR_GROUP, classid, accel_mode, extack) < 0)
+		{
 			nss_qdisc_error("Nss init for class %u failed\n", classid);
 			return -EINVAL;
 		}
@@ -384,7 +406,11 @@ failure:
 	return -EINVAL;
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 12, 0))
+static int nss_wrr_delete_class(struct Qdisc *sch, unsigned long arg, struct netlink_ext_ack *extack)
+#else
 static int nss_wrr_delete_class(struct Qdisc *sch, unsigned long arg)
+#endif
 {
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)arg;
@@ -412,7 +438,9 @@ static int nss_wrr_delete_class(struct Q
 	sch_tree_lock(sch);
 	qdisc_reset(cl->qdisc);
 	qdisc_class_hash_remove(&q->clhash, &cl->cl_common);
-	refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+
+	refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
+
 	sch_tree_unlock(sch);
 	if (!refcnt) {
 		nss_qdisc_error("Reference count should not be zero for class %px\n", cl);
@@ -421,8 +449,13 @@ static int nss_wrr_delete_class(struct Q
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
 								 struct Qdisc **old)
+#else
+static int nss_wrr_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
+								 struct Qdisc **old, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)arg;
@@ -504,6 +537,7 @@ static void nss_wrr_qlen_notify(struct Q
 	 */
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 static unsigned long nss_wrr_get_class(struct Qdisc *sch, u32 classid)
 {
 	struct nss_wrr_class_data *cl = nss_wrr_find_class(classid, sch);
@@ -526,10 +560,24 @@ static void nss_wrr_put_class(struct Qdi
 	 * We are safe to destroy the qdisc if the reference count
 	 * goes down to 0.
 	 */
-	if (atomic_sub_return(1, &cl->nq.refcnt) == 0) {
+	if (nss_qdisc_atomic_sub_return(&cl->nq) == 0) {
 		nss_wrr_destroy_class(sch, cl);
 	}
 }
+#else
+static unsigned long nss_wrr_search_class(struct Qdisc *sch, u32 classid)
+{
+	struct nss_wrr_class_data *cl = nss_wrr_find_class(classid, sch);
+
+	nss_qdisc_info("Get nss_wrr class %px - class match = %px\n", sch, cl);
+
+	if (cl != NULL) {
+		atomic_add(1, &cl->nq.refcnt.refs);
+	}
+
+	return (unsigned long)cl;
+}
+#endif
 
 static int nss_wrr_dump_class(struct Qdisc *sch, unsigned long arg, struct sk_buff *skb,
 		struct tcmsg *tcm)
@@ -550,7 +598,7 @@ static int nss_wrr_dump_class(struct Qdi
 	tcm->tcm_handle = cl->cl_common.classid;
 	tcm->tcm_info = cl->qdisc->handle;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSWRR_CLASS_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -565,7 +613,7 @@ static int nss_wrr_dump_class_stats(stru
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)arg;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &nq->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &nq->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &nq->qstats) < 0) {
 		return -1;
 	}
@@ -600,9 +648,17 @@ static void nss_wrr_walk(struct Qdisc *s
 	}
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_init_qdisc(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_wrr_init_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSWRR_MAX + 1];
 	int err;
 	struct nss_if_msg nim;
 	struct tc_nsswrr_qopt *qopt;
@@ -620,7 +676,11 @@ static int nss_wrr_init_qdisc(struct Qdi
 	qdisc_class_hash_insert(&q->clhash, &q->root.cl_common);
 	qdisc_class_hash_grow(sch, &q->clhash);
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		nss_qdisc_warning("Failed to parse input");
 		return -EINVAL;
@@ -629,7 +689,7 @@ static int nss_wrr_init_qdisc(struct Qdi
 	/*
 	 * Initialize the NSSWRR shaper in NSS
 	 */
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_WRR, 0, qopt->accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_WRR, 0, qopt->accel_mode, extack) < 0) {
 		nss_qdisc_warning("Failed init nss_wrr qdisc");
 		return -EINVAL;
 	}
@@ -669,8 +729,14 @@ static int nss_wrr_init_qdisc(struct Qdi
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_change_qdisc(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_wrr_change_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSWRR_MAX + 1];
 	struct nss_wrr_sched_data *q;
 	struct tc_nsswrr_qopt *qopt;
 
@@ -680,7 +746,11 @@ static int nss_wrr_change_qdisc(struct Q
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -743,7 +813,7 @@ static void nss_wrr_destroy_qdisc(struct
 			 * Reduce refcnt by 1 before destroying. This is to
 			 * ensure that polling of stat stops properly.
 			 */
-			atomic_sub(1, &cl->nq.refcnt);
+			 nss_qdisc_atomic_sub(&cl->nq);
 
 			/*
 			 * Detach class before destroying it. We dont check for noop qdisc here
@@ -794,7 +864,7 @@ static int nss_wrr_dump_qdisc(struct Qdi
 
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -809,9 +879,18 @@ nla_put_failure:
 	return -EMSGSIZE;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_wrr_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_wrr_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 static struct sk_buff *nss_wrr_dequeue(struct Qdisc *sch)
@@ -819,11 +898,13 @@ static struct sk_buff *nss_wrr_dequeue(s
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static unsigned int nss_wrr_drop(struct Qdisc *sch)
 {
 	nss_qdisc_info("Nsswrr drop\n");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 const struct Qdisc_class_ops nss_wrr_class_ops = {
 	.change		= nss_wrr_change_class,
@@ -831,9 +912,17 @@ const struct Qdisc_class_ops nss_wrr_cla
 	.graft		= nss_wrr_graft_class,
 	.leaf		= nss_wrr_leaf_class,
 	.qlen_notify	= nss_wrr_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_wrr_get_class,
 	.put		= nss_wrr_put_class,
+#else
+	.find       = nss_wrr_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block	= nss_qdisc_tcf_block,
+#endif
 	.bind_tcf	= nss_qdisc_tcf_bind,
 	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_wrr_dump_class,
@@ -851,7 +940,9 @@ struct Qdisc_ops nss_wrr_qdisc_ops __rea
 	.enqueue	= nss_wrr_enqueue,
 	.dequeue	= nss_wrr_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_wrr_drop,
+#endif
 	.cl_ops		= &nss_wrr_class_ops,
 	.priv_size	= sizeof(struct nss_wrr_sched_data),
 	.owner		= THIS_MODULE
@@ -863,9 +954,17 @@ const struct Qdisc_class_ops nss_wfq_cla
 	.graft		= nss_wrr_graft_class,
 	.leaf		= nss_wrr_leaf_class,
 	.qlen_notify	= nss_wrr_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_wrr_get_class,
 	.put		= nss_wrr_put_class,
+#else
+	.find       = nss_wrr_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block	= nss_qdisc_tcf_block,
+#endif
 	.bind_tcf	= nss_qdisc_tcf_bind,
 	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_wrr_dump_class,
@@ -883,7 +982,9 @@ struct Qdisc_ops nss_wfq_qdisc_ops __rea
 	.enqueue	= nss_wrr_enqueue,
 	.dequeue	= nss_wrr_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_wrr_drop,
+#endif
 	.cl_ops		= &nss_wrr_class_ops,
 	.priv_size	= sizeof(struct nss_wrr_sched_data),
 	.owner		= THIS_MODULE
--- a/exports/nss_connmgr_tunipip6.h
+++ b/exports/nss_connmgr_tunipip6.h
@@ -28,12 +28,13 @@ enum nss_connmgr_tunipip6_err_codes {
 	NSS_CONNMGR_TUNIPIP6_TUN_DESTROY_FAILURE,	/**< Tunnel destroy failure. */
 	NSS_CONNMGR_TUNIPIP6_TUN_NONE,			/**< Invalid tunnel type */
 	NSS_CONNMGR_TUNIPIP6_NETDEV_TYPE_FAILURE,	/**< Netdevice is not of type ipv6-in-ipv4. */
-	NSS_CONNMGR_TUNIPIP6_MAPRULE_ADD_FAILURE,		/**< BMR/FMR addition failure. */
-	NSS_CONNMGR_TUNIPIP6_MAPRULE_DEL_FAILURE,		/**< BMR/FMR deletion failure. */
-	NSS_CONNMGR_TUNIPIP6_FMR_RULE_FLUSH_FAILURE,		/**< FMR flush failure. */
+	NSS_CONNMGR_TUNIPIP6_MAPRULE_ADD_FAILURE,	/**< BMR/FMR addition failure. */
+	NSS_CONNMGR_TUNIPIP6_MAPRULE_DEL_FAILURE,	/**< BMR/FMR deletion failure. */
+	NSS_CONNMGR_TUNIPIP6_FMR_RULE_FLUSH_FAILURE,	/**< FMR flush failure. */
 	NSS_CONNMGR_TUNIPIP6_NO_DEV,			/**< No NSS node found. */
 	NSS_CONNMGR_TUNIPIP6_INVALID_PARAM,		/**< Invalid tunnel parameters. */
 	NSS_CONNMGR_TUNIPIP6_INVALID_RULE_TYPE,		/**< Invalid maprule type. */
+	NSS_CONNMGR_TUNIPIP6_CONTEXT_FAILURE,		/**< Tunnel host context not found. */
 };
 
 /*
--- a/tunipip6/Makefile
+++ b/tunipip6/Makefile
@@ -2,9 +2,8 @@
 ccflags-y += -I$(obj)/../exports -I$(obj)/..
 ccflags-y += -DNSS_CLIENT_BUILD_ID="$(BUILD_ID)"
 ccflags-y += -DNSS_TUNIPIP6_DEBUG_LEVEL=0
-ccflags-y += -Werror
 obj-m += qca-nss-tunipip6.o
-qca-nss-tunipip6-objs := nss_connmgr_tunipip6.o nss_connmgr_tunipip6_sysctl.o
+qca-nss-tunipip6-objs := nss_connmgr_tunipip6.o nss_connmgr_tunipip6_sysctl.o nss_connmgr_tunipip6_stats.o
 ifneq ($(findstring 4.4, $(KERNELVERSION)),)
 ccflags-y += -DDRAFT03_SUPPORT
 endif
--- a/tunipip6/nss_connmgr_tunipip6.c
+++ b/tunipip6/nss_connmgr_tunipip6.c
@@ -20,7 +20,6 @@
 #include <linux/types.h>
 #include <linux/ip.h>
 #include <linux/of.h>
-#include <linux/tcp.h>
 #include <linux/module.h>
 #include <linux/skbuff.h>
 #include <linux/netdevice.h>
@@ -29,71 +28,123 @@
 #include <linux/if.h>
 #include <net/ip_tunnels.h>
 #include <net/ip6_tunnel.h>
-#include <linux/if_arp.h>
 #include <nss_api_if.h>
 #include "nss_connmgr_tunipip6.h"
 #include "nss_connmgr_tunipip6_sysctl.h"
+#include "nss_connmgr_tunipip6_priv.h"
+
+#define NSS_TUNIPIP6_MAX_FMR 255	/* Maximum number of forward mapping rule (FMR). */
 
 /*
- * NSS tunipip6 debug macros
+ * Frag Id update is disabled by default
  */
-#if (NSS_TUNIPIP6_DEBUG_LEVEL < 1)
-#define nss_tunipip6_assert(fmt, args...)
-#else
-#define nss_tunipip6_assert(c) if (!(c)) { BUG_ON(!(c)); }
-#endif
-
-#if defined(CONFIG_DYNAMIC_DEBUG)
+bool frag_id_update = false;
+/*
+ * Creating custom ipip6 interface is disabled by default.
+ */
+static bool enable_custom;
+module_param(enable_custom, bool, 0);
 
 /*
- * Compile messages for dynamic enable/disable
+ * tunipip6 global context.
  */
-#define nss_tunipip6_warning(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-#define nss_tunipip6_info(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-#define nss_tunipip6_trace(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-#else
+struct nss_tunipip6_context tunipip6_ctx;
 
 /*
- * Statically compile messages at different levels
+ * nss_tunipip6_alloc_instance()
+ * 	Allocate tunipip6 interface instance.
  */
-#if (NSS_TUNIPIP6_DEBUG_LEVEL < 2)
-#define nss_tunipip6_warning(s, ...)
-#else
-#define nss_tunipip6_warning(s, ...) pr_warn("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-#endif
+static struct nss_tunipip6_instance *nss_tunipip6_alloc_instance(struct net_device *dev,
+					int inner_ifnum,
+					int outer_ifnum)
+{
+	struct nss_tunipip6_instance*ntii;
 
-#if (NSS_TUNIPIP6_DEBUG_LEVEL < 3)
-#define nss_tunipip6_info(s, ...)
-#else
-#define nss_tunipip6_info(s, ...)   pr_notice("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-#endif
+	ntii = vzalloc(sizeof(*ntii));
+	if (!ntii) {
+		nss_tunipip6_warning("%px: Not able to allocate tunipip6 instance\n", dev);
+		return NULL;
+	}
 
-#if (NSS_TUNIPIP6_DEBUG_LEVEL < 4)
-#define nss_tunipip6_trace(s, ...)
-#else
-#define nss_tunipip6_trace(s, ...)  pr_info("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
-#endif
-#endif
+	ntii->dev = dev;
+
+	/*
+	 * Create statistics dentry.
+	 */
+	if (!nss_tunipip6_stats_dentry_create(ntii)) {
+		vfree(ntii);
+		nss_tunipip6_warning("%px: Not able to create tunipip6 statistics dentry\n", dev);
+		return NULL;
+	}
+
+	INIT_LIST_HEAD(&ntii->list);
+	ntii->inner_ifnum = inner_ifnum;
+	ntii->outer_ifnum = outer_ifnum;
+	dev_hold(dev);
+	return ntii;
+}
 
 /*
- * Frag Id update is disabled by default
+ * nss_tunipip6_free_instance()
+ * 	Delete the tunipip6 interface instance from the list and free it.
+ *
+ * Note: tunnel list lock is expected to be held by the caller.
  */
-bool frag_id_update = false;
+static void nss_tunipip6_free_instance(struct nss_tunipip6_instance *ntii)
+{
+	if (!list_empty(&ntii->list)) {
+		list_del(&ntii->list);
+	}
+
+	vfree(ntii);
+}
+
 /*
- * Creating custom ipip6 interface is disabled by default.
+ * nss_tunipip6_find_instance()
+ * 	Find tunipip6 interface instance from list.
+ *
+ * Note: tunnel list lock is expected to be held by the caller.
  */
-static bool enable_custom;
-module_param(enable_custom, bool, 0);
+struct nss_tunipip6_instance *nss_tunipip6_find_instance(struct net_device *dev)
+{
+	struct nss_tunipip6_instance *ntii;
+
+	/*
+	 * Check if dev instance is in the list
+	 */
+	list_for_each_entry(ntii, &tunipip6_ctx.dev_list, list) {
+		if (ntii->dev == dev) {
+			return ntii;
+		}
+	}
+
+	return NULL;
+}
 
 /*
- *  tunipip6 stats structure
+ * nss_tunipip6_find_and_free_instance()
+ * 	Find and free the tunipip6 instance.
  */
-struct nss_tunipip6_stats {
-	uint32_t rx_packets;	/* Number of received packets */
-	uint32_t rx_bytes;	/* Number of received bytes */
-	uint32_t tx_packets;	/* Number of transmitted packets */
-	uint32_t tx_bytes;	/* Number of transmitted bytes */
-};
+static enum nss_connmgr_tunipip6_err_codes nss_tunipip6_find_and_free_instance(struct net_device *netdev)
+{
+	struct dentry *dentry;
+	struct nss_tunipip6_instance *ntii;
+
+	spin_lock_bh(&tunipip6_ctx.lock);
+	ntii = nss_tunipip6_find_instance(netdev);
+	if (!ntii) {
+		spin_unlock_bh(&tunipip6_ctx.lock);
+		nss_tunipip6_warning("%px: Not able to find tunipip6 instance for dev:%s\n", netdev, netdev->name);
+		return NSS_CONNMGR_TUNIPIP6_CONTEXT_FAILURE;
+	}
+
+	dentry = ntii->dentry;
+	nss_tunipip6_free_instance(ntii);
+	spin_unlock_bh(&tunipip6_ctx.lock);
+	debugfs_remove(dentry);
+	dev_put(netdev);
+	return NSS_CONNMGR_TUNIPIP6_SUCCESS;
+}
 
 /*
  * nss_tunipip6_encap_exception()
@@ -206,7 +257,7 @@ static void nss_tunipip6_decap_exception
 	struct iphdr *iph;
 	struct rtable *rt;
 	int cpu;
-	int8_t ver = skb->data[0] >> 4;
+	__attribute__((unused)) int8_t ver = skb->data[0] >> 4;
 
 	nss_tunipip6_trace("%px: received - %d bytes name %s ver %x\n",
 			dev, skb->len, dev->name, ver);
@@ -289,20 +340,29 @@ static void nss_tunipip6_decap_exception
 
 /*
  *  nss_tunipip6_update_dev_stats
- *	Update the Dev stats received from NetAp
+ *	Update the Dev stats received from NSS
  */
 static void nss_tunipip6_update_dev_stats(struct net_device *dev,
-					struct nss_tunipip6_stats_sync_msg *sync_stats)
+					struct nss_tunipip6_msg *tnlmsg)
 {
 	struct pcpu_sw_netstats stats;
+	enum nss_dynamic_interface_type interface_type;
+	struct nss_tunipip6_stats_sync_msg *sync_stats = (struct nss_tunipip6_stats_sync_msg *)&tnlmsg->msg.stats_sync;
+
+	interface_type = nss_dynamic_interface_get_type(nss_tunipip6_get_context(), tnlmsg->cm.interface);
+
+	memset(&stats, 0, sizeof(stats));
+	if (interface_type == NSS_DYNAMIC_INTERFACE_TYPE_TUNIPIP6_INNER) {
+		stats.tx_packets = sync_stats->node_stats.tx_packets;
+		stats.tx_bytes = sync_stats->node_stats.tx_bytes;
+	} else if (interface_type == NSS_DYNAMIC_INTERFACE_TYPE_TUNIPIP6_OUTER) {
+		stats.rx_packets = sync_stats->node_stats.rx_packets;
+		stats.rx_bytes = sync_stats->node_stats.rx_bytes;
+	} else {
+		nss_tunipip6_warning("%px: Invalid interface type received from NSS\n", dev);
+		return;
+	}
 
-	u64_stats_init(&stats.syncp);
-	u64_stats_update_begin(&stats.syncp);
-	stats.rx_packets = sync_stats->node_stats.rx_packets;
-	stats.rx_bytes = sync_stats->node_stats.rx_bytes;
-	stats.tx_packets = sync_stats->node_stats.tx_packets;
-	stats.tx_bytes = sync_stats->node_stats.tx_bytes;
-	u64_stats_update_end(&stats.syncp);
 	dev->stats.rx_dropped += nss_cmn_rx_dropped_sum(&sync_stats->node_stats);
 
 	/* TODO: Update rx_dropped stats in ip6_update_offload_stats() */
@@ -316,11 +376,20 @@ static void nss_tunipip6_update_dev_stat
 void nss_tunipip6_event_receive(void *if_ctx, struct nss_tunipip6_msg *tnlmsg)
 {
 	struct net_device *netdev = NULL;
+
 	netdev = (struct net_device *)if_ctx;
 
 	switch (tnlmsg->cm.type) {
 	case NSS_TUNIPIP6_RX_STATS_SYNC:
-		nss_tunipip6_update_dev_stats(netdev, (struct nss_tunipip6_stats_sync_msg *)&tnlmsg->msg.stats_sync);
+		/*
+		 * Update netdevice statistics.
+		 */
+		nss_tunipip6_update_dev_stats(netdev, tnlmsg);
+
+		/*
+		 * Update NSS statistics for tunipip6.
+		 */
+		nss_tunipip6_stats_sync(netdev, tnlmsg);
 		break;
 
 	default:
@@ -415,7 +484,7 @@ static void nss_tunipip6_dev_parse_param
 	tnlcfg->ttl_inherit = false;
 	tnlcfg->tos_inherit = true;
 	tnlcfg->frag_id_update = frag_id_update;
-
+	tnlcfg->fmr_max = NSS_TUNIPIP6_MAX_FMR;
 	/*
 	 * Flow Label In kernel is stored in big endian format.
 	 */
@@ -454,9 +523,9 @@ static void nss_connmgr_tunipip6_configu
 	tunnel = (struct ip6_tnl *)netdev_priv(netdev);
 
 	/*
-	 * Configure FMR table up to NSS_TUNIPIP6_MAX_FMR_NUMBER, the rest will be forwarded to BR
+	 * Configure FMR table up to NSS_TUNIPIP6_MAX_FMR, the rest will be forwarded to BR
 	 */
-	for (fmr = tunnel->parms.fmrs; fmr && fmr_number < NSS_TUNIPIP6_MAX_FMR_NUMBER; fmr = fmr->next, fmr_number++) {
+	for (fmr = tunnel->parms.fmrs; fmr && fmr_number < NSS_TUNIPIP6_MAX_FMR; fmr = fmr->next, fmr_number++) {
 		/*
 		 * Prepare "rulecfg"
 		 */
@@ -497,6 +566,7 @@ enum nss_connmgr_tunipip6_err_codes nss_
 	int inner_ifnum, outer_ifnum;
 	uint32_t features = 0;
 	nss_tx_status_t status;
+	struct nss_tunipip6_instance *ntii;
 
 #if IS_ENABLED(CONFIG_MAP_E_SUPPORT)
 #ifndef DRAFT03_SUPPORT
@@ -626,7 +696,7 @@ configure_tunnel:
 	status = nss_tunipip6_tx_sync(nss_ctx, &tnlmsg);
 	if (status != NSS_TX_SUCCESS) {
 		nss_tunipip6_warning("%px: Tunnel up command error %d\n", netdev, status);
-		goto config_fail;
+		goto context_alloc_fail;
 	}
 
 	/*
@@ -644,12 +714,28 @@ configure_tunnel:
 	status = nss_tunipip6_tx_sync(nss_ctx, &tnlmsg);
 	if (status != NSS_TX_SUCCESS) {
 		nss_tunipip6_warning("%px: Tunnel up command error %d\n", netdev, status);
-		goto config_fail;
+		goto context_alloc_fail;
 	}
 
+	/*
+	 * Initialize tunipip6 instance.
+	 */
+	ntii = nss_tunipip6_alloc_instance(netdev, inner_ifnum, outer_ifnum);
+	if (!ntii) {
+		nss_tunipip6_warning("%px: Not able to create tunipip6 instance\n", netdev);
+		goto context_alloc_fail;
+	}
+
+	/*
+	 * Add the new tunipip6 instance to the global list.
+	 */
+	spin_lock_bh(&tunipip6_ctx.lock);
+	list_add(&ntii->list, &tunipip6_ctx.dev_list);
+	spin_unlock_bh(&tunipip6_ctx.lock);
+
 	return NSS_CONNMGR_TUNIPIP6_SUCCESS;
 
-config_fail:
+context_alloc_fail:
 	nss_unregister_tunipip6_if(outer_ifnum);
 outer_reg_fail:
 	nss_unregister_tunipip6_if(inner_ifnum);
@@ -675,6 +761,8 @@ EXPORT_SYMBOL(nss_connmgr_tunipip6_creat
  */
 enum nss_connmgr_tunipip6_err_codes nss_connmgr_tunipip6_destroy_interface(struct net_device *netdev)
 {
+	enum nss_connmgr_tunipip6_err_codes ret;
+
 	/*
 	 * Validate netdev for ipv6-in-ipv4  Tunnel
 	 */
@@ -682,7 +770,20 @@ enum nss_connmgr_tunipip6_err_codes nss_
 		return NSS_CONNMGR_TUNIPIP6_NETDEV_TYPE_FAILURE;
 	}
 
-	return _nss_tunipip6_dyn_interface_destroy(netdev);
+	/*
+	 * Destroy tunipip6 NSS context.
+	 */
+	ret = _nss_tunipip6_dyn_interface_destroy(netdev);
+	if (ret != NSS_CONNMGR_TUNIPIP6_SUCCESS) {
+		nss_tunipip6_warning("%px: Not able to destroy NSS context. Err: %d\n", netdev, ret);
+		return ret;
+	}
+
+	/*
+	 * Find and free the tunipip6 instance.
+	 */
+	ret = nss_tunipip6_find_and_free_instance(netdev);
+	return ret;
 }
 EXPORT_SYMBOL(nss_connmgr_tunipip6_destroy_interface);
 
@@ -941,6 +1042,39 @@ static int nss_tunipip6_dev_event(struct
 }
 
 /*
+ * nss_tunipip6_destroy_interface_all()
+ * 	Destroy NSS interfaces and free instance for all tunipip6 interfaces.
+ */
+static void nss_tunipip6_destroy_interface_all(void)
+{
+	struct net_device *netdev;
+	struct dentry *dentry;
+	struct nss_tunipip6_instance *ntii;
+
+	spin_lock_bh(&tunipip6_ctx.lock);
+	ntii = list_first_entry_or_null(&tunipip6_ctx.dev_list, struct nss_tunipip6_instance, list);
+	do {
+		if (!ntii) {
+			spin_unlock_bh(&tunipip6_ctx.lock);
+			return;
+		}
+
+		netdev = ntii->dev;
+		dentry = ntii->dentry;
+		nss_tunipip6_free_instance(ntii);
+		spin_unlock_bh(&tunipip6_ctx.lock);
+
+		dev_put(netdev);
+		debugfs_remove(dentry);
+		_nss_tunipip6_dyn_interface_destroy(netdev);
+
+		spin_lock_bh(&tunipip6_ctx.lock);
+		ntii = list_first_entry_or_null(&tunipip6_ctx.dev_list, struct nss_tunipip6_instance, list);
+	} while (ntii);
+	spin_unlock_bh(&tunipip6_ctx.lock);
+}
+
+/*
  * Linux Net device Notifier
  */
 struct notifier_block nss_tunipip6_notifier = {
@@ -965,6 +1099,20 @@ int __init nss_tunipip6_init_module(void
 			  NSS_CLIENT_BUILD_ID);
 
 	/*
+	 * Initialize lock and dev list.
+	 */
+	INIT_LIST_HEAD(&tunipip6_ctx.dev_list);
+	spin_lock_init(&tunipip6_ctx.lock);
+
+	/*
+	 * Create the debugfs directory for statistics.
+	 */
+	if (!nss_tunipip6_stats_dentry_init()) {
+		nss_tunipip6_trace("Failed to initialize debugfs\n");
+		return -1;
+	}
+
+	/*
 	 * Do not register net device notification for
 	 * custom tunnel. Net device notification is used only
 	 * for standard tunnel.
@@ -1000,6 +1148,16 @@ void __exit nss_tunipip6_exit_module(voi
 #endif
 
 	/*
+	 * Free Host and NSS tunipip6 instances.
+	 */
+	nss_tunipip6_destroy_interface_all();
+
+	/*
+	 * De-initialize debugfs.
+	 */
+	nss_tunipip6_stats_dentry_deinit();
+
+	/*
 	 * Unregister net device notification for standard tunnel.
 	 */
 	if (!enable_custom) {
--- /dev/null
+++ b/tunipip6/nss_connmgr_tunipip6_priv.h
@@ -0,0 +1,94 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2020, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#ifndef __NSS_CONNMGR_TUNIPIP6_PRIV_H_
+#define __NSS_CONNMGR_TUNIPIP6_PRIV_H_
+
+#include "nss_connmgr_tunipip6_stats.h"
+#include <linux/debugfs.h>
+
+/*
+ * tunipip6 context
+ */
+extern struct nss_tunipip6_context tunipip6_ctx;
+
+/*
+ * NSS tunipip6 debug macros
+ */
+#if (NSS_TUNIPIP6_DEBUG_LEVEL < 1)
+#define nss_tunipip6_assert(fmt, args...)
+#else
+#define nss_tunipip6_assert(c) if (!(c)) { BUG_ON(!(c)); }
+#endif
+
+/*
+ * Compile messages for dynamic enable/disable
+ */
+#if defined(CONFIG_DYNAMIC_DEBUG)
+#define nss_tunipip6_warning(s, ...) pr_debug("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#define nss_tunipip6_info(s, ...) pr_debug("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#define nss_tunipip6_trace(s, ...) pr_debug("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#else /* CONFIG_DYNAMIC_DEBUG */
+/*
+ * Statically compile messages at different levels
+ */
+#if (NSS_TUNIPIP6_DEBUG_LEVEL < 2)
+#define nss_tunipip6_warning(s, ...)
+#else
+#define nss_tunipip6_warning(s, ...) pr_warn("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+
+#if (NSS_TUNIPIP6_DEBUG_LEVEL < 3)
+#define nss_tunipip6_info(s, ...)
+#else
+#define nss_tunipip6_info(s, ...)   pr_notice("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+
+#if (NSS_TUNIPIP6_DEBUG_LEVEL < 4)
+#define nss_tunipip6_trace(s, ...)
+#else
+#define nss_tunipip6_trace(s, ...)  pr_info("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+#endif /* CONFIG_DYNAMIC_DEBUG */
+
+extern struct nss_tunipip6_context tunipip6_ctx;
+
+/*
+ * tunipip6 global context structure.
+ */
+struct nss_tunipip6_context {
+	struct list_head dev_list;		/* List of tunipip6 interface instances */
+	struct dentry *tunipip6_dentry_dir;	/* tunipip6 debugfs directory entry */
+	spinlock_t lock;			/* Lock to protect list. */
+};
+
+/*
+ * tunipip6 interface instance structure.
+ */
+struct nss_tunipip6_instance {
+	struct list_head list;			/* List of tunipip6 interface instance */
+	struct net_device *dev;			/* tunipip6 netdevice */
+	struct dentry *dentry;			/* debugfs entry for this tunnel device */
+	struct nss_tunipip6_stats stats;	/* tunipip6 statistics */
+	uint32_t inner_ifnum;			/* tunipip6 inner dynamic interface */
+	uint32_t outer_ifnum;			/* tunipip6 outer dynamic interface */
+};
+
+struct nss_tunipip6_instance *nss_tunipip6_find_instance(struct net_device *dev);
+
+#endif /* __NSS_CONNMGR_TUNIPIP6_PRIV_H_ */
--- /dev/null
+++ b/tunipip6/nss_connmgr_tunipip6_stats.c
@@ -0,0 +1,225 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2020, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#include <nss_api_if.h>
+#include "nss_connmgr_tunipip6_priv.h"
+
+/*
+ * nss_tunipip6_stats_str
+ *	tunipip6 statistics strings for NSS tunnel stats
+ */
+static int8_t *nss_tunipip6_stats_str[NSS_TUNIPIP6_STATS_MAX] = {
+	"rx pkts",
+	"rx bytes",
+	"tx pkts",
+	"tx bytes",
+	"rx queue 0 dropped",
+	"rx queue 1 dropped",
+	"rx queue 2 dropped",
+	"rx queue 3 dropped",
+	"encap low headroom",
+	"encap unhandled_protocol",
+	"encap enqueue fail",
+	"encap tunnel exist",
+	"encap total fmr_count",
+	"encap fmr add count",
+	"encap fmr del count",
+	"encap fmr flush count",
+	"encap fmr update_count",
+	"encap fmr add_fail count",
+	"encap fmr del_fail count",
+	"encap error no fmr",
+	"encap bmr add count",
+	"encap bmr del count",
+	"encap error bmr exist",
+	"encap error no bmr",
+	"decap enqueue fail",
+};
+
+/*
+ * nss_tunipip6_stats_show()
+ *	Read tunipip6 tunnel statistics
+ */
+static int nss_tunipip6_stats_show(struct seq_file *m, void __attribute__((unused))*p)
+{
+	int i;
+	struct nss_tunipip6_instance *tun_inst;
+	struct nss_tunipip6_stats *tunipip6_tunnel_stats;
+
+	tun_inst = vzalloc(sizeof(struct nss_tunipip6_instance));
+	if (!tun_inst) {
+		nss_tunipip6_warning("Failed to allocate memory for tun_inst\n");
+		return -ENOMEM;
+	}
+
+	tunipip6_tunnel_stats = vzalloc(sizeof(struct nss_tunipip6_stats));
+	if (!tunipip6_tunnel_stats) {
+		nss_tunipip6_warning("Failed to allocate memory for tunipip6_tunnel_stats\n");
+		vfree(tun_inst);
+		return -ENOMEM;
+	}
+
+	/*
+	 * Copy the tunnel and stats information from the tunnel instance.
+	 */
+	spin_lock_bh(&tunipip6_ctx.lock);
+	memcpy(tun_inst, m->private, sizeof(struct nss_tunipip6_instance));
+	memcpy(tunipip6_tunnel_stats, &tun_inst->stats, sizeof(struct nss_tunipip6_stats));
+	spin_unlock_bh(&tunipip6_ctx.lock);
+
+	seq_printf(m, "\n\tInner ifnum %u stats:\n", tun_inst->inner_ifnum);
+	for (i = 0; i < NSS_TUNIPIP6_STATS_MAX; i++) {
+		seq_printf(m, "\t\t%s = %llu\n",
+				nss_tunipip6_stats_str[i],
+				tunipip6_tunnel_stats->inner_stats[i]);
+	}
+
+	seq_printf(m, "\n\tOuter ifnum %u stats:\n", tun_inst->outer_ifnum);
+	for (i = 0; i < NSS_TUNIPIP6_STATS_MAX; i++) {
+		seq_printf(m, "\t\t%s = %llu\n",
+				nss_tunipip6_stats_str[i],
+				tunipip6_tunnel_stats->outer_stats[i]);
+	}
+
+	seq_printf(m, "\n%s tunnel stats end\n\n", tun_inst->dev->name);
+	vfree(tun_inst);
+	vfree(tunipip6_tunnel_stats);
+	return 0;
+}
+
+/*
+ * nss_tunipip6_stats_open()
+ */
+static int nss_tunipip6_stats_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, nss_tunipip6_stats_show, inode->i_private);
+}
+
+/*
+ * nss_tunipip6_stats_update()
+ *	Update inner or outer node statistics
+ */
+static void nss_tunipip6_stats_update(uint64_t *stats, struct nss_tunipip6_stats_sync_msg *stats_msg)
+{
+	uint32_t i, *src;
+	uint64_t *dest = stats;
+
+	src = &stats_msg->node_stats.rx_packets;
+	for (i = NSS_TUNIPIP6_STATS_RX_PKTS; i < NSS_TUNIPIP6_STATS_MAX; i++, src++, dest++) {
+		*dest += *src;
+	}
+}
+
+/*
+ * nss_tunipip6_stats_sync()
+ *	Sync function for tunipip6 statistics
+ */
+void nss_tunipip6_stats_sync(struct net_device *dev, struct nss_tunipip6_msg *ntm)
+{
+	uint32_t ifnum = ntm->cm.interface;
+	struct nss_tunipip6_stats_sync_msg *stats = &ntm->msg.stats_sync;
+	struct nss_tunipip6_instance *ntii;
+	struct nss_tunipip6_stats *s;
+
+	spin_lock_bh(&tunipip6_ctx.lock);
+	ntii = nss_tunipip6_find_instance(dev);
+	if (!ntii) {
+		spin_unlock_bh(&tunipip6_ctx.lock);
+		nss_tunipip6_warning("%px: Not able to find context for device: %s\n", dev, dev->name);
+		return;
+	}
+
+	s = &ntii->stats;
+	if (ntii->inner_ifnum == ifnum) {
+		nss_tunipip6_stats_update(s->inner_stats, stats);
+	} else if (ntii->outer_ifnum == ifnum) {
+		nss_tunipip6_stats_update(s->outer_stats, stats);
+	} else {
+		nss_tunipip6_warning("%px: Netdev=%s invalid interface number. Interface No: %u\n", dev, dev->name, ifnum);
+	}
+
+	spin_unlock_bh(&tunipip6_ctx.lock);
+}
+
+/*
+ * nss_tunipip6_stats_ops
+ *	File operations for tunipip6 tunnel stats
+ */
+static const struct file_operations nss_tunipip6_stats_ops = { \
+	.open = nss_tunipip6_stats_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = seq_release
+};
+
+/*
+ * nss_tunipip6_stats_dentry_destroy()
+ *	Remove debufs file for given tunnel.
+ */
+void nss_tunipip6_stats_dentry_destroy(struct nss_tunipip6_instance *tun_inst)
+{
+	debugfs_remove(tun_inst->dentry);
+}
+
+/*
+ * nss_tunipip6_stats_dentry_create()
+ *	Create dentry for a given tunnel.
+ */
+bool nss_tunipip6_stats_dentry_create(struct nss_tunipip6_instance *tun_inst)
+{
+	char dentry_name[IFNAMSIZ];
+
+	scnprintf(dentry_name, sizeof(dentry_name), "%s", tun_inst->dev->name);
+	tun_inst->dentry = debugfs_create_file(dentry_name, S_IRUGO,
+			tunipip6_ctx.tunipip6_dentry_dir, tun_inst, &nss_tunipip6_stats_ops);
+	if (!tun_inst->dentry) {
+		nss_tunipip6_warning("Debugfs file creation failed for tun %s\n", tun_inst->dev->name);
+		return false;
+	}
+
+	return true;
+}
+
+/*
+ * nss_tunipip6_stats_dentry_deinit()
+ *	Cleanup the debugfs tree.
+ */
+void nss_tunipip6_stats_dentry_deinit(void)
+{
+	if (tunipip6_ctx.tunipip6_dentry_dir) {
+		debugfs_remove_recursive(tunipip6_ctx.tunipip6_dentry_dir);
+	}
+}
+
+/*
+ * nss_tunipip6_stats_dentry_init()
+ *	Create tunipip6 tunnel statistics debugfs entry.
+ */
+bool nss_tunipip6_stats_dentry_init(void)
+{
+	/*
+	 * Initialize debugfs directory.
+	 */
+	tunipip6_ctx.tunipip6_dentry_dir = debugfs_create_dir("qca-nss-tunipip6", NULL);
+	if (!tunipip6_ctx.tunipip6_dentry_dir) {
+		nss_tunipip6_warning("Failed to create debug entry for subsystem: qca-nss-tunipip6\n");
+		return false;
+	}
+
+	return true;
+}
--- /dev/null
+++ b/tunipip6/nss_connmgr_tunipip6_stats.h
@@ -0,0 +1,73 @@
+/*
+ ******************************************************************************
+ * Copyright (c) 2020, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * ****************************************************************************
+ */
+
+#ifndef _NSS_CONNMGR_TUNIPIP6_STATS_H_
+#define _NSS_CONNMGR_TUNIPIP6_STATS_H_
+
+struct nss_tunipip6_instance;
+
+/*
+ * tunipip6 statistic counters
+ */
+enum nss_tunipip6_stats_type {
+	NSS_TUNIPIP6_STATS_RX_PKTS,
+	NSS_TUNIPIP6_STATS_RX_BYTES,
+	NSS_TUNIPIP6_STATS_TX_PKTS,
+	NSS_TUNIPIP6_STATS_TX_BYTES,
+	NSS_TUNIPIP6_STATS_RX_QUEUE_0_DROPPED,
+	NSS_TUNIPIP6_STATS_RX_QUEUE_1_DROPPED,
+	NSS_TUNIPIP6_STATS_RX_QUEUE_2_DROPPED,
+	NSS_TUNIPIP6_STATS_RX_QUEUE_3_DROPPED,
+	NSS_TUNIPIP6_STATS_EXCEP_ENCAP_LOW_HEADROOM,
+	NSS_TUNIPIP6_STATS_EXCEP_ENCAP_UNHANDLED_PROTOCOL,
+	NSS_TUNIPIP6_STATS_DROP_ENCAP_ENQUEUE_FAIL,
+	NSS_TUNIPIP6_STATS_CONFIG_ERR_TUNNEL,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_TOTAL_FMR,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_FMR_ADD,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_FMR_DEL,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_FMR_FLUSH,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_FMR_UPDATE,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_FMR_ADD_FAIL,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_FMR_DEL_FAIL,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_ERR_NO_FMR,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_BMR_ADD,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_BMR_DEL,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_ERR_BMR_EXIST,
+	NSS_TUNIPIP6_STATS_CONFIG_ENCAP_ERR_NO_BMR,
+	NSS_TUNIPIP6_STATS_DROP_DECAP_ENQUEUE_FAIL,
+	NSS_TUNIPIP6_STATS_MAX,
+};
+
+/*
+ * tunipip6 statistics
+ */
+struct nss_tunipip6_stats {
+	uint64_t inner_stats[NSS_TUNIPIP6_STATS_MAX];
+	uint64_t outer_stats[NSS_TUNIPIP6_STATS_MAX];
+};
+
+/*
+ * tunipip6 statistics API
+ */
+extern void nss_tunipip6_stats_sync(struct net_device *dev, struct nss_tunipip6_msg *ntm);
+extern void nss_tunipip6_stats_dentry_deinit(void);
+extern bool nss_tunipip6_stats_dentry_init(void);
+extern void nss_tunipip6_stats_dentry_destroy(struct nss_tunipip6_instance *tun_inst);
+extern bool nss_tunipip6_stats_dentry_create(struct nss_tunipip6_instance *tun_inst);
+
+#endif /* _NSS_CONNMGR_TUNIPIP6_STATS_H_ */
--- a/tunipip6/nss_connmgr_tunipip6_sysctl.c
+++ b/tunipip6/nss_connmgr_tunipip6_sysctl.c
@@ -1,6 +1,6 @@
  /*
  **************************************************************************
- * Copyright (c) 2020, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2020-2021, The Linux Foundation. All rights reserved.
 
  * Permission to use, copy, modify, and/or distribute this software for any
  * purpose with or without fee is hereby granted, provided that the above
@@ -61,7 +61,7 @@ static int nss_tunipip6_data_parser(stru
 	bool ipv4_prefix_valid = false, ipv4_prefix_len_valid = false, ipv6_suffix_len_valid = false;
 	bool rule_type_valid = false, ea_len_valid = false, psid_offset_valid = false, netdev_valid = false;
 	struct nss_connmgr_tunipip6_maprule_cfg mrcfg = {0};
-	char *buf = kzalloc(MAX_PROC_SIZE, GFP_KERNEL);
+	char *buf;
 	enum nss_connmgr_tunipip6_err_codes status;
 	struct net_device *dev = NULL;
 	char *pfree;
@@ -69,7 +69,11 @@ static int nss_tunipip6_data_parser(stru
 	int ret;
 	int count;
 
+        if (!write) {
+                return -EINVAL;
+        }
 
+	buf = kzalloc(MAX_PROC_SIZE, GFP_KERNEL);
 	if (!buf) {
 		return -ENOMEM;
 	}
@@ -122,6 +126,7 @@ static int nss_tunipip6_data_parser(stru
 
 			if ((rule_type !=NSS_CONNMGR_TUNIPIP6_RULE_BMR) &&
 				       (rule_type != NSS_CONNMGR_TUNIPIP6_RULE_FMR)) {
+				kfree(pfree);
 				goto fail;
 			}
 			rule_type_valid = true;
@@ -135,6 +140,7 @@ static int nss_tunipip6_data_parser(stru
 			}
 
 			if (frag_id != 0 && frag_id != 1) {
+				kfree(pfree);
 				goto fail;
 			}
 			continue;
@@ -396,9 +402,9 @@ static int nss_tunipip6_cmd_procfs_read_
 			b. To delete maprule(BMR):\n\
 			echo dev=<map-mape/MAP-E netdevice> rule_type=<1> > remove_map_rule\n\
 			3. To flush FMR entries:\n\
-			echo dev=<map-mape/MAP-E netdevice> > flush_fmr_rule\n\
-			4. To enable/disable frag id:\n\
-			echo frag_id_update=<0/1> > frag_id\n\
+			echo dev=<map-mape/MAP-E netdevice> > flush_fmr_rule\n");
+	pr_info("\t\t\t4. To enable/disable frag id: \n\
+			echo frag_id_update=<0/1> > frag_id \n\
 			=====end of help=====\n");
 	*lenp = 0;
 	return ret;
--- a/capwapmgr/nss_capwapmgr.c
+++ b/capwapmgr/nss_capwapmgr.c
@@ -348,6 +348,40 @@ static struct rtnl_link_stats64 *nss_cap
 	return stats;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0))
+/*
+ * nss_capwapmgr_dev_tunnel_stats()
+ *	Netdev ops function to retrieve stats for kernel version < 4.6
+ */
+static struct rtnl_link_stats64 *nss_capwapmgr_dev_tunnel_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+{
+	return nss_capwapmgr_get_tunnel_stats(dev, stats);
+}
+#else
+/*
+ * nss_capwapmgr_dev_tunnel_stats()
+ *	Netdev ops function to retrieve stats for kernel version > 4.6
+ */
+static void nss_capwapmgr_dev_tunnel_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+{
+	nss_capwapmgr_get_tunnel_stats(dev, stats);
+}
+#endif
+
+/**
+ * nss_capwapmgr_change_mtu - set new MTU size
+ * @dev: network device
+ * @new_mtu: new Maximum Transfer Unit
+ *
+ * Allow changing MTU size. Needs to be overridden for devices
+ * supporting jumbo frames.
+ */
+int nss_capwapmgr_change_mtu(struct net_device *dev, int new_mtu)
+{
+	dev->mtu = new_mtu;
+	return 0;
+}
+
 /*
  * nss_capwapmgr_netdev_ops
  *	Netdev operations.
@@ -357,8 +391,8 @@ static const struct net_device_ops nss_c
 	.ndo_stop		= nss_capwapmgr_close,
 	.ndo_start_xmit		= nss_capwapmgr_start_xmit,
 	.ndo_set_mac_address	= eth_mac_addr,
-	.ndo_change_mtu		= eth_change_mtu,
-	.ndo_get_stats64	= nss_capwapmgr_get_tunnel_stats,
+	.ndo_change_mtu		= nss_capwapmgr_change_mtu,
+	.ndo_get_stats64	= nss_capwapmgr_dev_tunnel_stats,
 };
 
 /*
@@ -375,7 +409,12 @@ static void nss_capwapmgr_dummpy_netdev_
 	dev->ethtool_ops = NULL;
 	dev->header_ops = NULL;
 	dev->netdev_ops = &nss_capwapmgr_netdev_ops;
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 11, 8))
 	dev->destructor = NULL;
+#else
+	dev->priv_destructor = NULL;
+#endif
 	memcpy(dev->dev_addr, "\x00\x00\x00\x00\x00\x00", dev->addr_len);
 	memset(dev->broadcast, 0xff, dev->addr_len);
 	memcpy(dev->perm_addr, dev->dev_addr, dev->addr_len);
@@ -514,6 +553,8 @@ static nss_capwapmgr_status_t nss_capwap
 /*
  * nss_capwapmgr_verify_tunnel_param()
  *	Common function to verify tunnel_id and returns pointer to tunnel.
+ *
+ * The caller of the function should hold reference to the net device before calling.
  */
 static struct nss_capwapmgr_tunnel *nss_capwapmgr_verify_tunnel_param(struct net_device *dev, uint8_t tunnel_id)
 {
@@ -1050,6 +1091,7 @@ static nss_tx_status_t nss_capwapmgr_cre
 	nircm->rule_flags |= rule_flags;
 	nircm->valid_flags |= valid_flags;
 
+	down(&ip_response.sem);
 	status = nss_ipv6_tx(nss_ctx, &nim);
 	if (status != NSS_TX_SUCCESS) {
 		up(&ip_response.sem);
--- a/match/nss_match_l2.c
+++ b/match/nss_match_l2.c
@@ -1,6 +1,7 @@
 /*
  *******************************************************************************
  * Copyright (c) 2020, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2022 Qualcomm Innovation Center, Inc. All rights reserved.
  *
  * Permission to use, copy, modify, and/or distribute this software for any
  * purpose with or without fee is hereby granted, provided that the above
@@ -133,7 +134,7 @@ static int nss_match_l2_cmd_parse(char *
 	struct nss_ctx_instance *nss_ctx = nss_match_get_context();
 	int ret = 0;
 	uint32_t mask_val[4] = {0};
-	uint32_t actions = 0, if_num = 0, setprio = 0, nexthop = 0;
+	uint32_t actions = 0, if_num = 0, setprio = NSS_MAX_NUM_PRI, nexthop = 0;
 	uint16_t smac[3] = {0}, dmac[3] = {0}, mask_id = 0, ethertype = 0;
 	uint8_t mac_addr_tmp[6];
 	char tmp[4];
@@ -340,22 +341,22 @@ static int nss_match_l2_cmd_parse(char *
 
 		switch(actions) {
 		case NSS_MATCH_ACTION_SETPRIO:
-			if (nexthop || !setprio || setprio >= NSS_MAX_NUM_PRI) {
+			if (nexthop || setprio >= NSS_MAX_NUM_PRI) {
 				goto fail;
 			}
 			break;
 		case NSS_MATCH_ACTION_FORWARD:
-			if (setprio || !nexthop) {
+			if (!(setprio == NSS_MAX_NUM_PRI) || !nexthop) {
 				goto fail;
 			}
 			break;
 		case NSS_MATCH_ACTION_SETPRIO | NSS_MATCH_ACTION_FORWARD:
-			if (!setprio || !nexthop || setprio >= NSS_MAX_NUM_PRI) {
+			if (!nexthop || setprio >= NSS_MAX_NUM_PRI) {
 				goto fail;
 			}
 			break;
 		case NSS_MATCH_ACTION_DROP:
-			if (setprio || nexthop) {
+			if (!(setprio == NSS_MAX_NUM_PRI) || nexthop) {
 				goto fail;
 			}
 			break;
--- a/match/nss_match_vow.c
+++ b/match/nss_match_vow.c
@@ -1,6 +1,6 @@
 /*
  *******************************************************************************
- * Copyright (c) 2020, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2020-2021, The Linux Foundation. All rights reserved.
  *
  * Permission to use, copy, modify, and/or distribute this software for any
  * purpose with or without fee is hereby granted, provided that the above
@@ -122,7 +122,7 @@ static int nss_match_vow_cmd_parse(char
 	char *token, *param, *value;
 	struct nss_ctx_instance *nss_ctx = nss_match_get_context();
 	int ret = 0;
-	uint32_t actions = 0, if_num = 0, dscp = 0, outer_prio = 0, inner_prio = 0, setprio = 0, nexthop = 0;
+	uint32_t actions = 0, if_num = 0, dscp = 0, outer_prio = 0, inner_prio = 0, setprio = NSS_MAX_NUM_PRI, nexthop = 0;
 	uint16_t mask_id = 0;
 	uint32_t mask_val = 0;
 
@@ -301,22 +301,22 @@ static int nss_match_vow_cmd_parse(char
 
 		switch(actions) {
 		case NSS_MATCH_ACTION_SETPRIO:
-			if (nexthop || !setprio || setprio >= NSS_MAX_NUM_PRI) {
+			if (nexthop || setprio >= NSS_MAX_NUM_PRI) {
 				goto fail;
 			}
 			break;
 		case NSS_MATCH_ACTION_FORWARD:
-			if (setprio || !nexthop) {
+			if (!(setprio == NSS_MAX_NUM_PRI) || !nexthop) {
 				goto fail;
 			}
 			break;
 		case NSS_MATCH_ACTION_SETPRIO | NSS_MATCH_ACTION_FORWARD:
-			if (!setprio || !nexthop || setprio >= NSS_MAX_NUM_PRI) {
+			if (!nexthop || setprio >= NSS_MAX_NUM_PRI) {
 				goto fail;
 			}
 			break;
 		case NSS_MATCH_ACTION_DROP:
-			if (setprio || nexthop) {
+			if (!(setprio == NSS_MAX_NUM_PRI) || nexthop) {
 				goto fail;
 			}
 			break;
--- a/pvxlanmgr/nss_pvxlanmgr.c
+++ b/pvxlanmgr/nss_pvxlanmgr.c
@@ -186,6 +186,26 @@ static struct rtnl_link_stats64 *nss_pvx
 	return stats;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0))
+/*
+ * nss_pvxlanmgr_dev_tunnel_stats()
+ *	Netdev ops function to retrieve stats for kernel version < 4.6
+ */
+static struct rtnl_link_stats64 *nss_pvxlanmgr_dev_tunnel_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+{
+	return nss_pvxlanmgr_get_tunnel_stats(dev, stats);
+}
+#else
+/*
+ * nss_pvxlanmgr_dev_tunnel_stats()
+ *	Netdev ops function to retrieve stats for kernel version > 4.6
+ */
+static void nss_pvxlanmgr_dev_tunnel_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+{
+	nss_pvxlanmgr_get_tunnel_stats(dev, stats);
+}
+#endif
+
 /*
  * nss_pvxlanmgr_unregister_with_nss()
  *	Internal function to unregister with NSS FW
@@ -262,7 +282,7 @@ static const struct net_device_ops nss_p
 	.ndo_stop		= nss_pvxlanmgr_close,
 	.ndo_start_xmit		= nss_pvxlanmgr_start_xmit,
 	.ndo_set_mac_address	= eth_mac_addr,
-	.ndo_get_stats64	= nss_pvxlanmgr_get_tunnel_stats,
+	.ndo_get_stats64	= nss_pvxlanmgr_dev_tunnel_stats,
 };
 
 /*
@@ -278,7 +298,13 @@ static void nss_pvxlanmgr_dummy_netdev_s
 	dev->ethtool_ops = NULL;
 	dev->header_ops = NULL;
 	dev->netdev_ops = &nss_pvxlanmgr_netdev_ops;
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(4, 11, 8))
 	dev->destructor = NULL;
+#else
+	dev->priv_destructor = NULL;
+#endif
+
 	memcpy(dev->dev_addr, "\x00\x00\x00\x00\x00\x00", dev->addr_len);
 	memset(dev->broadcast, 0xff, dev->addr_len);
 	memcpy(dev->perm_addr, dev->dev_addr, dev->addr_len);
@@ -600,13 +626,14 @@ EXPORT_SYMBOL(nss_pvxlanmgr_netdev_creat
 void __exit nss_pvxlanmgr_exit_module(void)
 {
 	int ret;
-
+#ifdef CONFIG_OF
 	/*
 	 * If the node is not compatible, don't do anything.
 	 */
 	if (!of_find_node_by_name(NULL, "nss-common")) {
 		return;
 	}
+#endif
 
 	ret = unregister_netdevice_notifier(&nss_pvxlanmgr_netdev_notifier);
 	if (!ret) {
@@ -623,12 +650,14 @@ void __exit nss_pvxlanmgr_exit_module(vo
 int __init nss_pvxlanmgr_init_module(void)
 {
 	int ret;
+#ifdef CONFIG_OF
 	/*
 	 * If the node is not compatible, don't do anything.
 	 */
 	if (!of_find_node_by_name(NULL, "nss-common")) {
 		return 0;
 	}
+#endif
 
 	nss_pvxlanmgr_info("module %s loaded\n",
 			   NSS_CLIENT_BUILD_ID);
--- a/pvxlanmgr/nss_pvxlanmgr_priv.h
+++ b/pvxlanmgr/nss_pvxlanmgr_priv.h
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2019, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2019-2020, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -19,8 +19,10 @@
  *	Pvxlan manager private defines
  */
 #include <linux/types.h>
+#include <linux/of.h>
 #include <linux/module.h>
 #include <linux/skbuff.h>
+#include <linux/version.h>
 #include <nss_api_if.h>
 #include <linux/in.h>
 #include <linux/etherdevice.h>
