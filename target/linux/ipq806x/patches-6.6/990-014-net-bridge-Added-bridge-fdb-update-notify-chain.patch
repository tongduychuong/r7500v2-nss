From ae56f1dceb55a3e8e5fadf9bc109270436e3d8fa Mon Sep 17 00:00:00 2001
From: Murat Sezgin <quic_msezgin@quicinc.com>
Date: Thu, 18 May 2023 21:11:09 -0700
Subject: [PATCH 220/281] net: bridge: Added bridge fdb update notify chain

Registered modules are notified based on two events:
1. Dst port changes for any existing bridge fdb entry
2. Bridge fdb entry ages out/deleted

Change-Id: Iaba8fba6859bcc8e638df4f2e9900c131b1a6d34
Signed-off-by: ratheesh kannoth <rkannoth@codeaurora.org>
Signed-off-by: Murat Sezgin <msezgin@codeaurora.org>

net: bridge : delete fdb entry before callbacks

Ageing timer expires and deletes corresponding fdb entry. Registered
callbacks for br_fdb_update_notifier chains are called one by one.
Since callback invocation is before the deletion of fdb entry,
it may lead to race condition. Fix is to reorder it.

Change-Id: Idefce6d879bfa6104cadc495aa61d164db214c97
Signed-off-by: ratheesh kannoth <rkannoth@codeaurora.org>
Signed-off-by: Murat Sezgin <msezgin@codeaurora.org>
Signed-off-by: Murat Sezgin <quic_msezgin@quicinc.com>
---
 include/linux/if_bridge.h |  2 ++
 net/bridge/br_fdb.c       | 28 ++++++++++++++++++++++++++--
 2 files changed, 28 insertions(+), 2 deletions(-)

--- a/include/linux/if_bridge.h
+++ b/include/linux/if_bridge.h
@@ -79,6 +79,8 @@ extern void br_dev_update_stats(struct n
 extern struct net_bridge_fdb_entry *br_fdb_has_entry(struct net_device *dev,
 						     const char *addr,
 						     __u16 vid);
+extern void br_fdb_update_register_notify(struct notifier_block *nb);
+extern void br_fdb_update_unregister_notify(struct notifier_block *nb);
 
 #if IS_ENABLED(CONFIG_BRIDGE) && IS_ENABLED(CONFIG_BRIDGE_IGMP_SNOOPING)
 int br_multicast_list_adjacent(struct net_device *dev,
--- a/net/bridge/br_fdb.c
+++ b/net/bridge/br_fdb.c
@@ -519,6 +519,20 @@ out:
 	spin_unlock_bh(&br->hash_lock);
 }
 
+ATOMIC_NOTIFIER_HEAD(br_fdb_update_notifier_list);
+
+void br_fdb_update_register_notify(struct notifier_block *nb)
+{
+	atomic_notifier_chain_register(&br_fdb_update_notifier_list, nb);
+}
+EXPORT_SYMBOL_GPL(br_fdb_update_register_notify);
+
+void br_fdb_update_unregister_notify(struct notifier_block *nb)
+{
+	atomic_notifier_chain_unregister(&br_fdb_update_notifier_list, nb);
+}
+EXPORT_SYMBOL_GPL(br_fdb_update_unregister_notify);
+
 void br_fdb_cleanup(struct work_struct *work)
 {
 	struct net_bridge *br = container_of(work, struct net_bridge,
@@ -527,6 +541,8 @@ void br_fdb_cleanup(struct work_struct *
 	unsigned long delay = hold_time(br);
 	unsigned long work_delay = delay;
 	unsigned long now = jiffies;
+	u8 mac_addr[6];
+
 
 	/* this part is tricky, in order to avoid blocking learning and
 	 * consequently forwarding, we rely on rcu to delete objects with
@@ -553,8 +569,12 @@ void br_fdb_cleanup(struct work_struct *
 			work_delay = min(work_delay, this_timer - now);
 		} else {
 			spin_lock_bh(&br->hash_lock);
-			if (!hlist_unhashed(&f->fdb_node))
-				fdb_delete(br, f, true);
+			if (!hlist_unhashed(&f->fdb_node)) {
+			    ether_addr_copy(mac_addr, f->key.addr.addr);
+			    fdb_delete(br, f, true);
+			    atomic_notifier_call_chain(&br_fdb_update_notifier_list, 0,
+						       (void *)mac_addr);
+			}
 			spin_unlock_bh(&br->hash_lock);
 		}
 	}
@@ -886,6 +906,11 @@ void br_fdb_update(struct net_bridge *br
 						      &fdb->flags)))
 					clear_bit(BR_FDB_ADDED_BY_EXT_LEARN,
 						  &fdb->flags);
+
+				atomic_notifier_call_chain(
+					&br_fdb_update_notifier_list,
+					0, (void *)addr);
+
 				/* Clear locked flag when roaming to an
 				 * unlocked port.
 				 */
